{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f63e91-19bf-4a70-96b8-29a59b42b12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import tifffile\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import copy\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Import interactive libraries\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, fixed, interact_manual, interactive\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Add the parent directory to the path so we can import modules\n",
    "parent_dir = os.path.dirname(os.path.dirname(os.path.abspath('.')))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# For direct imports from the parent directory\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "\n",
    "# Import pipeline modules\n",
    "# Note: If modules are in a different directory, adjust the import path accordingly\n",
    "try:\n",
    "    from modules.file_matcher import match_tif_and_roi_files\n",
    "    from modules.preprocessing import (\n",
    "        correct_photobleaching,\n",
    "        remove_background,\n",
    "        denoise,\n",
    "        stripe_correction\n",
    "    )\n",
    "    from modules.roi_processing import (\n",
    "        extract_roi_fluorescence, \n",
    "        subtract_background,\n",
    "        subtract_global_background,\n",
    "        extract_rois_from_zip, \n",
    "        save_masks_for_cnmf, \n",
    "        extract_roi_fluorescence_with_cnmf,\n",
    "        refine_rois_with_cnmfe,\n",
    "        refine_rois_with_pnr,\n",
    "        split_signal_noise,\n",
    "        visualize_pnr_results,\n",
    "        save_trace_data\n",
    "    )\n",
    "    from modules.analysis import (\n",
    "        analyze_fluorescence, \n",
    "        perform_qc_checks,\n",
    "        extract_peak_parameters,\n",
    "        extract_spontaneous_activity,\n",
    "        calculate_baseline_excluding_peaks\n",
    "    )\n",
    "    from modules.visualization import generate_visualizations\n",
    "    from modules.utils import setup_logging, save_slice_data, save_mouse_summary\n",
    "    \n",
    "    # Try importing advanced analysis module if available\n",
    "    try:\n",
    "        from modules.advanced_analysis import run_advanced_analysis\n",
    "        ADVANCED_ANALYSIS_AVAILABLE = True\n",
    "    except ImportError:\n",
    "        ADVANCED_ANALYSIS_AVAILABLE = False\n",
    "        print(\"Advanced analysis module not available. Some features will be disabled.\")\n",
    "    \n",
    "    print(\"Successfully imported all modules\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing modules: {e}\")\n",
    "    print(\"Make sure the required modules are in the 'modules' directory or adjust the import path.\")\n",
    "    \n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c8ee16-b57e-4d0f-9a81-cda83e806d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    \"\"\"Class to simulate command line arguments\"\"\"\n",
    "    def __init__(self):\n",
    "        self.input_dir = r\"F:\\Recovered\\Research\\BoninLab\\PainModelingProject\\calcium_imaging_data\\CAAR Testing\\CAAR part2 data\\paclitaxel\\Pac_25_contra\"  # CHANGE THIS\n",
    "        self.output_dir = r\"F:\\Recovered\\Research\\BoninLab\\PainModelingProject\\calcium_imaging_data\\CAAR Testing\\CUMIN output\\CUMIN_49_optimized13_bgtweaks\"   # CHANGE THIS\n",
    "        self.config = \"../config.yaml\"  # Make sure this points to your config file\n",
    "        self.mode = \"all\"  # Options: \"all\", \"preprocess\", \"extract\", \"analyze\"\n",
    "        self.max_workers = 4  # Adjust based on your CPU cores\n",
    "        self.disable_advanced = False\n",
    "\n",
    "# Create args object\n",
    "args = Args()\n",
    "\n",
    "# Create interactive widgets for adjusting parameters\n",
    "input_dir_widget = widgets.Text(\n",
    "    value=args.input_dir,\n",
    "    description='Input Directory:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "output_dir_widget = widgets.Text(\n",
    "    value=args.output_dir,\n",
    "    description='Output Directory:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "config_widget = widgets.Text(\n",
    "    value=args.config,\n",
    "    description='Config File:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "mode_widget = widgets.Dropdown(\n",
    "    options=['all', 'preprocess', 'extract', 'analyze'],\n",
    "    value=args.mode,\n",
    "    description='Pipeline Mode:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "workers_widget = widgets.IntSlider(\n",
    "    value=args.max_workers,\n",
    "    min=1,\n",
    "    max=12,\n",
    "    step=1,\n",
    "    description='Max Workers:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "disable_advanced_widget = widgets.Checkbox(\n",
    "    value=args.disable_advanced,\n",
    "    description='Disable Advanced Analysis',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Function to update args object based on widget values\n",
    "def update_args():\n",
    "    args.input_dir = input_dir_widget.value\n",
    "    args.output_dir = output_dir_widget.value\n",
    "    args.config = config_widget.value\n",
    "    args.mode = mode_widget.value\n",
    "    args.max_workers = workers_widget.value\n",
    "    args.disable_advanced = disable_advanced_widget.value\n",
    "    print(\"Parameters updated:\")\n",
    "    print(f\"Input Directory: {args.input_dir}\")\n",
    "    print(f\"Output Directory: {args.output_dir}\")\n",
    "    print(f\"Config File: {args.config}\")\n",
    "    print(f\"Pipeline Mode: {args.mode}\")\n",
    "    print(f\"Max Workers: {args.max_workers}\")\n",
    "    print(f\"Disable Advanced Analysis: {args.disable_advanced}\")\n",
    "\n",
    "# Create update button\n",
    "update_button = widgets.Button(\n",
    "    description='Update Parameters',\n",
    "    button_style='info',\n",
    "    tooltip='Click to update parameters'\n",
    ")\n",
    "\n",
    "update_button.on_click(lambda b: update_args())\n",
    "\n",
    "# Display widgets\n",
    "display(input_dir_widget)\n",
    "display(output_dir_widget)\n",
    "display(config_widget)\n",
    "display(mode_widget)\n",
    "display(workers_widget)\n",
    "display(disable_advanced_widget)\n",
    "display(update_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9668ef-e59f-4586-a08e-46766665ba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_path, args=None):\n",
    "    \"\"\"Load configuration from YAML file and apply command line overrides.\"\"\"\n",
    "    try:\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        print(f\"Loaded configuration from {config_path}\")\n",
    "        \n",
    "        # Apply command line overrides if provided\n",
    "        if args and args.disable_advanced:\n",
    "            # Disable advanced analysis if requested via command line\n",
    "            if \"advanced_analysis\" in config:\n",
    "                config[\"advanced_analysis\"][\"enabled\"] = False\n",
    "                print(\"Advanced analysis disabled via command line argument\")\n",
    "        \n",
    "        return config\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load configuration: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Setup logging\n",
    "logger = setup_logging()\n",
    "\n",
    "# Load configuration\n",
    "config = load_config(args.config, args)\n",
    "\n",
    "if config:\n",
    "    print(\"Configuration loaded successfully.\")\n",
    "    \n",
    "    # Create a backup of original config for reference\n",
    "    config_original = copy.deepcopy(config)\n",
    "else:\n",
    "    print(\"Failed to load configuration. Please check the config file path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4cd60a-aaf1-4e15-bc3a-05f38c3f281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find matching TIF and ROI file pairs\n",
    "print(f\"Finding file pairs in {args.input_dir}...\")\n",
    "file_pairs = match_tif_and_roi_files(args.input_dir, logger)\n",
    "print(f\"Found {len(file_pairs)} matched file pairs\")\n",
    "\n",
    "# Create widgets to select a file pair for analysis\n",
    "pair_names = [f\"{i+1}: {Path(tif).stem}\" for i, (tif, roi) in enumerate(file_pairs)]\n",
    "file_pair_dropdown = widgets.Dropdown(\n",
    "    options=list(zip(pair_names, range(len(file_pairs)))),\n",
    "    description='Select File Pair:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "def on_select_change(change):\n",
    "    index = change['new']\n",
    "    tif_path, roi_path = file_pairs[index]\n",
    "    print(f\"Selected file pair {index+1}:\")\n",
    "    print(f\"TIF: {tif_path}\")\n",
    "    print(f\"ROI: {roi_path}\")\n",
    "\n",
    "file_pair_dropdown.observe(on_select_change, names='value')\n",
    "\n",
    "# Display the dropdown\n",
    "display(file_pair_dropdown)\n",
    "\n",
    "# Create a button to load the selected file pair\n",
    "load_button = widgets.Button(\n",
    "    description='Load Selected File Pair',\n",
    "    button_style='success',\n",
    "    tooltip='Click to load the selected file pair for analysis'\n",
    ")\n",
    "\n",
    "def on_load_button_click(b):\n",
    "    global selected_tif_path, selected_roi_path, image_data, image_shape\n",
    "    index = file_pair_dropdown.value\n",
    "    selected_tif_path, selected_roi_path = file_pairs[index]\n",
    "    \n",
    "    print(f\"Loading file pair {index+1}:\")\n",
    "    print(f\"TIF: {selected_tif_path}\")\n",
    "    print(f\"ROI: {selected_roi_path}\")\n",
    "    \n",
    "    # Load image data\n",
    "    try:\n",
    "        print(\"Loading image data...\")\n",
    "        with tifffile.TiffFile(selected_tif_path) as tif:\n",
    "            image_data = tif.asarray()\n",
    "            \n",
    "            # Check dimensions - some TIFFs may be in TZYX format\n",
    "            if len(image_data.shape) > 3:\n",
    "                # Assume TZYX format and take first channel\n",
    "                print(f\"Detected {len(image_data.shape)}D data, reshaping\")\n",
    "                if len(image_data.shape) == 4:  # TZYX\n",
    "                    image_data = image_data[:, 0] if image_data.shape[1] < image_data.shape[0] else image_data[0]\n",
    "                elif len(image_data.shape) == 5:  # TZCYX\n",
    "                    image_data = image_data[:, 0, 0] if image_data.shape[1] < image_data.shape[0] else image_data[0, 0]\n",
    "            \n",
    "            # Ensure data is in (frames, height, width) format\n",
    "            if len(image_data.shape) == 3:\n",
    "                if image_data.shape[0] < image_data.shape[1] and image_data.shape[0] < image_data.shape[2]:\n",
    "                    # Already in (frames, height, width) format\n",
    "                    pass\n",
    "                else:\n",
    "                    # Try to rearrange to (frames, height, width)\n",
    "                    if image_data.shape[2] < image_data.shape[0] and image_data.shape[2] < image_data.shape[1]:\n",
    "                        image_data = np.moveaxis(image_data, 2, 0)\n",
    "                    elif image_data.shape[1] < image_data.shape[0] and image_data.shape[1] < image_data.shape[2]:\n",
    "                        image_data = np.moveaxis(image_data, 1, 0)\n",
    "        \n",
    "        n_frames, height, width = image_data.shape\n",
    "        image_shape = (height, width)\n",
    "        \n",
    "        print(f\"Image loaded successfully with shape: {image_data.shape}\")\n",
    "        print(f\"Number of frames: {n_frames}\")\n",
    "        print(f\"Frame dimensions: {height}x{width}\")\n",
    "        \n",
    "        # Convert to float32 if needed\n",
    "        if image_data.dtype != np.float32:\n",
    "            image_data = image_data.astype(np.float32)\n",
    "            print(\"Converted data to float32\")\n",
    "        \n",
    "        # Extract metadata from filename\n",
    "        slice_name = Path(selected_tif_path).stem\n",
    "        metadata = extract_metadata_from_filename(slice_name)\n",
    "        print(f\"Extracted metadata: {metadata}\")\n",
    "        \n",
    "        # Extract ROI masks for visualization\n",
    "        global roi_masks, roi_centers\n",
    "        roi_masks, roi_centers = extract_rois_from_zip(selected_roi_path, image_shape, logger)\n",
    "        print(f\"Extracted {len(roi_masks)} ROI masks\")\n",
    "        \n",
    "        # Create output directory for this slice\n",
    "        global slice_output_dir\n",
    "        slice_output_dir = os.path.join(args.output_dir, slice_name)\n",
    "        os.makedirs(slice_output_dir, exist_ok=True)\n",
    "        print(f\"Created output directory: {slice_output_dir}\")\n",
    "        \n",
    "        # Run initial preprocessing to set up visualization data\n",
    "        print(\"Performing initial preprocessing for visualization...\")\n",
    "        global corrected_data\n",
    "        corrected_data, _ = correct_photobleaching(\n",
    "            image_data,\n",
    "            None,  # No output file needed for visualization\n",
    "            config[\"preprocessing\"],\n",
    "            logger,\n",
    "            save_output=False\n",
    "        )\n",
    "        print(\"Initial preprocessing complete\")\n",
    "        \n",
    "        # Extract ROI fluorescence for visualization\n",
    "        global roi_data\n",
    "        _, roi_data = extract_roi_fluorescence(\n",
    "            selected_roi_path,\n",
    "            corrected_data,\n",
    "            image_shape,\n",
    "            slice_output_dir,\n",
    "            config[\"roi_processing\"],\n",
    "            logger\n",
    "        )\n",
    "        print(f\"Extracted fluorescence traces for {len(roi_masks)} ROIs\")\n",
    "        \n",
    "        # Save visualization data for later use\n",
    "        vis_data = {\n",
    "            'image_data': image_data,\n",
    "            'corrected_data': corrected_data,\n",
    "            'roi_masks': roi_masks,\n",
    "            'roi_centers': roi_centers,\n",
    "            'roi_data': roi_data,\n",
    "            'metadata': metadata,\n",
    "            'selected_tif_path': selected_tif_path,\n",
    "            'selected_roi_path': selected_roi_path,\n",
    "            'image_shape': image_shape\n",
    "        }\n",
    "        \n",
    "        # Save visualization data\n",
    "        vis_data_file = os.path.join(slice_output_dir, \"visualization_data.pkl\")\n",
    "        with open(vis_data_file, 'wb') as f:\n",
    "            pickle.dump(vis_data, f)\n",
    "            \n",
    "        print(f\"Saved visualization data to {vis_data_file}\")\n",
    "        print(\"Data loaded successfully and ready for visualization!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading files: {str(e)}\")\n",
    "\n",
    "load_button.on_click(on_load_button_click)\n",
    "display(load_button)\n",
    "\n",
    "# Define extract_metadata_from_filename function (copied from your utils module)\n",
    "def extract_metadata_from_filename(filename):\n",
    "    \"\"\"Extract metadata from custom filename pattern 'CFA1_7.23.20_ipsi1_0um'.\"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Initialize metadata dictionary\n",
    "    metadata = {\n",
    "        \"mouse_id\": \"unknown\",\n",
    "        \"date\": \"unknown\",\n",
    "        \"pain_model\": \"unknown\",\n",
    "        \"slice_type\": \"unknown\",\n",
    "        \"slice_number\": \"1\",\n",
    "        \"condition\": \"unknown\"\n",
    "    }\n",
    "    \n",
    "    # Split filename by underscore\n",
    "    parts = filename.split('_')\n",
    "    \n",
    "    if len(parts) < 3:\n",
    "        return metadata\n",
    "    \n",
    "    # First part typically contains pain model + mouse number (e.g., \"CFA1\")\n",
    "    if parts[0]:\n",
    "        # Extract pain model (letters) and mouse number (digits)\n",
    "        model_match = re.match(r'([A-Za-z]+)([0-9]*)', parts[0])\n",
    "        if model_match:\n",
    "            metadata[\"pain_model\"] = model_match.group(1)\n",
    "            mouse_number = model_match.group(2) or \"1\"\n",
    "            metadata[\"mouse_id\"] = f\"{metadata['pain_model']}{mouse_number}\"\n",
    "        else:\n",
    "            metadata[\"mouse_id\"] = parts[0]\n",
    "    \n",
    "    # Second part is usually the date\n",
    "    if len(parts) > 1:\n",
    "        metadata[\"date\"] = parts[1]\n",
    "    \n",
    "    # Third part usually contains slice type and number\n",
    "    if len(parts) > 2:\n",
    "        # Look for ipsi/contra with optional number\n",
    "        slice_match = re.match(r'(ipsi|contra)([0-9]*)', parts[2].lower())\n",
    "        if slice_match:\n",
    "            metadata[\"slice_type\"] = slice_match.group(1).capitalize()  # Capitalize first letter\n",
    "            metadata[\"slice_number\"] = slice_match.group(2) or \"1\"\n",
    "    \n",
    "    # Last part usually has the condition\n",
    "    for part in parts:\n",
    "        if any(cond in part.lower() for cond in [\"0um\", \"10um\", \"25um\"]):\n",
    "            metadata[\"condition\"] = part\n",
    "            break\n",
    "    \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2258a637-239a-4067-8418-6f905e330cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_visualization_data(data_file):\n",
    "    \"\"\"Load saved visualization data from pickle file\"\"\"\n",
    "    try:\n",
    "        with open(data_file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Assign to global variables for use in visualizations\n",
    "        global image_data, corrected_data, roi_masks, roi_centers, roi_data, metadata, selected_tif_path, selected_roi_path, image_shape\n",
    "        image_data = data['image_data']\n",
    "        corrected_data = data['corrected_data']\n",
    "        roi_masks = data['roi_masks']\n",
    "        roi_centers = data['roi_centers']\n",
    "        roi_data = data['roi_data']\n",
    "        metadata = data['metadata']\n",
    "        selected_tif_path = data['selected_tif_path']\n",
    "        selected_roi_path = data['selected_roi_path']\n",
    "        image_shape = data['image_shape']\n",
    "        \n",
    "        print(\"Visualization data loaded successfully!\")\n",
    "        print(f\"File: {Path(selected_tif_path).stem}\")\n",
    "        print(f\"Image shape: {image_data.shape}\")\n",
    "        print(f\"Number of ROIs: {len(roi_masks)}\")\n",
    "        print(f\"Condition: {metadata.get('condition', 'unknown')}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading visualization data: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Widget to select a visualization data file\n",
    "load_vis_data_button = widgets.Button(\n",
    "    description='Load Saved Visualization Data',\n",
    "    button_style='info',\n",
    "    tooltip='Load previously saved visualization data'\n",
    ")\n",
    "\n",
    "vis_data_path_widget = widgets.Text(\n",
    "    placeholder='Enter path to visualization_data.pkl file',\n",
    "    description='Data File:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "def on_load_vis_data_click(b):\n",
    "    path = vis_data_path_widget.value\n",
    "    if path:\n",
    "        success = load_visualization_data(path)\n",
    "        if success:\n",
    "            print(\"Ready for visualization!\")\n",
    "    else:\n",
    "        print(\"Please enter a valid path to the visualization_data.pkl file\")\n",
    "\n",
    "load_vis_data_button.on_click(on_load_vis_data_click)\n",
    "\n",
    "display(vis_data_path_widget)\n",
    "display(load_vis_data_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506e3df6-8508-4dfa-a6e5-5d120abb3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaussian_denoising_visualization():\n",
    "    \"\"\"Create interactive visualization for Gaussian denoising\"\"\"\n",
    "    try:\n",
    "        # Check if image data is loaded\n",
    "        if 'image_data' not in globals() or image_data is None:\n",
    "            print(\"Please load image data first\")\n",
    "            return\n",
    "        \n",
    "        # Get a sample frame\n",
    "        frame_idx_slider = widgets.IntSlider(\n",
    "            value=10,\n",
    "            min=0,\n",
    "            max=min(image_data.shape[0]-1, 100),  # Limit to 100 frames for performance\n",
    "            step=1,\n",
    "            description='Frame:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Create widgets for Gaussian denoising parameters\n",
    "        ksize_slider = widgets.IntSlider(\n",
    "            value=5,\n",
    "            min=1,\n",
    "            max=21,\n",
    "            step=2,  # Must be odd number\n",
    "            description='Kernel Size:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        sigmaX_slider = widgets.FloatSlider(\n",
    "            value=1.5,\n",
    "            min=0.1,\n",
    "            max=10.0,\n",
    "            step=0.1,\n",
    "            description='Sigma X:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Normalize frame for display\n",
    "        def normalize_for_display(img):\n",
    "            img_min = img.min()\n",
    "            img_max = img.max()\n",
    "            if img_max > img_min:\n",
    "                return (img - img_min) / (img_max - img_min)\n",
    "            return img\n",
    "        \n",
    "        # Define the display function\n",
    "        def display_denoising(frame_idx, ksize, sigmaX):\n",
    "            # Ensure ksize is odd\n",
    "            if ksize % 2 == 0:\n",
    "                ksize += 1\n",
    "                \n",
    "            # Get the selected frame\n",
    "            sample_frame = image_data[frame_idx].copy()\n",
    "            \n",
    "            # Apply Gaussian denoising\n",
    "            denoised_frame = cv2.GaussianBlur(sample_frame, (ksize, ksize), sigmaX)\n",
    "            \n",
    "            # Display original vs denoised\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "            \n",
    "            # Display original frame\n",
    "            axes[0].imshow(normalize_for_display(sample_frame), cmap='gray')\n",
    "            axes[0].set_title('Original Frame')\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            # Display denoised frame\n",
    "            axes[1].imshow(normalize_for_display(denoised_frame), cmap='gray')\n",
    "            axes[1].set_title(f'Gaussian Denoised (k={ksize}, σ={sigmaX:.1f})')\n",
    "            axes[1].axis('off')\n",
    "            \n",
    "            # Display difference\n",
    "            diff = np.abs(sample_frame - denoised_frame)\n",
    "            axes[2].imshow(normalize_for_display(diff), cmap='hot')\n",
    "            axes[2].set_title('Difference (Red=More Change)')\n",
    "            axes[2].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Update config with current values (for reference)\n",
    "            if 'denoise' not in config['preprocessing']:\n",
    "                config['preprocessing']['denoise'] = {}\n",
    "            \n",
    "            config['preprocessing']['denoise']['enabled'] = True\n",
    "            config['preprocessing']['denoise']['method'] = 'gaussian'\n",
    "            config['preprocessing']['denoise']['params'] = {\n",
    "                'ksize': [ksize, ksize],\n",
    "                'sigmaX': sigmaX\n",
    "            }\n",
    "            \n",
    "            print(f\"Updated config with: ksize={ksize}, sigmaX={sigmaX}\")\n",
    "            print(\"To apply these settings to your pipeline, update your config.yaml file.\")\n",
    "        \n",
    "        # Create interactive widget\n",
    "        interactive_plot = interactive(\n",
    "            display_denoising,\n",
    "            frame_idx=frame_idx_slider,\n",
    "            ksize=ksize_slider,\n",
    "            sigmaX=sigmaX_slider\n",
    "        )\n",
    "        \n",
    "        # Display the interactive widget\n",
    "        display(interactive_plot)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating Gaussian denoising visualization: {str(e)}\")\n",
    "        \n",
    "# Create a button to launch the visualization\n",
    "gaussian_denoising_button = widgets.Button(\n",
    "    description='Launch Gaussian Denoising Visualization',\n",
    "    button_style='primary',\n",
    "    tooltip='Click to launch interactive visualization for Gaussian denoising'\n",
    ")\n",
    "\n",
    "gaussian_denoising_button.on_click(lambda b: create_gaussian_denoising_visualization())\n",
    "display(gaussian_denoising_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b150b-8b5e-4dfb-8de6-422b8421312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n## Interactive ROI Processing with PNR Refinement ##\")\n",
    "\n",
    "def create_pnr_refinement_visualization():\n",
    "    \"\"\"Create interactive visualization for PNR refinement\"\"\"\n",
    "    try:\n",
    "        # Check if ROI data is loaded\n",
    "        if 'roi_data' not in globals() or roi_data is None:\n",
    "            print(\"Please load ROI data first\")\n",
    "            return\n",
    "        \n",
    "        # Create widgets for PNR refinement parameters\n",
    "        noise_freq_cutoff_slider = widgets.FloatSlider(\n",
    "            value=0.03,\n",
    "            min=0.01,\n",
    "            max=0.2,\n",
    "            step=0.01,\n",
    "            description='Noise Freq Cutoff:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        percentile_threshold_slider = widgets.FloatSlider(\n",
    "            value=99,\n",
    "            min=90,\n",
    "            max=99.9,\n",
    "            step=0.1,\n",
    "            description='Percentile Threshold:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        trace_smoothing_slider = widgets.IntSlider(\n",
    "            value=3,\n",
    "            min=0,\n",
    "            max=15,\n",
    "            step=1,\n",
    "            description='Trace Smoothing:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        min_pnr_slider = widgets.FloatSlider(\n",
    "            value=8.0,\n",
    "            min=3.0,\n",
    "            max=20.0,\n",
    "            step=0.5,\n",
    "            description='Min PNR:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Widget to select ROIs to display\n",
    "        roi_selector = widgets.SelectMultiple(\n",
    "            options=[(f\"ROI {i+1}\", i) for i in range(min(10, len(roi_data)))],\n",
    "            value=[0, 1, 2],  # Default: first 3 ROIs\n",
    "            description='ROIs to Display:',\n",
    "            disabled=False,\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Define the display function\n",
    "        def display_pnr_refinement(noise_freq_cutoff, percentile_threshold, trace_smoothing, min_pnr, roi_indices):\n",
    "            if not roi_indices:\n",
    "                print(\"Please select at least one ROI to display\")\n",
    "                return\n",
    "                \n",
    "            # Split traces into signal and noise components\n",
    "            sample_traces = roi_data[list(roi_indices)]\n",
    "            signal_traces, noise_traces = split_signal_noise(sample_traces, noise_freq_cutoff, logger)\n",
    "            \n",
    "            # Apply smoothing if enabled\n",
    "            if trace_smoothing > 0:\n",
    "                smoothed_signal = np.zeros_like(signal_traces)\n",
    "                for i in range(len(signal_traces)):\n",
    "                    window = np.ones(trace_smoothing) / trace_smoothing\n",
    "                    smoothed_signal[i] = np.convolve(signal_traces[i], window, mode='same')\n",
    "            else:\n",
    "                smoothed_signal = signal_traces\n",
    "            \n",
    "            # Compute PNR values\n",
    "            pnr_values = np.zeros(len(roi_indices))\n",
    "            for i in range(len(roi_indices)):\n",
    "                # Get peak value (using percentile)\n",
    "                peak_value = np.percentile(smoothed_signal[i], percentile_threshold)\n",
    "                \n",
    "                # Calculate noise standard deviation\n",
    "                noise_std = np.std(noise_traces[i])\n",
    "                \n",
    "                # Avoid division by zero\n",
    "                if noise_std > 0:\n",
    "                    pnr_values[i] = peak_value / noise_std\n",
    "                else:\n",
    "                    pnr_values[i] = 0\n",
    "            \n",
    "            # Display traces and PNR values\n",
    "            n_rois = len(roi_indices)\n",
    "            fig, axes = plt.subplots(n_rois, 3, figsize=(15, 4*n_rois))\n",
    "            \n",
    "            # Handle single ROI case\n",
    "            if n_rois == 1:\n",
    "                axes = np.array([axes])\n",
    "            \n",
    "            for i, roi_idx in enumerate(roi_indices):\n",
    "                # Original trace\n",
    "                axes[i, 0].plot(roi_data[roi_idx], 'k-', label=f'Original')\n",
    "                axes[i, 0].set_title(f'ROI {roi_idx+1} - Original Trace')\n",
    "                axes[i, 0].set_xlabel('Frame')\n",
    "                axes[i, 0].set_ylabel('Fluorescence')\n",
    "                axes[i, 0].grid(True, alpha=0.3)\n",
    "                \n",
    "                # Signal component\n",
    "                axes[i, 1].plot(signal_traces[i], 'g-', label='Signal')\n",
    "                if trace_smoothing > 0:\n",
    "                    axes[i, 1].plot(smoothed_signal[i], 'r-', label='Smoothed Signal')\n",
    "                axes[i, 1].set_title(f'Signal Component (cutoff={noise_freq_cutoff})')\n",
    "                axes[i, 1].set_xlabel('Frame')\n",
    "                axes[i, 1].set_ylabel('Fluorescence')\n",
    "                axes[i, 1].grid(True, alpha=0.3)\n",
    "                axes[i, 1].legend()\n",
    "                \n",
    "                # Noise component\n",
    "                axes[i, 2].plot(noise_traces[i], 'b-', label='Noise')\n",
    "                axes[i, 2].set_title(f'Noise Component (PNR={pnr_values[i]:.2f})')\n",
    "                axes[i, 2].set_xlabel('Frame')\n",
    "                axes[i, 2].set_ylabel('Fluorescence')\n",
    "                axes[i, 2].grid(True, alpha=0.3)\n",
    "                \n",
    "                # Add PNR threshold line and indication if the ROI passes the threshold\n",
    "                axes[i, 2].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "                if pnr_values[i] >= min_pnr:\n",
    "                    status = \"PASS\"\n",
    "                    color = 'green'\n",
    "                else:\n",
    "                    status = \"FAIL\"\n",
    "                    color = 'red'\n",
    "                \n",
    "                axes[i, 2].text(0.05, 0.95, f\"PNR: {pnr_values[i]:.2f} ({status})\", \n",
    "                                transform=axes[i, 2].transAxes, \n",
    "                                fontsize=10, va='top', ha='left',\n",
    "                                bbox=dict(facecolor=color, alpha=0.3))\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Display summary\n",
    "            n_pass = sum(pnr >= min_pnr for pnr in pnr_values)\n",
    "            print(f\"PNR Summary: {n_pass}/{len(roi_indices)} selected ROIs pass the threshold (>= {min_pnr})\")\n",
    "            \n",
    "            # Update config with current values (for reference)\n",
    "            if 'pnr_refinement' not in config['roi_processing']:\n",
    "                config['roi_processing']['pnr_refinement'] = {}\n",
    "            \n",
    "            config['roi_processing']['pnr_refinement']['noise_freq_cutoff'] = noise_freq_cutoff\n",
    "            config['roi_processing']['pnr_refinement']['min_pnr'] = min_pnr\n",
    "            config['roi_processing']['pnr_refinement']['percentile_threshold'] = percentile_threshold\n",
    "            config['roi_processing']['pnr_refinement']['trace_smoothing'] = trace_smoothing\n",
    "            \n",
    "            print(f\"Updated config with: noise_freq_cutoff={noise_freq_cutoff}, min_pnr={min_pnr}\")\n",
    "            print(f\"percentile_threshold={percentile_threshold}, trace_smoothing={trace_smoothing}\")\n",
    "            print(\"To apply these settings to your pipeline, update your config.yaml file.\")\n",
    "        \n",
    "        # Create interactive widget\n",
    "        interactive_plot = interactive(\n",
    "            display_pnr_refinement,\n",
    "            noise_freq_cutoff=noise_freq_cutoff_slider,\n",
    "            percentile_threshold=percentile_threshold_slider,\n",
    "            trace_smoothing=trace_smoothing_slider,\n",
    "            min_pnr=min_pnr_slider,\n",
    "            roi_indices=roi_selector\n",
    "        )\n",
    "        \n",
    "        # Display the interactive widget\n",
    "        display(interactive_plot)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating PNR refinement visualization: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "# Create a button to launch the visualization\n",
    "pnr_refinement_button = widgets.Button(\n",
    "    description='Launch PNR Refinement Visualization',\n",
    "    button_style='primary',\n",
    "    tooltip='Click to launch interactive visualization for PNR refinement'\n",
    ")\n",
    "\n",
    "pnr_refinement_button.on_click(lambda b: create_pnr_refinement_visualization())\n",
    "display(pnr_refinement_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb19c4-7941-4fc6-9c41-18b7dad2097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n## Interactive Background Subtraction Visualization ##\")\n",
    "\n",
    "def create_background_subtraction_visualization():\n",
    "    \"\"\"Create interactive visualization for background subtraction\"\"\"\n",
    "    try:\n",
    "        # Check if necessary data is loaded\n",
    "        if 'roi_data' not in globals() or 'image_data' not in globals() or 'roi_masks' not in globals():\n",
    "            print(\"Please load image data, ROI data and masks first\")\n",
    "            return\n",
    "        \n",
    "        # Create widgets for background subtraction parameters\n",
    "        bg_method_selector = widgets.Dropdown(\n",
    "            options=[\n",
    "                ('Darkest Pixels', 'darkest_pixels'), \n",
    "                ('ROI Periphery', 'roi_periphery'),\n",
    "                ('Global Background', 'global_background')\n",
    "            ],\n",
    "            value='darkest_pixels',\n",
    "            description='Method:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        percentile_slider = widgets.FloatSlider(\n",
    "            value=0.2,\n",
    "            min=0.1,\n",
    "            max=10.0,\n",
    "            step=0.1,\n",
    "            description='Percentile (%):',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        min_bg_area_slider = widgets.IntSlider(\n",
    "            value=200,\n",
    "            min=50,\n",
    "            max=1000,\n",
    "            step=50,\n",
    "            description='Min Background Area:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        median_filter_slider = widgets.IntSlider(\n",
    "            value=5,\n",
    "            min=0,\n",
    "            max=15,\n",
    "            step=2,\n",
    "            description='Median Filter Size:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        periphery_size_slider = widgets.IntSlider(\n",
    "            value=2,\n",
    "            min=1,\n",
    "            max=10,\n",
    "            step=1,\n",
    "            description='Periphery Size:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Widget to select ROIs to display\n",
    "        roi_selector = widgets.SelectMultiple(\n",
    "            options=[(f\"ROI {i+1}\", i) for i in range(min(10, len(roi_data)))],\n",
    "            value=[0, 1, 2],  # Default: first 3 ROIs\n",
    "            description='ROIs to Display:',\n",
    "            disabled=False,\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Define the display function\n",
    "        def display_background_subtraction(bg_method, percentile, min_bg_area, median_filter_size, periphery_size, roi_indices):\n",
    "            if not roi_indices:\n",
    "                print(\"Please select at least one ROI to display\")\n",
    "                return\n",
    "            \n",
    "            # Create configuration for background subtraction\n",
    "            bg_config = {\n",
    "                \"method\": bg_method,\n",
    "                \"percentile\": percentile,\n",
    "                \"min_background_area\": min_bg_area,\n",
    "                \"median_filter_size\": median_filter_size,\n",
    "                \"periphery_size\": periphery_size\n",
    "            }\n",
    "            \n",
    "            # Get ROI data for selected ROIs\n",
    "            selected_roi_data = roi_data[list(roi_indices)]\n",
    "            selected_roi_masks = [roi_masks[i] for i in roi_indices]\n",
    "            \n",
    "            # Apply background subtraction\n",
    "            if bg_method == 'global_background':\n",
    "                bg_corrected_data = subtract_global_background(\n",
    "                    image_data, \n",
    "                    selected_roi_data,\n",
    "                    selected_roi_masks,\n",
    "                    bg_config,\n",
    "                    logger\n",
    "                )\n",
    "            else:\n",
    "                bg_corrected_data = subtract_background(\n",
    "                    image_data, \n",
    "                    selected_roi_data,\n",
    "                    selected_roi_masks,\n",
    "                    bg_config,\n",
    "                    logger\n",
    "                )\n",
    "            \n",
    "            # Display original vs background-corrected traces\n",
    "            n_rois = len(roi_indices)\n",
    "            fig, axes = plt.subplots(n_rois, 2, figsize=(15, 4*n_rois))\n",
    "            \n",
    "            # Handle single ROI case\n",
    "            if n_rois == 1:\n",
    "                axes = np.array([axes])\n",
    "            \n",
    "            for i, roi_idx in enumerate(roi_indices):\n",
    "                # Original trace\n",
    "                axes[i, 0].plot(selected_roi_data[i], 'k-', label=f'Original')\n",
    "                axes[i, 0].set_title(f'ROI {roi_idx+1} - Original Trace')\n",
    "                axes[i, 0].set_xlabel('Frame')\n",
    "                axes[i, 0].set_ylabel('Fluorescence')\n",
    "                axes[i, 0].grid(True, alpha=0.3)\n",
    "                \n",
    "                # Background-corrected trace\n",
    "                axes[i, 1].plot(bg_corrected_data[i], 'g-', label='Background Corrected')\n",
    "                axes[i, 1].set_title(f'Background Corrected ({bg_method})')\n",
    "                axes[i, 1].set_xlabel('Frame')\n",
    "                axes[i, 1].set_ylabel('Fluorescence')\n",
    "                axes[i, 1].grid(True, alpha=0.3)\n",
    "                \n",
    "                # Add zero line for reference\n",
    "                axes[i, 1].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Visualize background mask (for darkest_pixels method)\n",
    "            if bg_method == 'darkest_pixels':\n",
    "                # Create darkest pixels mask\n",
    "                avg_intensity = np.mean(image_data, axis=0)\n",
    "                threshold = np.percentile(avg_intensity, percentile)\n",
    "                darkest_pixels_mask = avg_intensity <= threshold\n",
    "                \n",
    "                # Apply median filter to remove noise\n",
    "                if median_filter_size > 0:\n",
    "                    darkest_pixels_mask = median_filter(darkest_pixels_mask.astype(float), \n",
    "                                                       size=median_filter_size) > 0.5\n",
    "                \n",
    "                # Create a visualization of the background mask\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "                \n",
    "                # Display average intensity image\n",
    "                axes[0].imshow(normalize_for_display(avg_intensity), cmap='gray')\n",
    "                axes[0].set_title('Average Intensity')\n",
    "                axes[0].axis('off')\n",
    "                \n",
    "                # Display background mask\n",
    "                axes[1].imshow(darkest_pixels_mask, cmap='hot')\n",
    "                axes[1].set_title(f'Background Mask (percentile={percentile}%)')\n",
    "                axes[1].axis('off')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            \n",
    "            # Visualize ROI periphery (for roi_periphery method)\n",
    "            elif bg_method == 'roi_periphery' and n_rois > 0:\n",
    "                # Create periphery mask for the first selected ROI\n",
    "                first_roi_idx = roi_indices[0]\n",
    "                mask = roi_masks[first_roi_idx]\n",
    "                expanded_mask = binary_dilation(mask, iterations=periphery_size)\n",
    "                periphery_mask = expanded_mask & ~mask\n",
    "                \n",
    "                # Create a visualization of the ROI periphery\n",
    "                fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                \n",
    "                # Get first frame for background display\n",
    "                first_frame = image_data[0]\n",
    "                \n",
    "                # Display original ROI\n",
    "                axes[0].imshow(normalize_for_display(first_frame), cmap='gray')\n",
    "                axes[0].imshow(mask, cmap='hot', alpha=0.5)\n",
    "                axes[0].set_title(f'ROI {first_roi_idx+1} Mask')\n",
    "                axes[0].axis('off')\n",
    "                \n",
    "                # Display expanded ROI\n",
    "                axes[1].imshow(normalize_for_display(first_frame), cmap='gray')\n",
    "                axes[1].imshow(expanded_mask, cmap='hot', alpha=0.5)\n",
    "                axes[1].set_title(f'Expanded Mask (periphery={periphery_size})')\n",
    "                axes[1].axis('off')\n",
    "                \n",
    "                # Display periphery only\n",
    "                axes[2].imshow(normalize_for_display(first_frame), cmap='gray')\n",
    "                axes[2].imshow(periphery_mask, cmap='hot', alpha=0.5)\n",
    "                axes[2].set_title('Periphery Mask (for background)')\n",
    "                axes[2].axis('off')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            \n",
    "            # Update config with current values\n",
    "            if 'background' not in config['roi_processing']:\n",
    "                config['roi_processing']['background'] = {}\n",
    "            \n",
    "            config['roi_processing']['background']['method'] = bg_method\n",
    "            config['roi_processing']['background']['percentile'] = percentile\n",
    "            config['roi_processing']['background']['min_background_area'] = min_bg_area\n",
    "            config['roi_processing']['background']['median_filter_size'] = median_filter_size\n",
    "            config['roi_processing']['background']['periphery_size'] = periphery_size\n",
    "            \n",
    "            print(f\"Updated config with: method={bg_method}, percentile={percentile}\")\n",
    "            print(f\"min_background_area={min_bg_area}, median_filter_size={median_filter_size}\")\n",
    "            print(f\"periphery_size={periphery_size}\")\n",
    "            print(\"To apply these settings to your pipeline, update your config.yaml file.\")\n",
    "        \n",
    "        # Create interactive widget\n",
    "        interactive_plot = interactive(\n",
    "            display_background_subtraction,\n",
    "            bg_method=bg_method_selector,\n",
    "            percentile=percentile_slider,\n",
    "            min_bg_area=min_bg_area_slider,\n",
    "            median_filter_size=median_filter_slider,\n",
    "            periphery_size=periphery_size_slider,\n",
    "            roi_indices=roi_selector\n",
    "        )\n",
    "        \n",
    "        # Display the interactive widget\n",
    "        display(interactive_plot)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating background subtraction visualization: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "# Create a button to launch the visualization\n",
    "bg_subtraction_button = widgets.Button(\n",
    "    description='Launch Background Subtraction Visualization',\n",
    "    button_style='primary',\n",
    "    tooltip='Click to launch interactive visualization for background subtraction'\n",
    ")\n",
    "\n",
    "bg_subtraction_button.on_click(lambda b: create_background_subtraction_visualization())\n",
    "display(bg_subtraction_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d68a5-5ddc-4878-95b9-d00c48d4e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n## Interactive Event Detection and Analysis Visualization ##\")\n",
    "\n",
    "def create_event_detection_visualization():\n",
    "    \"\"\"Create interactive visualization for event detection and analysis\"\"\"\n",
    "    try:\n",
    "        # Check if ROI data is loaded\n",
    "        if 'roi_data' not in globals() or roi_data is None:\n",
    "            print(\"Please load ROI data first\")\n",
    "            return\n",
    "        \n",
    "        # Create a copy of traces for visualization\n",
    "        # We'll convert ROI data to dF/F for the event detection\n",
    "        if 'corrected_data' not in globals() or corrected_data is None:\n",
    "            # If corrected_data isn't available, use roi_data directly\n",
    "            traces_for_analysis = roi_data.copy()\n",
    "        else:\n",
    "            # Extract traces directly from corrected_data using ROI masks\n",
    "            n_rois = len(roi_masks)\n",
    "            n_frames = corrected_data.shape[0]\n",
    "            traces_for_analysis = np.zeros((n_rois, n_frames), dtype=np.float32)\n",
    "            for i, mask in enumerate(roi_masks):\n",
    "                for t in range(n_frames):\n",
    "                    binary_mask = mask.astype(bool)\n",
    "                    traces_for_analysis[i, t] = np.mean(corrected_data[t][binary_mask])\n",
    "        \n",
    "        # Convert to dF/F using a simple baseline calculation\n",
    "        # This is just for visualization - the real pipeline will use more sophisticated methods\n",
    "        df_f_traces = np.zeros_like(traces_for_analysis)\n",
    "        for i in range(len(traces_for_analysis)):\n",
    "            # Use first 100 frames or fewer for baseline calculation\n",
    "            baseline_frames = min(100, traces_for_analysis.shape[1])\n",
    "            baseline = np.percentile(traces_for_analysis[i, :baseline_frames], 8)\n",
    "            df_f_traces[i] = (traces_for_analysis[i] - baseline) / baseline if baseline > 0 else traces_for_analysis[i]\n",
    "        \n",
    "        # Create widgets for event detection parameters\n",
    "        # Peak detection parameters\n",
    "        prominence_slider = widgets.FloatSlider(\n",
    "            value=0.03,\n",
    "            min=0.01,\n",
    "            max=0.2,\n",
    "            step=0.01,\n",
    "            description='Prominence:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        width_slider = widgets.IntSlider(\n",
    "            value=2,\n",
    "            min=1,\n",
    "            max=10,\n",
    "            step=1,\n",
    "            description='Width:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        distance_slider = widgets.IntSlider(\n",
    "            value=10,\n",
    "            min=5,\n",
    "            max=30,\n",
    "            step=1,\n",
    "            description='Distance:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        height_slider = widgets.FloatSlider(\n",
    "            value=0.02,\n",
    "            min=0.01,\n",
    "            max=0.2,\n",
    "            step=0.01,\n",
    "            description='Height:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Activity threshold\n",
    "        active_threshold_slider = widgets.FloatSlider(\n",
    "            value=0.02,\n",
    "            min=0.01,\n",
    "            max=0.1,\n",
    "            step=0.01,\n",
    "            description='Activity Threshold:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Widget for condition selection\n",
    "        condition_selector = widgets.Dropdown(\n",
    "            options=[\n",
    "                ('Spontaneous (0µm)', '0um'),\n",
    "                ('Evoked (10µm)', '10um'),\n",
    "                ('Evoked (25µm)', '25um')\n",
    "            ],\n",
    "            value='0um',\n",
    "            description='Condition:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Widget to select ROIs to display\n",
    "        roi_selector = widgets.SelectMultiple(\n",
    "            options=[(f\"ROI {i+1}\", i) for i in range(min(10, len(df_f_traces)))],\n",
    "            value=[0, 1, 2],  # Default: first 3 ROIs\n",
    "            description='ROIs to Display:',\n",
    "            disabled=False,\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Define the display function\n",
    "        def display_event_detection(prominence, width, distance, height, active_threshold, condition, roi_indices):\n",
    "            if not roi_indices:\n",
    "                print(\"Please select at least one ROI to display\")\n",
    "                return\n",
    "            \n",
    "            # Create peak detection config\n",
    "            peak_config = {\n",
    "                \"prominence\": prominence,\n",
    "                \"width\": width,\n",
    "                \"distance\": distance,\n",
    "                \"height\": height,\n",
    "                \"rel_height\": 0.5\n",
    "            }\n",
    "            \n",
    "            # Create the peak detection and display\n",
    "            n_rois = len(roi_indices)\n",
    "            fig, axes = plt.subplots(n_rois, 1, figsize=(15, 4*n_rois))\n",
    "            \n",
    "            # Handle single ROI case\n",
    "            if n_rois == 1:\n",
    "                axes = np.array([axes])\n",
    "            \n",
    "            # Set analysis frames based on condition\n",
    "            if condition == '0um':\n",
    "                # For spontaneous, analyze all frames\n",
    "                analysis_frames = [0, df_f_traces.shape[1]-1]\n",
    "                active_metric = \"spont_peak_frequency\"\n",
    "                title_suffix = \"Spontaneous Activity\"\n",
    "            else:\n",
    "                # For evoked, focus on frames after stimulus\n",
    "                analysis_frames = [100, df_f_traces.shape[1]-1]\n",
    "                active_metric = \"peak_amplitude\"\n",
    "                title_suffix = f\"Evoked Activity ({condition})\"\n",
    "            \n",
    "            # Calculate baseline frames - just use first 100 frames or fewer\n",
    "            baseline_frames = [0, min(100, df_f_traces.shape[1]-1)]\n",
    "            \n",
    "            # Process and display each selected ROI\n",
    "            active_rois = 0\n",
    "            for i, roi_idx in enumerate(roi_indices):\n",
    "                trace = df_f_traces[roi_idx]\n",
    "                \n",
    "                # Extract analysis window\n",
    "                analysis_start, analysis_end = analysis_frames\n",
    "                analysis_window = trace[analysis_start:analysis_end+1]\n",
    "                \n",
    "                # For evoked conditions, calculate and display stimulus time\n",
    "                if condition != '0um':\n",
    "                    stim_frame = 100  # Frame where stimulus occurs\n",
    "                \n",
    "                # Extract peaks\n",
    "                if condition == '0um':\n",
    "                    # For spontaneous, look at peaks during baseline period\n",
    "                    spont_params = extract_spontaneous_activity(\n",
    "                        trace[baseline_frames[0]:baseline_frames[1]+1],\n",
    "                        {\"prominence\": prominence/2, \"width\": width},  # Use lower threshold for spontaneous\n",
    "                        logger\n",
    "                    )\n",
    "                    is_active = spont_params['peak_frequency'] > active_threshold\n",
    "                    if is_active:\n",
    "                        active_rois += 1\n",
    "                    \n",
    "                    # Plot trace\n",
    "                    axes[i].plot(trace, 'k-', label='dF/F')\n",
    "                    \n",
    "                    # Find and highlight peaks\n",
    "                    from scipy.signal import find_peaks\n",
    "                    peaks, properties = find_peaks(\n",
    "                        trace,\n",
    "                        prominence=prominence/2,\n",
    "                        width=width,\n",
    "                        distance=distance,\n",
    "                        height=active_threshold\n",
    "                    )\n",
    "                    \n",
    "                    if len(peaks) > 0:\n",
    "                        axes[i].plot(peaks, trace[peaks], 'ro', label='Peaks')\n",
    "                    \n",
    "                    # Add title with metrics\n",
    "                    peak_freq = spont_params['peak_frequency']\n",
    "                    axes[i].set_title(f\"ROI {roi_idx+1} - {'Active' if is_active else 'Inactive'} - Peak Freq: {peak_freq:.2f}/100 frames\")\n",
    "                    \n",
    "                else:\n",
    "                    # For evoked, look at peaks after stimulus\n",
    "                    peak_params = extract_peak_parameters(\n",
    "                        analysis_window,\n",
    "                        peak_config,\n",
    "                        logger\n",
    "                    )\n",
    "                    \n",
    "                    # Check if ROI is active based on peak amplitude\n",
    "                    is_active = peak_params['amplitude'] > active_threshold\n",
    "                    if is_active:\n",
    "                        active_rois += 1\n",
    "                    \n",
    "                    # Plot trace\n",
    "                    axes[i].plot(trace, 'k-', label='dF/F')\n",
    "                    \n",
    "                    # Add a vertical line at stimulus time\n",
    "                    axes[i].axvline(x=stim_frame, color='r', linestyle='--', label='Stimulus', alpha=0.7)\n",
    "                    \n",
    "                    # Highlight analysis window\n",
    "                    axes[i].axvspan(analysis_start, analysis_end, color='lightgray', alpha=0.2, label='Analysis Window')\n",
    "                    \n",
    "                    # Find and highlight peaks\n",
    "                    from scipy.signal import find_peaks\n",
    "                    peaks, properties = find_peaks(\n",
    "                        analysis_window,\n",
    "                        prominence=prominence,\n",
    "                        width=width,\n",
    "                        distance=distance,\n",
    "                        height=height\n",
    "                    )\n",
    "                    \n",
    "                    if len(peaks) > 0:\n",
    "                        # Adjust peak indices to match original trace\n",
    "                        adjusted_peaks = peaks + analysis_start\n",
    "                        axes[i].plot(adjusted_peaks, trace[adjusted_peaks], 'ro', label='Peaks')\n",
    "                    \n",
    "                    # Add title with metrics\n",
    "                    amplitude = peak_params['amplitude']\n",
    "                    axes[i].set_title(f\"ROI {roi_idx+1} - {'Active' if is_active else 'Inactive'} - Peak Amplitude: {amplitude:.4f}\")\n",
    "                \n",
    "                # Add zero line for reference\n",
    "                axes[i].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "                \n",
    "                # Add a threshold line\n",
    "                axes[i].axhline(y=active_threshold, color='g', linestyle=':', \n",
    "                               label=f'Threshold ({active_threshold:.2f})', alpha=0.5)\n",
    "                \n",
    "                axes[i].set_xlabel('Frame')\n",
    "                axes[i].set_ylabel('dF/F')\n",
    "                axes[i].legend()\n",
    "                axes[i].grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.suptitle(f\"Event Detection - {title_suffix} ({active_rois}/{n_rois} ROIs Active)\", fontsize=16, y=1.02)\n",
    "            plt.show()\n",
    "            \n",
    "            # Update config with current values\n",
    "            # Peak detection parameters\n",
    "            if 'peak_detection' not in config['analysis']:\n",
    "                config['analysis']['peak_detection'] = {}\n",
    "            \n",
    "            config['analysis']['peak_detection']['prominence'] = prominence\n",
    "            config['analysis']['peak_detection']['width'] = width\n",
    "            config['analysis']['peak_detection']['distance'] = distance\n",
    "            config['analysis']['peak_detection']['height'] = height\n",
    "            \n",
    "            # Activity threshold\n",
    "            config['analysis']['active_threshold'] = active_threshold\n",
    "            \n",
    "            # Condition-specific parameters\n",
    "            if 'condition_specific' not in config['analysis']:\n",
    "                config['analysis']['condition_specific'] = {}\n",
    "            \n",
    "            if condition not in config['analysis']['condition_specific']:\n",
    "                config['analysis']['condition_specific'][condition] = {}\n",
    "            \n",
    "            config['analysis']['condition_specific'][condition]['active_threshold'] = active_threshold\n",
    "            config['analysis']['condition_specific'][condition]['active_metric'] = active_metric\n",
    "            \n",
    "            print(f\"Updated config with: prominence={prominence}, width={width}, distance={distance}, height={height}\")\n",
    "            print(f\"active_threshold={active_threshold}, condition={condition}, active_metric={active_metric}\")\n",
    "            print(\"To apply these settings to your pipeline, update your config.yaml file.\")\n",
    "        \n",
    "        # Create interactive widget\n",
    "        interactive_plot = interactive(\n",
    "            display_event_detection,\n",
    "            prominence=prominence_slider,\n",
    "            width=width_slider,\n",
    "            distance=distance_slider,\n",
    "            height=height_slider,\n",
    "            active_threshold=active_threshold_slider,\n",
    "            condition=condition_selector,\n",
    "            roi_indices=roi_selector\n",
    "        )\n",
    "        \n",
    "        # Display the interactive widget\n",
    "        display(interactive_plot)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating event detection visualization: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "# Create a button to launch the visualization\n",
    "event_detection_button = widgets.Button(\n",
    "    description='Launch Event Detection Visualization',\n",
    "    button_style='primary',\n",
    "    tooltip='Click to launch interactive visualization for event detection'\n",
    ")\n",
    "\n",
    "event_detection_button.on_click(lambda b: create_event_detection_visualization())\n",
    "display(event_detection_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f454a8b-b2f3-4361-bce7-652a017dc49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n## Save Configuration ##\")\n",
    "\n",
    "def save_config_to_file():\n",
    "    \"\"\"Save the updated configuration to a YAML file\"\"\"\n",
    "    try:\n",
    "        # Create a file selector\n",
    "        output_path = widgets.Text(\n",
    "            value='optimized_config.yaml',\n",
    "            placeholder='Enter file path to save config',\n",
    "            description='Output File:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='80%')\n",
    "        )\n",
    "        \n",
    "        display(output_path)\n",
    "        \n",
    "        # Create a save button\n",
    "        save_button = widgets.Button(\n",
    "            description='Save Configuration',\n",
    "            button_style='success',\n",
    "            tooltip='Click to save the current configuration to a file'\n",
    "        )\n",
    "        \n",
    "        def on_save_click(b):\n",
    "            try:\n",
    "                path = output_path.value\n",
    "                if not path:\n",
    "                    print(\"Please enter a valid file path\")\n",
    "                    return\n",
    "                \n",
    "                # Save the configuration to the specified file\n",
    "                with open(path, 'w') as f:\n",
    "                    yaml.dump(config, f, default_flow_style=False)\n",
    "                \n",
    "                print(f\"Configuration saved to {path}\")\n",
    "                print(\"To use this configuration in your pipeline, specify it with the --config parameter\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving configuration: {str(e)}\")\n",
    "        \n",
    "        save_button.on_click(on_save_click)\n",
    "        display(save_button)\n",
    "        \n",
    "        # Create a button to print the current configuration\n",
    "        print_button = widgets.Button(\n",
    "            description='Print Current Configuration',\n",
    "            button_style='info',\n",
    "            tooltip='Click to print the current configuration to the notebook'\n",
    "        )\n",
    "        \n",
    "        def on_print_click(b):\n",
    "            # Print the configuration in a readable format\n",
    "            print(\"Current Configuration:\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            # Print as formatted YAML\n",
    "            print(yaml.dump(config, default_flow_style=False))\n",
    "        \n",
    "        print_button.on_click(on_print_click)\n",
    "        display(print_button)\n",
    "        \n",
    "        # Create a button to reset configuration to original\n",
    "        reset_button = widgets.Button(\n",
    "            description='Reset Configuration',\n",
    "            button_style='danger',\n",
    "            tooltip='Click to reset the configuration to the original values'\n",
    "        )\n",
    "        \n",
    "        def on_reset_click(b):\n",
    "            # Reset the configuration to the original values\n",
    "            global config\n",
    "            config = copy.deepcopy(config_original)\n",
    "            print(\"Configuration reset to original values\")\n",
    "        \n",
    "        reset_button.on_click(on_reset_click)\n",
    "        display(reset_button)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in save configuration function: {str(e)}\")\n",
    "\n",
    "# Call the save configuration function\n",
    "save_config_to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6e1b80-ea4d-475e-a792-5baaf3d54ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n## Run Full Pipeline ##\")\n",
    "\n",
    "def run_full_pipeline():\n",
    "    \"\"\"Run the full pipeline with the current configuration\"\"\"\n",
    "    # Create a run button\n",
    "    run_button = widgets.Button(\n",
    "        description='Run Full Pipeline',\n",
    "        button_style='success',\n",
    "        tooltip='Click to run the full pipeline with the current configuration'\n",
    "    )\n",
    "    \n",
    "    def on_run_click(b):\n",
    "        # Run the pipeline with the current configuration\n",
    "        print(\"Running pipeline...\")\n",
    "        print(f\"Input Directory: {args.input_dir}\")\n",
    "        print(f\"Output Directory: {args.output_dir}\")\n",
    "        print(f\"Pipeline Mode: {args.mode}\")\n",
    "        print(f\"Max Workers: {args.max_workers}\")\n",
    "        \n",
    "        try:\n",
    "            # Update args with current widget values\n",
    "            update_args()\n",
    "            \n",
    "            # Match tif and roi files\n",
    "            file_pairs = match_tif_and_roi_files(args.input_dir, logger)\n",
    "            print(f\"Found {len(file_pairs)} matched file pairs\")\n",
    "            \n",
    "            # Process each file pair\n",
    "            import concurrent.futures\n",
    "            from tqdm.notebook import tqdm\n",
    "            \n",
    "            # Process a single file pair\n",
    "            def process_file_pair(pair_idx):\n",
    "                tif_path, roi_path = file_pairs[pair_idx]\n",
    "                slice_name = Path(tif_path).stem\n",
    "                print(f\"Processing {slice_name}...\")\n",
    "                \n",
    "                # Create output directory for this slice\n",
    "                slice_output_dir = os.path.join(args.output_dir, slice_name)\n",
    "                os.makedirs(slice_output_dir, exist_ok=True)\n",
    "                \n",
    "                # Extract metadata from filename\n",
    "                metadata = extract_metadata_from_filename(slice_name)\n",
    "                \n",
    "                # Load and preprocess the image data\n",
    "                with tifffile.TiffFile(tif_path) as tif:\n",
    "                    image_data = tif.asarray()\n",
    "                    \n",
    "                    # Ensure data is in (frames, height, width) format\n",
    "                    if len(image_data.shape) == 3:\n",
    "                        if image_data.shape[0] < image_data.shape[1] and image_data.shape[0] < image_data.shape[2]:\n",
    "                            # Already in (frames, height, width) format\n",
    "                            pass\n",
    "                        else:\n",
    "                            # Try to rearrange to (frames, height, width)\n",
    "                            if image_data.shape[2] < image_data.shape[0] and image_data.shape[2] < image_data.shape[1]:\n",
    "                                image_data = np.moveaxis(image_data, 2, 0)\n",
    "                            elif image_data.shape[1] < image_data.shape[0] and image_data.shape[1] < image_data.shape[2]:\n",
    "                                image_data = np.moveaxis(image_data, 1, 0)\n",
    "                \n",
    "                n_frames, height, width = image_data.shape\n",
    "                image_shape = (height, width)\n",
    "                \n",
    "                # Apply photobleaching correction\n",
    "                output_h5 = os.path.join(slice_output_dir, f\"{slice_name}_corrected.h5\")\n",
    "                corrected_data, _ = correct_photobleaching(\n",
    "                    image_data,\n",
    "                    output_h5,\n",
    "                    config[\"preprocessing\"],\n",
    "                    logger,\n",
    "                    save_output=config[\"preprocessing\"].get(\"save_corrected_data\", True)\n",
    "                )\n",
    "                \n",
    "                # Extract ROIs\n",
    "                roi_masks, roi_data = extract_roi_fluorescence(\n",
    "                    roi_path,\n",
    "                    corrected_data,\n",
    "                    image_shape,\n",
    "                    slice_output_dir,\n",
    "                    config[\"roi_processing\"],\n",
    "                    logger\n",
    "                )\n",
    "                \n",
    "                # Background subtraction\n",
    "                if config[\"roi_processing\"].get(\"steps\", {}).get(\"subtract_background\", True):\n",
    "                    bg_method = config[\"roi_processing\"][\"background\"].get(\"method\", \"darkest_pixels\")\n",
    "                    \n",
    "                    if bg_method == \"global_background\":\n",
    "                        bg_corrected_data = subtract_global_background(\n",
    "                            corrected_data,\n",
    "                            roi_data,\n",
    "                            roi_masks,\n",
    "                            config[\"roi_processing\"][\"background\"],\n",
    "                            logger,\n",
    "                            output_dir=slice_output_dir\n",
    "                        )\n",
    "                    else:\n",
    "                        bg_corrected_data = subtract_background(\n",
    "                            corrected_data,\n",
    "                            roi_data,\n",
    "                            roi_masks,\n",
    "                            config[\"roi_processing\"][\"background\"],\n",
    "                            logger,\n",
    "                            output_dir=slice_output_dir\n",
    "                        )\n",
    "                else:\n",
    "                    bg_corrected_data = roi_data\n",
    "                \n",
    "                # Analyze fluorescence\n",
    "                metrics_df, df_f_traces = analyze_fluorescence(\n",
    "                    bg_corrected_data,\n",
    "                    roi_masks,\n",
    "                    tif_path,\n",
    "                    config[\"analysis\"],\n",
    "                    logger,\n",
    "                    output_dir=slice_output_dir,\n",
    "                    metadata=metadata\n",
    "                )\n",
    "                \n",
    "                # Save metrics to Excel\n",
    "                metrics_file = os.path.join(slice_output_dir, f\"{slice_name}_metrics.xlsx\")\n",
    "                metrics_df.to_excel(metrics_file, index=False)\n",
    "                \n",
    "                # Also save as CSV for easier processing\n",
    "                csv_file = os.path.join(slice_output_dir, f\"{slice_name}_metrics.csv\")\n",
    "                metrics_df.to_csv(csv_file, index=False)\n",
    "                \n",
    "                # Generate visualizations\n",
    "                flagged_rois = perform_qc_checks(\n",
    "                    bg_corrected_data,\n",
    "                    metrics_df,\n",
    "                    config[\"analysis\"].get(\"qc_thresholds\", {}),\n",
    "                    logger\n",
    "                )\n",
    "                \n",
    "                generate_visualizations(\n",
    "                    df_f_traces,\n",
    "                    roi_masks,\n",
    "                    metrics_df,\n",
    "                    flagged_rois,\n",
    "                    tif_path,\n",
    "                    slice_output_dir,\n",
    "                    config[\"visualization\"],\n",
    "                    logger,\n",
    "                    metadata=metadata\n",
    "                )\n",
    "                \n",
    "                return {\n",
    "                    \"slice_name\": slice_name,\n",
    "                    \"metrics_file\": metrics_file,\n",
    "                    \"metadata\": metadata\n",
    "                }\n",
    "            \n",
    "            # Process file pairs sequentially or in parallel based on max_workers\n",
    "            results = []\n",
    "            if args.max_workers > 1:\n",
    "                with concurrent.futures.ProcessPoolExecutor(max_workers=args.max_workers) as executor:\n",
    "                    futures = [executor.submit(process_file_pair, i) for i in range(len(file_pairs))]\n",
    "                    for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
    "                        result = future.result()\n",
    "                        results.append(result)\n",
    "            else:\n",
    "                for i in tqdm(range(len(file_pairs))):\n",
    "                    result = process_file_pair(i)\n",
    "                    results.append(result)\n",
    "            \n",
    "            print(f\"Processing completed for {len(results)} file pairs\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error running pipeline: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    run_button.on_click(on_run_click)\n",
    "    display(run_button)\n",
    "\n",
    "# Call the run pipeline function\n",
    "run_full_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619d4461-523a-4082-bc1d-8987c1d1d3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n## Notebook Summary ##\")\n",
    "print(\"This notebook provides interactive tools to:\")\n",
    "print(\"1. Load and configure the fluorescence analysis pipeline\")\n",
    "print(\"2. Explore parameter effects on:\")\n",
    "print(\"   - Gaussian denoising\")\n",
    "print(\"   - ROI processing with PNR refinement\")\n",
    "print(\"   - Background subtraction\")\n",
    "print(\"   - Event detection and analysis\")\n",
    "print(\"3. Save optimized configurations\")\n",
    "print(\"4. Run the full pipeline with optimized parameters\")\n",
    "print(\"\\nData saved in the output directory can be used for further analysis.\")\n",
    "print(\"For any issues or questions, please refer to the pipeline documentation.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
