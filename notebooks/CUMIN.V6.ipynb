{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a9911b3-d435-465d-9d70-aec08af5418c",
   "metadata": {},
   "source": [
    "# CUMIN (CUrated MINion): A Fluorescence Analysis Pipeline for Curated ROIs\n",
    "\n",
    "This notebook provides an interactive interface to the fluorescence analysis pipeline, allowing you to explore parameter effects on ROI detection, trace extraction, and event analysis.\n",
    "\n",
    "## Overview\n",
    "- Load and select fluorescence imaging data\n",
    "- Explore parameter effects with interactive visualizations:\n",
    "  - Gaussian denoising for image preprocessing\n",
    "  - ROI processing with PNR refinement\n",
    "  - Background subtraction for improved signal\n",
    "  - Event detection and analysis\n",
    "- Save optimized configurations\n",
    "- Run the full pipeline with optimized parameters\n",
    "\n",
    "Each section includes in-depth explanations of the algorithms and parameters, helping you understand how different settings affect your analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ec1e1d-73c5-45c0-9898-e3976ddebdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "  const py_version = '3.5.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  const reloading = false;\n",
       "  const Bokeh = root.Bokeh;\n",
       "\n",
       "  // Set a timeout for this load but only if we are not already initializing\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      // Don't load bokeh if it is still initializing\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      // There is nothing to load\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error(e) {\n",
       "      const src_el = e.srcElement\n",
       "      console.error(\"failed to load \" + (src_el.href || src_el.src));\n",
       "    }\n",
       "\n",
       "    const skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n",
       "      root._bokeh_is_loading = css_urls.length + 0;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    const existing_stylesheets = []\n",
       "    const links = document.getElementsByTagName('link')\n",
       "    for (let i = 0; i < links.length; i++) {\n",
       "      const link = links[i]\n",
       "      if (link.href != null) {\n",
       "        existing_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (existing_stylesheets.indexOf(escaped) !== -1) {\n",
       "        on_load()\n",
       "        continue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    var existing_scripts = []\n",
       "    const scripts = document.getElementsByTagName('script')\n",
       "    for (let i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "        existing_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (let i = 0; i < js_modules.length; i++) {\n",
       "      const url = js_modules[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      const url = js_exports[name];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.holoviz.org/panel/1.5.1/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.5.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.5.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.5.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.5.2.min.js\", \"https://cdn.holoviz.org/panel/1.5.1/dist/panel.min.js\"];\n",
       "  const js_modules = [];\n",
       "  const js_exports = {};\n",
       "  const css_urls = [];\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (let i = 0; i < inline_js.length; i++) {\n",
       "        try {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "        } catch(e) {\n",
       "          if (!reloading) {\n",
       "            throw e;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "        var NewBokeh = root.Bokeh;\n",
       "        if (Bokeh.versions === undefined) {\n",
       "          Bokeh.versions = new Map();\n",
       "        }\n",
       "        if (NewBokeh.version !== Bokeh.version) {\n",
       "          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "        }\n",
       "        root.Bokeh = Bokeh;\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      // If the timeout and bokeh was not successfully loaded we reset\n",
       "      // everything and try loading again\n",
       "      root._bokeh_timeout = Date.now() + 5000;\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      root._bokeh_is_loading = 0\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "        if (root.Bokeh) {\n",
       "          root.Bokeh = undefined;\n",
       "        }\n",
       "        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "        run_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.5.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.5.1/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.5.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.5.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.5.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.5.2.min.js\", \"https://cdn.holoviz.org/panel/1.5.1/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1002'>\n",
       "  <div id=\"d9bae892-0f28-4a5f-bb5a-c78fd992254d\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"ea75ff78-5caf-47d1-8809-6a69ebfb767e\":{\"version\":\"3.5.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1002\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1003\",\"attributes\":{\"plot_id\":\"p1002\",\"comm_id\":\"5e5703b9c7d0496ca4ec12a91b8582b4\",\"client_comm_id\":\"96297b5183fd4b329648fc38a8448633\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\"},{\"type\":\"model\",\"name\":\"JSComponent1\"},{\"type\":\"model\",\"name\":\"ReactComponent1\"},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\"},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"ea75ff78-5caf-47d1-8809-6a69ebfb767e\",\"roots\":{\"p1002\":\"d9bae892-0f28-4a5f-bb5a-c78fd992254d\"},\"root_ids\":[\"p1002\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1002"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"logo-block\">\n",
       "<img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAAB+wAAAfsBxc2miwAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAA6zSURB\n",
       "VHic7ZtpeFRVmsf/5966taWqUlUJ2UioBBJiIBAwCZtog9IOgjqACsogKtqirT2ttt069nQ/zDzt\n",
       "tI4+CrJIREFaFgWhBXpUNhHZQoKBkIUASchWla1S+3ar7r1nPkDaCAnZKoQP/D7mnPOe9/xy76n3\n",
       "nFSAW9ziFoPFNED2LLK5wcyBDObkb8ZkxuaoSYlI6ZcOKq1eWFdedqNzGHQBk9RMEwFAASkk0Xw3\n",
       "ETacDNi2vtvc7L0ROdw0AjoSotQVkKSvHQz/wRO1lScGModBFbDMaNRN1A4tUBCS3lk7BWhQkgpD\n",
       "lG4852/+7DWr1R3uHAZVQDsbh6ZPN7CyxUrCzJMRouusj0ipRwD2uKm0Zn5d2dFwzX1TCGhnmdGo\n",
       "G62Nna+isiUqhkzuKrkQaJlPEv5mFl2fvGg2t/VnzkEV8F5ioioOEWkLG86fvbpthynjdhXYZziQ\n",
       "x1hC9J2NFyi8vCTt91Fh04KGip0AaG9zuCk2wQCVyoNU3Hjezee9bq92duzzTmxsRJoy+jEZZZYo\n",
       "GTKJ6SJngdJqAfRzpze0+jHreUtPc7gpBLQnIYK6BYp/uGhw9YK688eu7v95ysgshcg9qSLMo3JC\n",
       "4jqLKQFBgdKDPoQ+Pltb8dUyQLpeDjeVgI6EgLIQFT5tEl3rn2losHVsexbZ3EyT9wE1uGdkIPcy\n",
       "BGxn8QUq1QrA5nqW5i2tLqvrrM9NK6AdkVIvL9E9bZL/oyfMVd/jqvc8LylzRBKDJSzIExwhQzuL\n",
       "QYGQj4rHfFTc8mUdu3E7yoLtbTe9gI4EqVgVkug2i5+uXGo919ixbRog+3fTbQ8qJe4ZOYNfMoTI\n",
       "OoshUNosgO60AisX15aeI2PSIp5KiFLI9ubb1vV3Qb2ltwLakUCDAkWX7/nHKRmmGIl9VgYsUhJm\n",
       "2NXjKYADtM1ygne9QQDIXlk49FBstMKx66D1v4+XuQr7vqTe0VcBHQlRWiOCbmmSYe2SqtL6q5rJ\n",
       "zsTb7lKx3FKOYC4DoqyS/B5bvLPxvD9Qtf6saxYLQGJErmDOdOMr/zo96km1nElr8bmPOBwI9COv\n",
       "HnFPRIwmkSOv9kcAS4heRsidOkpeWBgZM+UBrTFAXNYL5Vf2ii9c1trNzpYdaoVil3WIc+wdk+gQ\n",
       "noie3ecCcxt9ITcLAPWt/laGEO/9U6PmzZkenTtsSMQ8uYywJVW+grCstAvCIaAdArAsIWkRDDs/\n",
       "KzLm2YcjY1Lv0UdW73HabE9n6V66cxSzfEmuJssTpKGVp+0vHq73FwL46eOjpMpbRAnNmJFrGJNu\n",
       "Ukf9Yrz+3rghiumCKNXXWPhLYcjxGsIpoCMsIRoFITkW8AuyM8jC1+/QLx4bozCEJIq38+1rtpR6\n",
       "V/yzb8eBlRb3fo5l783N0CWolAzJHaVNzkrTzlEp2bQ2q3TC5gn6wpnoQAmwSiGh2GitnTmVMc5O\n",
       "UyfKWUKCIsU7+fZDKwqdT6DDpvkzAX4/+AMFjk0tDp5GRXLpQ2MUmhgDp5gxQT8+Y7hyPsMi8uxF\n",
       "71H0oebujHALECjFKaW9Lm68n18wXp2kVzIcABytD5iXFzg+WVXkegpAsOOYziqo0OkK76GyquC3\n",
       "ltZAzMhhqlSNmmWTE5T6e3IN05ITFLM4GdN0vtZ3ob8Jh1NAKXFbm5PtLU/eqTSlGjkNAJjdgn/N\n",
       "aedXa0tdi7+t9G0FIF49rtMSEgAs1kDLkTPO7ebm4IUWeyh1bKomXqlgMG6kJmHcSM0clYLJ8XtR\n",
       "1GTnbV3F6I5wCGikAb402npp1h1s7LQUZZSMIfALFOuL3UUrfnS8+rez7v9qcold5tilgHbO1fjK\n",
       "9ubb17u9oshxzMiUBKXWqJNxd+fqb0tLVs4lILFnK71H0Ind7uiPgACVcFJlrb0tV6DzxqqTIhUM\n",
       "CwDf1/rrVhTa33/3pGPxJYdQ2l2cbgVcQSosdx8uqnDtbGjh9SlDVSMNWhlnilfqZk42Th2ZpLpf\n",
       "xrHec5e815zrr0dfBZSwzkZfqsv+1FS1KUknUwPARVvItfKUY+cn57yP7qv07UE3p8B2uhUwLk09\n",
       "e0SCOrK+hbdYHYLjRIl71wWzv9jpEoeOHhGRrJAzyEyNiJuUqX0g2sBN5kGK6y2Blp5M3lsB9Qh4\n",
       "y2Ja6x6+i0ucmKgwMATwhSjdUu49tKrQ/pvN5d53ml2CGwCmJipmKjgmyuaXzNeL2a0AkQ01Th5j\n",
       "2DktO3Jyk8f9vcOBQHV94OK+fPumJmvQHxJoWkaKWq9Vs+yUsbq0zGT1I4RgeH2b5wef7+c7bl8F\n",
       "eKgoHVVZa8ZPEORzR6sT1BzDUAD/d9F78e2Tzv99v8D+fLVTqAKAsbGamKey1Mt9Ann4eH3gTXTz\n",
       "idWtAJ8PQWOk7NzSeQn/OTHDuEikVF1R4z8BQCy+6D1aWRfY0tTGG2OM8rRoPaeIj5ZHzJxszElN\n",
       "VM8K8JS5WOfv8mzRnQAKoEhmt8gyPM4lU9SmBK1MCQBnW4KONT86v1hZ1PbwSXPw4JWussVjtH9Y\n",
       "NCoiL9UoH/6PSu8jFrfY2t36erQHXLIEakMi1SydmzB31h3GGXFDFNPaK8Rme9B79Ixrd0WN+1ij\n",
       "NRQ/doRmuFLBkHSTOm5GruG+pFjFdAmorG4IXH1Qua6ASniclfFtDYt+oUjKipPrCQB7QBQ2lrgP\n",
       "fFzm+9XWUtcqJ3/5vDLDpJ79XHZk3u8nGZ42qlj1+ydtbxysCezrydp6ugmipNJ7WBPB5tydY0jP\n",
       "HaVNzs3QzeE4ZpTbI+ZbnSFPbVOw9vsfnVvqWnirPyCNGD08IlqtYkh2hjZ5dErEQzoNm+6ykyOt\n",
       "Lt5/PQEuSRRKo22VkydK+vvS1XEKlhCJAnsqvcVvH7f/ZU2R67eXbMEGAMiIV5oWZWiWvz5Fv2xG\n",
       "sjqNJQRvn3Rs2lji/lNP19VjAQDgD7FHhujZB9OGqYxRkZxixgRDVlqS6uEOFaJUVu0rPFzctrnF\n",
       "JqijImVp8dEKVWyUXDk92zAuMZ6bFwpBU1HrOw6AdhQgUooChb0+ItMbWJitSo5Ws3IAOGEOtL53\n",
       "0vHZih9sC4vtofZ7Qu6523V/fmGcds1TY3V36pUsBwAbSlxnVh2xLfAD/IAIMDf7XYIkNmXfpp2l\n",
       "18rkAJAy9HKFaIr/qULkeQQKy9zf1JgDB2uaeFNGijo5QsUyacNUUTOnGO42xSnv4oOwpDi1zYkc\n",
       "efUc3I5Gk6PhyTuVKaOGyLUAYPGIoY9Pu/atL/L92+4q9wbflRJ2Trpm/jPjdBtfnqB/dIThcl8A\n",
       "KG7hbRuKnb8qsQsVvVlTrwQAQMUlf3kwJI24Z4JhPMtcfng5GcH49GsrxJpGvvHIaeem2ma+KSjQ\n",
       "lIwUdYyCY8j4dE1KzijNnIP2llF2wcXNnsoapw9XxsgYAl6k+KzUXbi2yP3KR2ecf6z3BFsBICdW\n",
       "nvnIaG3eHybqX7vbpEqUMT+9OL4Qpe8VON7dXuFd39v19FoAABRVePbGGuXTszO0P7tu6lghUonE\n",
       "llRdrhArLvmKdh9u29jcFiRRkfLUxBiFNiqSU9icoZQHo5mYBI1MBgBH6wMNb+U7Pnw337H4gi1Y\n",
       "ciWs+uks3Z9fztUvfzxTm9Ne8XXkvQLHNytOOZeiD4e0PgkAIAYCYknKUNUDSXEKzdWNpnil7r4p\n",
       "xqkjTarZMtk/K8TQ6Qve78qqvXurGwIJqcOUKfUWHsm8KGvxSP68YudXq4pcj39X49uOK2X142O0\n",
       "Tz5/u/7TVybqH0rSya6ZBwD21/gubbrgWdDgEOx9WUhfBaC2ibcEBYm7a7x+ukrBMNcEZggyR0TE\n",
       "T8zUPjikQ4VosQZbTpS4vqizBKvqmvjsqnpfzaZyx9JPiz1/bfGKdgD45XB1zoIMzYbfTdS/NClB\n",
       "Gct0USiY3YL/g0LHy/uq/Ef6uo5+n0R/vyhp17Klpge763f8rMu6YU/zrn2nml+2WtH+Z+5IAAFc\n",
       "2bUTdTDOSNa9+cQY7YLsOIXhevEkCvzph7a8laecz/Un/z4/Ae04XeL3UQb57IwU9ZDr9UuKVajv\n",
       "nxp1+1UVIo/LjztZkKH59fO3G/JemqCfmaCRqbqbd90ZZ8FfjtkfAyD0J/9+C2h1hDwsSxvGjNDc\n",
       "b4zk5NfrSwiQblLHzZhg+Jf4aPlUwpDqkQqa9nimbt1/TDH8OitGMaQnj+RJS6B1fbF7SY1TqO5v\n",
       "/v0WAADl1f7zokgS7s7VT2DZ7pegUjBM7mjtiDZbcN4j0YrHH0rXpCtY0qPX0cVL0rv5jv/ZXend\n",
       "0u/EESYBAFBU4T4Qa5TflZOhTe7pmKpaP8kCVUVw1+yhXfJWvn1P3hnXi33JsTN6PnP3hHZ8Z3/h\n",
       "aLHzmkNPuPj7Bc/F/Q38CwjTpSwQXgE4Vmwry9tpfq/ZFgqFMy4AVDtCvi8rvMvOmv0N4YwbVgEA\n",
       "sPM72/KVnzfspmH7HQGCRLG2yL1+z8XwvPcdCbsAANh+xPzstgMtxeGKt+6MK3/tacfvwhWvIwMi\n",
       "oKEBtm0H7W+UVfkc/Y1V0BhoPlDr/w1w/eu1vjIgAgDg22OtX6/eYfnEz/focrZTHAFR+PSs56/7\n",
       "q32nwpjazxgwAQCwcU/T62t3WL7r6/jVRa6/byp1rei+Z98ZUAEAhEPHPc8fKnTU9nbgtnOe8h0l\n",
       "9hcGIqmODLQAHCy2Xti6v/XNRivf43f4fFvIteu854+VHnR7q9tfBlwAAGz+pnndB9vM26UebAe8\n",
       "SLHujPOTPVW+rwY+sxskAAC2HrA8t2Vvc7ffP1r9o+vwR2dcr92InIAbKKC1FZ5tB1tf+/G8p8sv\n",
       "N/9Q5zd/XR34LYCwV5JdccMEAMDBk45DH243r/X4xGvqxFa/GNpS7n6rwOwNWwHVE26oAADYurf1\n",
       "zx/utOzt+DMKYM0p17YtZZ5VNzqfsB2HewG1WXE8PoZ7gOclbTIvynZf9JV+fqZtfgs/8F/Nu5rB\n",
       "EIBmJ+8QRMmpU7EzGRsf2FzuePqYRbzh/zE26EwdrT10f6r6o8HOYzCJB9Dpff8tbnGLG8L/A/WE\n",
       "roTBs2RqAAAAAElFTkSuQmCC'\n",
       "     style='height:25px; border-radius:12px; display: inline-block; float: left; vertical-align: middle'></img>\n",
       "\n",
       "\n",
       "  <img src='data:image/png;base64,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'\n",
       "       style='height:15px; border-radius:12px; display: inline-block; float: left'></img>\n",
       "  \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = false;\n",
       "  const py_version = '3.5.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  const reloading = true;\n",
       "  const Bokeh = root.Bokeh;\n",
       "\n",
       "  // Set a timeout for this load but only if we are not already initializing\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      // Don't load bokeh if it is still initializing\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      // There is nothing to load\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error(e) {\n",
       "      const src_el = e.srcElement\n",
       "      console.error(\"failed to load \" + (src_el.href || src_el.src));\n",
       "    }\n",
       "\n",
       "    const skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n",
       "      root._bokeh_is_loading = css_urls.length + 0;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    const existing_stylesheets = []\n",
       "    const links = document.getElementsByTagName('link')\n",
       "    for (let i = 0; i < links.length; i++) {\n",
       "      const link = links[i]\n",
       "      if (link.href != null) {\n",
       "        existing_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (existing_stylesheets.indexOf(escaped) !== -1) {\n",
       "        on_load()\n",
       "        continue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    var existing_scripts = []\n",
       "    const scripts = document.getElementsByTagName('script')\n",
       "    for (let i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "        existing_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (let i = 0; i < js_modules.length; i++) {\n",
       "      const url = js_modules[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      const url = js_exports[name];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.holoviz.org/panel/1.5.1/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\"];\n",
       "  const js_modules = [];\n",
       "  const js_exports = {};\n",
       "  const css_urls = [];\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (let i = 0; i < inline_js.length; i++) {\n",
       "        try {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "        } catch(e) {\n",
       "          if (!reloading) {\n",
       "            throw e;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "        var NewBokeh = root.Bokeh;\n",
       "        if (Bokeh.versions === undefined) {\n",
       "          Bokeh.versions = new Map();\n",
       "        }\n",
       "        if (NewBokeh.version !== Bokeh.version) {\n",
       "          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "        }\n",
       "        root.Bokeh = Bokeh;\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      // If the timeout and bokeh was not successfully loaded we reset\n",
       "      // everything and try loading again\n",
       "      root._bokeh_timeout = Date.now() + 5000;\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      root._bokeh_is_loading = 0\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "        if (root.Bokeh) {\n",
       "          root.Bokeh = undefined;\n",
       "        }\n",
       "        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "        run_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = false;\n  const py_version = '3.5.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = true;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.5.1/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\caiman\\lib\\site-packages\\cupy\\_environment.py:217: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\CUMIN V3 Pipeline\\notebooks\\..\\modules\\motion_correction.py:27: UserWarning: NoRMCorre not found. Motion correction will be unavailable. Install with: pip install normcorre\n",
      "  warnings.warn(\"NoRMCorre not found. Motion correction will be unavailable. Install with: pip install normcorre\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported all modules\n"
     ]
    }
   ],
   "source": [
    "# @title Import Libraries and Setup {display-mode: \"form\"}\n",
    "# Import standard libraries\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import tifffile\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import copy\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "from scipy.ndimage import binary_dilation, median_filter\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Import interactive libraries\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, fixed, interact_manual, interactive\n",
    "\n",
    "# Check for HoloViews and Panel\n",
    "try:\n",
    "    import holoviews as hv\n",
    "    import panel as pn\n",
    "    import param\n",
    "    HAS_PANEL = True\n",
    "    hv.extension('bokeh')\n",
    "    pn.extension()\n",
    "except ImportError:\n",
    "    HAS_PANEL = False\n",
    "    print(\"HoloViews and Panel are not installed. Some visualizations will be limited.\")\n",
    "    print(\"To install: pip install holoviews panel param bokeh\")\n",
    "\n",
    "# Add parent directory to path if notebook is in notebooks/\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "\n",
    "# Add current directory to path to import local modules\n",
    "if '.' not in sys.path:\n",
    "    sys.path.append('.')\n",
    "\n",
    "# Import pipeline modules\n",
    "try:\n",
    "    from modules.file_matcher import match_tif_and_roi_files, extract_metadata_from_filename\n",
    "    from modules.preprocessing import (\n",
    "        correct_photobleaching, remove_background, denoise, stripe_correction\n",
    "    )\n",
    "    from modules.roi_processing import (\n",
    "        extract_roi_fluorescence, subtract_background, subtract_global_background,\n",
    "        extract_rois_from_zip, save_masks_for_cnmf, extract_roi_fluorescence_with_cnmf,\n",
    "        refine_rois_with_cnmfe, refine_rois_with_pnr, split_signal_noise, visualize_pnr_results,\n",
    "        save_trace_data\n",
    "    )\n",
    "    from modules.analysis import (\n",
    "        analyze_fluorescence, perform_qc_checks, extract_peak_parameters,\n",
    "        extract_spontaneous_activity, calculate_baseline_excluding_peaks\n",
    "    )\n",
    "    from modules.visualization import generate_visualizations\n",
    "    from modules.utils import setup_logging, save_slice_data, save_mouse_summary\n",
    "    #from modules.advanced_analysis import run_advanced_analysis\n",
    "    from modules.visualization_helpers import (\n",
    "        run_denoising_visualization, run_background_removal_visualization,\n",
    "        run_motion_correction_visualization, run_event_detection_visualization,\n",
    "        normalize_for_display\n",
    "    )\n",
    "    \n",
    "    # Check for motion correction module\n",
    "    try:\n",
    "        from modules.motion_correction import apply_normcorre_correction, estimate_motion\n",
    "        HAS_MOTION_CORRECTION = True\n",
    "    except ImportError:\n",
    "        HAS_MOTION_CORRECTION = False\n",
    "        print(\"Motion correction module not available. This feature will be disabled.\")\n",
    "    \n",
    "    #Try importing advanced analysis module if available\n",
    "    try:\n",
    "        from modules.advanced_analysis import run_advanced_analysis\n",
    "        ADVANCED_ANALYSIS_AVAILABLE = True\n",
    "    except ImportError:\n",
    "        ADVANCED_ANALYSIS_AVAILABLE = False\n",
    "        print(\"Advanced analysis module not available. Some features will be disabled.\")\n",
    "    \n",
    "    print(\"Successfully imported all modules\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing modules: {e}\")\n",
    "    print(\"Make sure the required modules are in the 'modules' directory or adjust the import path.\")\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e373ae-e3e6-4f63-8f67-32eab7f50521",
   "metadata": {},
   "source": [
    "## Setting Up Pipeline Parameters\n",
    "\n",
    "Before starting the analysis, we need to configure the pipeline parameters including:\n",
    "\n",
    "- **Input Directory**: Location of your .tif (image) and .zip (ROI) files\n",
    "- **Output Directory**: Where analysis results will be saved\n",
    "- **Configuration File**: YAML file with pipeline parameters\n",
    "- **Pipeline Mode**: \"all\" runs the complete pipeline; other options are \"preprocess\", \"extract\", and \"analyze\"\n",
    "- **Max Workers**: Number of parallel processes for multi-core processing\n",
    "\n",
    "You can adjust these parameters below. Click \"Update Parameters\" after making changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59e737f7-f403-49c7-85a8-cf9a17e3222d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1612643199f427d818bdfd45d4819ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='F:\\\\Recovered\\\\Research\\\\BoninLab\\\\PainModelingProject\\\\ForCumin', description='Input Directory:',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130ba296568943ffbb021fd45bf2e449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='F:\\\\Recovered\\\\Research\\\\BoninLab\\\\PainModelingProject\\\\ForCumin\\\\New folder', description='Output…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d53dd67613942afbd77159ef53e51e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='config.yaml', description='Config File:', style=TextStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afbae72c69543a5a5c1fd866790571a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Pipeline Mode:', options=('all', 'preprocess', 'extract', 'analyze'), style=DescriptionS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816453d13a424d0eadc21d172ae5fda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=4, description='Max Workers:', max=12, min=1, style=SliderStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cedea0ded7c04aa7a6408a1a9077378c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Disable Advanced Analysis', style=CheckboxStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a76e15d371d48b19cedf536d5cee10b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Update Parameters', style=ButtonStyle(), tooltip='Click to update par…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Pipeline Parameters {display-mode: \"form\"}\n",
    "class Args:\n",
    "    \"\"\"Class to simulate command line arguments\"\"\"\n",
    "    def __init__(self):\n",
    "        self.input_dir = r\"F:\\Recovered\\Research\\BoninLab\\PainModelingProject\\ForCumin\"  # CHANGE THIS\n",
    "        self.output_dir = r\"F:\\Recovered\\Research\\BoninLab\\PainModelingProject\\ForCumin\\New folder\"  # CHANGE THIS\n",
    "        self.config = \"config.yaml\"  # Path to your config file\n",
    "        self.mode = \"all\"  # Options: \"all\", \"preprocess\", \"extract\", \"analyze\"\n",
    "        self.max_workers = 4  # Adjust based on your CPU cores\n",
    "        self.disable_advanced = False\n",
    "\n",
    "# Create args object\n",
    "args = Args()\n",
    "\n",
    "# Create interactive widgets for adjusting parameters\n",
    "input_dir_widget = widgets.Text(\n",
    "    value=args.input_dir,\n",
    "    description='Input Directory:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "output_dir_widget = widgets.Text(\n",
    "    value=args.output_dir,\n",
    "    description='Output Directory:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "config_widget = widgets.Text(\n",
    "    value=args.config,\n",
    "    description='Config File:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "mode_widget = widgets.Dropdown(\n",
    "    options=['all', 'preprocess', 'extract', 'analyze'],\n",
    "    value=args.mode,\n",
    "    description='Pipeline Mode:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "workers_widget = widgets.IntSlider(\n",
    "    value=args.max_workers,\n",
    "    min=1,\n",
    "    max=12,\n",
    "    step=1,\n",
    "    description='Max Workers:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "disable_advanced_widget = widgets.Checkbox(\n",
    "    value=args.disable_advanced,\n",
    "    description='Disable Advanced Analysis',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Function to update args object based on widget values\n",
    "def update_args():\n",
    "    args.input_dir = input_dir_widget.value\n",
    "    args.output_dir = output_dir_widget.value\n",
    "    args.config = config_widget.value\n",
    "    args.mode = mode_widget.value\n",
    "    args.max_workers = workers_widget.value\n",
    "    args.disable_advanced = disable_advanced_widget.value\n",
    "    print(\"Parameters updated:\")\n",
    "    print(f\"Input Directory: {args.input_dir}\")\n",
    "    print(f\"Output Directory: {args.output_dir}\")\n",
    "    print(f\"Config File: {args.config}\")\n",
    "    print(f\"Pipeline Mode: {args.mode}\")\n",
    "    print(f\"Max Workers: {args.max_workers}\")\n",
    "    print(f\"Disable Advanced Analysis: {args.disable_advanced}\")\n",
    "\n",
    "# Create update button\n",
    "update_button = widgets.Button(\n",
    "    description='Update Parameters',\n",
    "    button_style='info',\n",
    "    tooltip='Click to update parameters'\n",
    ")\n",
    "\n",
    "update_button.on_click(lambda b: update_args())\n",
    "\n",
    "# Display widgets\n",
    "display(input_dir_widget)\n",
    "display(output_dir_widget)\n",
    "display(config_widget)\n",
    "display(mode_widget)\n",
    "display(workers_widget)\n",
    "display(disable_advanced_widget)\n",
    "display(update_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd871866-26b2-49d1-a609-a62af63e0200",
   "metadata": {},
   "source": [
    "## Loading Configuration\n",
    "\n",
    "The pipeline configuration is stored in a YAML file that defines parameters for each processing step. \n",
    "The configuration includes settings for:\n",
    "\n",
    "- **Preprocessing**: Methods and parameters for photo-bleaching correction, denoising, etc.\n",
    "- **ROI Processing**: ROI extraction, refinement, and background subtraction\n",
    "- **Analysis**: Event detection parameters, condition-specific settings, etc.\n",
    "- **Visualization**: Plot types, colormaps, and other visualization settings\n",
    "\n",
    "Click \"Load Configuration\" to load the configuration file specified in the parameters section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f5adf4d-fcab-444b-a769-62f0574acdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2383124d95b949f08da839620899ad76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Load Configuration', style=ButtonStyle(), tooltip='Click to load t…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Load Configuration {display-mode: \"form\"}\n",
    "def load_config(config_path, args=None):\n",
    "    \"\"\"Load configuration from YAML file and apply command line overrides.\"\"\"\n",
    "    try:\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        print(f\"Loaded configuration from {config_path}\")\n",
    "        \n",
    "        # Apply command line overrides if provided\n",
    "        if args and args.disable_advanced:\n",
    "            # Disable advanced analysis if requested via command line\n",
    "            if \"advanced_analysis\" in config:\n",
    "                config[\"advanced_analysis\"][\"enabled\"] = False\n",
    "                print(\"Advanced analysis disabled via command line argument\")\n",
    "        \n",
    "        return config\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load configuration: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Setup logging\n",
    "logger = setup_logging()\n",
    "\n",
    "# Create a load button\n",
    "load_config_button = widgets.Button(\n",
    "    description='Load Configuration',\n",
    "    button_style='success',\n",
    "    tooltip='Click to load the configuration file'\n",
    ")\n",
    "\n",
    "def on_load_config_click(b):\n",
    "    global config, config_original\n",
    "    # Load configuration\n",
    "    config = load_config(args.config, args)\n",
    "    if config:\n",
    "        print(\"Configuration loaded successfully.\")\n",
    "        # Create a backup of original config for reference\n",
    "        config_original = copy.deepcopy(config)\n",
    "        # Print some key configuration settings\n",
    "        print(\"\\nKey Configuration Settings:\")\n",
    "        print(f\"Photobleaching correction method: {config['preprocessing'].get('correction_method', 'Not specified')}\")\n",
    "        print(f\"Motion correction enabled: {config.get('motion_correction', {}).get('enabled', False)}\")\n",
    "        if 'denoise' in config['preprocessing']:\n",
    "            print(f\"Denoising enabled: {config['preprocessing']['denoise'].get('enabled', False)}\")\n",
    "        if 'background_removal' in config['preprocessing']:\n",
    "            print(f\"Background removal enabled: {config['preprocessing']['background_removal'].get('enabled', False)}\")\n",
    "        print(f\"Background subtraction method: {config['roi_processing'].get('background', {}).get('method', 'Not specified')}\")\n",
    "    else:\n",
    "        print(\"Failed to load configuration. Please check the config file path.\")\n",
    "\n",
    "load_config_button.on_click(on_load_config_click)\n",
    "display(load_config_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7234c599-2e19-4c29-8da5-ff0752f5d4fb",
   "metadata": {},
   "source": [
    "## Data Selection and Loading\n",
    "\n",
    "This section allows you to select a file pair (TIF image stack and ZIP ROI file) for analysis. The pipeline searches for matching file pairs in the input directory.\n",
    "\n",
    "### File Pairs\n",
    "A file pair consists of:\n",
    "- A **.tif file** containing the fluorescence imaging data (time series of frames)\n",
    "- A **.zip file** containing ImageJ/FIJI ROI definitions\n",
    "\n",
    "### Loading Process\n",
    "When you load a file pair, the following happens:\n",
    "1. The TIF stack is loaded and preprocessed\n",
    "2. ROI masks are extracted from the ZIP file\n",
    "3. Intermediate data is prepared for interactive visualization\n",
    "4. Visualization data is saved for future use\n",
    "\n",
    "Select a file pair from the dropdown menu and click \"Load Selected File Pair\" to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d80dd3-55de-4a1b-84c7-43a964f95c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Select and Load Data {display-mode: \"form\"}\n",
    "\n",
    "def select_and_load_data():\n",
    "    \"\"\"Select and load a TIFF file for analysis\"\"\"\n",
    "    global image_data, tif_path\n",
    "    \n",
    "    # Check if input directory exists\n",
    "    if not os.path.exists(args.input_dir):\n",
    "        print(f\"Input directory {args.input_dir} does not exist!\")\n",
    "        return\n",
    "    \n",
    "    # Get list of TIFF files\n",
    "    tiff_files = sorted([f for f in os.listdir(args.input_dir) if f.endswith(('.tif', '.tiff'))])\n",
    "    \n",
    "    if not tiff_files:\n",
    "        print(f\"No TIFF files found in {args.input_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Create file selection widget\n",
    "    file_selector = widgets.Dropdown(\n",
    "        options=tiff_files,\n",
    "        description='Select TIFF file:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "    \n",
    "    max_frames_slider = widgets.IntSlider(\n",
    "        value=100,\n",
    "        min=50,\n",
    "        max=500,\n",
    "        step=50,\n",
    "        description='Max Frames:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    load_button = widgets.Button(\n",
    "        description='Load Data',\n",
    "        button_style='success',\n",
    "        tooltip='Click to load the selected TIFF file'\n",
    "    )\n",
    "    \n",
    "    info_output = widgets.Output()\n",
    "    \n",
    "    def on_load_click(b):\n",
    "        with info_output:\n",
    "            clear_output()\n",
    "            print(f\"Loading {file_selector.value}...\")\n",
    "            \n",
    "            try:\n",
    "                # Set global tif_path\n",
    "                global tif_path\n",
    "                tif_path = os.path.join(args.input_dir, file_selector.value)\n",
    "                \n",
    "                # Load limited frames to save memory\n",
    "                with tifffile.TiffFile(tif_path) as tif:\n",
    "                    n_frames = min(max_frames_slider.value, len(tif.pages))\n",
    "                    global image_data\n",
    "                    image_data = np.zeros((n_frames, tif.pages[0].shape[0], tif.pages[0].shape[1]), dtype=np.float32)\n",
    "                    \n",
    "                    for i in range(n_frames):\n",
    "                        image_data[i] = tif.pages[i].asarray()\n",
    "                    \n",
    "                    print(f\"Loaded {n_frames} frames with shape {image_data.shape[1]}x{image_data.shape[2]}\")\n",
    "                    print(\"Data statistics:\")\n",
    "                    print(f\"  Min: {image_data.min():.2f}\")\n",
    "                    print(f\"  Max: {image_data.max():.2f}\")\n",
    "                    print(f\"  Mean: {image_data.mean():.2f}\")\n",
    "                    print(f\"Data loaded successfully. You can now proceed with processing steps.\")\n",
    "                    \n",
    "                    # Display a sample frame\n",
    "                    plt.figure(figsize=(8, 8))\n",
    "                    plt.imshow(image_data[0], cmap='gray')\n",
    "                    plt.title(f\"First Frame of {file_selector.value}\")\n",
    "                    plt.colorbar(label='Intensity')\n",
    "                    plt.show()\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading file: {str(e)}\")\n",
    "    \n",
    "    load_button.on_click(on_load_click)\n",
    "    \n",
    "    # Display widgets\n",
    "    display(widgets.VBox([\n",
    "        file_selector, \n",
    "        max_frames_slider, \n",
    "        load_button, \n",
    "        info_output\n",
    "    ]))\n",
    "\n",
    "# Initialize global variables\n",
    "image_data = None\n",
    "tif_path = None\n",
    "\n",
    "# Run the function\n",
    "select_and_load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb7132b-9a80-4224-9a46-a70af5e0979d",
   "metadata": {},
   "source": [
    "## Load Previously Saved Visualization Data\n",
    "\n",
    "If you've previously run this notebook and saved visualization data, you can load it here instead of reprocessing the data. This saves time when you want to continue exploring the same dataset.\n",
    "\n",
    "The visualization data includes:\n",
    "- Original image data\n",
    "- Preprocessed (corrected) data\n",
    "- ROI masks and centers\n",
    "- ROI fluorescence traces\n",
    "- Metadata extracted from the filename\n",
    "\n",
    "Enter the path to the saved visualization data file (`visualization_data.pkl`) and click \"Load Saved Visualization Data\" to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f916e-5182-403c-b8ea-b5ccc739352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Load Saved Visualization Data {display-mode: \"form\"}\n",
    "def load_visualization_data(data_file):\n",
    "    \"\"\"Load saved visualization data from pickle file\"\"\"\n",
    "    try:\n",
    "        with open(data_file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Assign to global variables for use in visualizations\n",
    "        global image_data, corrected_data, roi_masks, roi_centers, roi_data, metadata, selected_tif_path, selected_roi_path, image_shape\n",
    "        image_data = data['image_data']\n",
    "        corrected_data = data['corrected_data']\n",
    "        roi_masks = data['roi_masks']\n",
    "        roi_centers = data['roi_centers']\n",
    "        roi_data = data['roi_data']\n",
    "        metadata = data['metadata']\n",
    "        selected_tif_path = data['selected_tif_path']\n",
    "        selected_roi_path = data['selected_roi_path']\n",
    "        image_shape = data['image_shape']\n",
    "        \n",
    "        print(\"Visualization data loaded successfully!\")\n",
    "        print(f\"File: {Path(selected_tif_path).stem}\")\n",
    "        print(f\"Image shape: {image_data.shape}\")\n",
    "        print(f\"Number of ROIs: {len(roi_masks)}\")\n",
    "        print(f\"Condition: {metadata.get('condition', 'unknown')}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading visualization data: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Widget to select a visualization data file\n",
    "vis_data_path_widget = widgets.Text(\n",
    "    placeholder='Enter path to visualization_data.pkl file',\n",
    "    description='Data File:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "load_vis_data_button = widgets.Button(\n",
    "    description='Load Saved Visualization Data',\n",
    "    button_style='info',\n",
    "    tooltip='Load previously saved visualization data'\n",
    ")\n",
    "\n",
    "def on_load_vis_data_click(b):\n",
    "    path = vis_data_path_widget.value\n",
    "    if path:\n",
    "        success = load_visualization_data(path)\n",
    "        if success:\n",
    "            print(\"Ready for visualization!\")\n",
    "    else:\n",
    "        print(\"Please enter a valid path to the visualization_data.pkl file\")\n",
    "\n",
    "load_vis_data_button.on_click(on_load_vis_data_click)\n",
    "display(vis_data_path_widget)\n",
    "display(load_vis_data_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c5f206-be58-40c2-80d5-f120ff93b32c",
   "metadata": {},
   "source": [
    "## Motion Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1e7326-b97e-4385-9441-57036f468e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Motion Correction {display-mode: \"form\"}\n",
    "def run_motion_correction():\n",
    "    \"\"\"Run interactive motion correction visualization\"\"\"\n",
    "    global image_data, config, selected_tif_path\n",
    "    \n",
    "    if 'image_data' not in globals() or image_data is None:\n",
    "        print(\"Please load image data first\")\n",
    "        return\n",
    "    \n",
    "    if 'config' not in globals() or config is None:\n",
    "        print(\"Please load configuration first\")\n",
    "        return\n",
    "    \n",
    "    # Create the visualization\n",
    "    motion_app = run_motion_correction_visualization(image_data, selected_tif_path, config, logger)\n",
    "    \n",
    "    if motion_app is not None:\n",
    "        display(motion_app)\n",
    "    else:\n",
    "        print(\"Failed to create motion correction visualization.\")\n",
    "        print(\"Make sure HoloViews and Panel are installed:\")\n",
    "        print(\"pip install holoviews panel param bokeh\")\n",
    "\n",
    "# Run the function\n",
    "run_motion_correction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2f7380-fb0a-448e-ba29-234bb2a92cf3",
   "metadata": {},
   "source": [
    "## Photobleaching Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bff702-3191-4f67-a128-c9858d3da9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Photobleaching Correction {display-mode: \"form\"}\n",
    "def run_photobleaching_correction():\n",
    "    \"\"\"Apply photobleaching correction\"\"\"\n",
    "    global image_data, config, corrected_data\n",
    "    \n",
    "    if 'image_data' not in globals() or image_data is None:\n",
    "        print(\"Image data not found. Please make sure you've loaded data using the 'Load and Explore Data' cell.\")\n",
    "        print(\"If you've loaded data but still see this error, try running the following code to verify data availability:\")\n",
    "        print(\"print('Available variables:', [var for var in globals() if not var.startswith('_')])\")\n",
    "        print(\"print('Image data shape:', image_data.shape if 'image_data' in globals() and image_data is not None else 'Not available')\")\n",
    "        return\n",
    "    \n",
    "    if 'config' not in globals() or config is None:\n",
    "        print(\"Please load configuration first\")\n",
    "        return\n",
    "    \n",
    "    # Get photobleaching correction parameters\n",
    "    method = widgets.Dropdown(\n",
    "        options=[\n",
    "            ('Polynomial Detrend', 'polynomial_detrend'),\n",
    "            ('Exponential Decay', 'exponential_decay'),\n",
    "            ('Bi-Exponential', 'bi_exponential'),\n",
    "            ('Adaptive Percentile', 'adaptive_percentile'),\n",
    "            ('Two-Stage Detrend', 'two_stage_detrend')\n",
    "        ],\n",
    "        value=config['preprocessing'].get('correction_method', 'polynomial_detrend'),\n",
    "        description='Method:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    polynomial_order = widgets.IntSlider(\n",
    "        value=config['preprocessing'].get('polynomial_order', 3),\n",
    "        min=1,\n",
    "        max=5,\n",
    "        step=1,\n",
    "        description='Polynomial Order:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    smoothing_sigma = widgets.FloatSlider(\n",
    "        value=config['preprocessing'].get('smoothing_sigma', 2.0),\n",
    "        min=0.0,\n",
    "        max=5.0,\n",
    "        step=0.1,\n",
    "        description='Smoothing Sigma:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    generate_plot = widgets.Checkbox(\n",
    "        value=config['preprocessing'].get('generate_plot', True),\n",
    "        description='Generate Plot',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    run_button = widgets.Button(\n",
    "        description='Run Correction',\n",
    "        button_style='warning',\n",
    "        tooltip='Click to run photobleaching correction'\n",
    "    )\n",
    "    \n",
    "    info_output = widgets.Output()\n",
    "    \n",
    "    def on_run_click(b):\n",
    "        with info_output:\n",
    "            clear_output()\n",
    "            print(f\"Running photobleaching correction with method: {method.value}\")\n",
    "            \n",
    "            # Update config with current values\n",
    "            config['preprocessing']['correction_method'] = method.value\n",
    "            config['preprocessing']['polynomial_order'] = polynomial_order.value\n",
    "            config['preprocessing']['smoothing_sigma'] = smoothing_sigma.value\n",
    "            config['preprocessing']['generate_plot'] = generate_plot.value\n",
    "            \n",
    "            try:\n",
    "                # Apply photobleaching correction\n",
    "                global corrected_data\n",
    "                corrected_data, _ = correct_photobleaching(\n",
    "                    image_data,\n",
    "                    None,  # No output path needed\n",
    "                    config['preprocessing'],\n",
    "                    logger,\n",
    "                    save_output=False\n",
    "                )\n",
    "                \n",
    "                print(\"Photobleaching correction completed successfully.\")\n",
    "                \n",
    "                # Plot mean intensity before and after correction\n",
    "                mean_original = np.mean(image_data, axis=(1, 2))\n",
    "                mean_corrected = np.mean(corrected_data, axis=(1, 2))\n",
    "                \n",
    "                fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), gridspec_kw={'height_ratios': [3, 1]})\n",
    "                \n",
    "                # Format method name for display\n",
    "                method_display = method.value.replace('_', ' ').title()\n",
    "                \n",
    "                # Plot mean intensity over time\n",
    "                ax1.plot(mean_original, 'r-', alpha=0.7, label='Original')\n",
    "                ax1.plot(mean_corrected, 'g-', alpha=0.7, label=f'Corrected ({method_display})')\n",
    "                ax1.set_title('Photobleaching Correction Verification', fontsize=14)\n",
    "                ax1.set_xlabel('Frame')\n",
    "                ax1.set_ylabel('Mean Intensity')\n",
    "                ax1.legend(loc='best')\n",
    "                ax1.grid(True, alpha=0.3)\n",
    "                \n",
    "                # Plot the correction factor (ratio between original and corrected)\n",
    "                correction_factor = mean_corrected / np.maximum(mean_original, 1e-6)\n",
    "                ax2.plot(correction_factor, 'b-', alpha=0.7)\n",
    "                ax2.set_title('Correction Factor', fontsize=12)\n",
    "                ax2.set_xlabel('Frame')\n",
    "                ax2.set_ylabel('Factor')\n",
    "                ax2.grid(True, alpha=0.3)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                # Show a before/after frame comparison\n",
    "                sample_frame = 50  # Use frame 50 for comparison\n",
    "                if sample_frame >= len(image_data):\n",
    "                    sample_frame = len(image_data) // 2\n",
    "                \n",
    "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "                \n",
    "                ax1.imshow(image_data[sample_frame], cmap='gray')\n",
    "                ax1.set_title(f\"Original (Frame {sample_frame})\")\n",
    "                ax1.axis('off')\n",
    "                \n",
    "                ax2.imshow(corrected_data[sample_frame], cmap='gray')\n",
    "                ax2.set_title(f\"Corrected (Frame {sample_frame})\")\n",
    "                ax2.axis('off')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                # Display button to proceed with corrected data\n",
    "                print(\"\\nPhotobleaching correction is complete. The corrected data is now available.\")\n",
    "                print(\"You can now proceed to ROI extraction and analysis.\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error during photobleaching correction: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "    \n",
    "    run_button.on_click(on_run_click)\n",
    "    \n",
    "    # Create description of methods\n",
    "    method_info = widgets.HTML(\n",
    "        \"\"\"\n",
    "        <h3>Photobleaching Correction Methods:</h3>\n",
    "        <ul>\n",
    "            <li><strong>Polynomial Detrend</strong>: Fits a polynomial to mean intensities and normalizes. Good for simple bleaching patterns.</li>\n",
    "            <li><strong>Exponential Decay</strong>: Models bleaching as an exponential decay. Good for typical photobleaching.</li>\n",
    "            <li><strong>Bi-Exponential</strong>: Uses two exponential components for complex decay patterns.</li>\n",
    "            <li><strong>Adaptive Percentile</strong>: Uses a sliding window percentile approach. More adaptive to complex patterns.</li>\n",
    "            <li><strong>Two-Stage Detrend</strong>: Applies two polynomial fits in sequence. Good for mixed decay patterns.</li>\n",
    "        </ul>\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Display widgets\n",
    "    display(method_info)\n",
    "    display(widgets.VBox([\n",
    "        method,\n",
    "        polynomial_order,\n",
    "        smoothing_sigma,\n",
    "        generate_plot,\n",
    "        run_button,\n",
    "        info_output\n",
    "    ]))\n",
    "\n",
    "# Initialize corrected_data\n",
    "corrected_data = None\n",
    "\n",
    "# Run the function\n",
    "run_photobleaching_correction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a395f40-f042-46b8-a2d4-3fe69811c5b5",
   "metadata": {},
   "source": [
    "## Gaussian Denoising\n",
    "\n",
    "Gaussian denoising helps reduce noise in fluorescence images while preserving important features. This is particularly important for accurately identifying ROIs and detecting events in your calcium imaging data.\n",
    "\n",
    "### How It Works\n",
    "The Gaussian blur operation applies a weighted average to each pixel, where nearby pixels have more influence than distant ones. The weighting follows a Gaussian distribution centered at the pixel being processed.\n",
    "\n",
    "### Key Parameters\n",
    "- **Kernel Size**: Controls the size of the filter window (must be odd). Larger values remove more noise but may blur important details.\n",
    "- **Sigma**: Controls the width of the Gaussian distribution. Higher values produce more blurring and stronger noise reduction.\n",
    "\n",
    "### Finding Optimal Values\n",
    "The best parameters balance noise reduction and feature preservation:\n",
    "- For noisy recordings, try larger kernel sizes (7-11) and higher sigma values (2-4)\n",
    "- For cleaner recordings, use smaller kernels (3-5) and lower sigma values (0.5-1.5)\n",
    "\n",
    "Use the interactive tool below to experiment with different settings and observe their effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7408fa-590e-4d31-88f3-38b24becd512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "# Import our custom visualization module\n",
    "from modules.visualization_helpers import run_denoising_visualization\n",
    "\n",
    "# Setup configuration dictionary\n",
    "if 'config' not in globals():\n",
    "    config = {\n",
    "        'preprocessing': {\n",
    "            'denoise': {\n",
    "                'enabled': False,\n",
    "                'method': 'gaussian',\n",
    "                'params': {'ksize': (5, 5), 'sigmaX': 1.5}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "# @title Advanced Denoising with Contour Plots {display-mode: \"form\"}\n",
    "def run_denoising():\n",
    "    \"\"\"Run interactive denoising visualization with contour plots\"\"\"\n",
    "    global image_data, config, corrected_data\n",
    "    \n",
    "    # Use corrected data if available, otherwise use original image data\n",
    "    data_to_use = corrected_data if 'corrected_data' in globals() and corrected_data is not None else image_data\n",
    "    \n",
    "    if data_to_use is None:\n",
    "        print(\"Please load image data first\")\n",
    "        return\n",
    "    \n",
    "    if 'config' not in globals() or config is None:\n",
    "        print(\"Please load configuration first\")\n",
    "        return\n",
    "    \n",
    "    # Create the visualization\n",
    "    denoising_app = run_denoising_visualization(data_to_use, config, logger)\n",
    "    \n",
    "    if denoising_app is not None:\n",
    "        display(denoising_app)\n",
    "    else:\n",
    "        print(\"Failed to create denoising visualization.\")\n",
    "        print(\"Make sure HoloViews and Panel are installed:\")\n",
    "        print(\"pip install holoviews panel param bokeh\")\n",
    "\n",
    "# Run the function\n",
    "run_denoising()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d49aac-7c9c-4c44-be0d-4fb22df9b93b",
   "metadata": {},
   "source": [
    "## Background Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c404b7-df8c-4168-a0ef-e6b06aff5a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Background Removal {display-mode: \"form\"}\n",
    "def run_background_removal():\n",
    "    \"\"\"Run interactive background removal visualization\"\"\"\n",
    "    global image_data, config, corrected_data\n",
    "    \n",
    "    # Use corrected data if available, otherwise use original image data\n",
    "    data_to_use = corrected_data if 'corrected_data' in globals() and corrected_data is not None else image_data\n",
    "    \n",
    "    if data_to_use is None:\n",
    "        print(\"Please load image data first\")\n",
    "        return\n",
    "    \n",
    "    if 'config' not in globals() or config is None:\n",
    "        print(\"Please load configuration first\")\n",
    "        return\n",
    "    \n",
    "    # Create a custom implementation of background removal visualization\n",
    "    # This avoids compatibility issues with HoloViews parameter naming\n",
    "    \n",
    "    # Get method options\n",
    "    method = widgets.Dropdown(\n",
    "        options=[\n",
    "            ('Uniform', 'uniform'),\n",
    "            ('Tophat', 'tophat')\n",
    "        ],\n",
    "        value='uniform',\n",
    "        description='Method:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Window size parameter\n",
    "    window_size = widgets.IntSlider(\n",
    "        value=7,\n",
    "        min=3,\n",
    "        max=99,\n",
    "        step=2,\n",
    "        description='Window Size:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Output for displaying results\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    # Run button\n",
    "    run_button = widgets.Button(\n",
    "        description='Apply Background Removal',\n",
    "        button_style='success',\n",
    "        tooltip='Click to run background removal'\n",
    "    )\n",
    "    \n",
    "    def on_button_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(f\"Applying {method.value} background removal with window size {window_size.value}...\")\n",
    "            \n",
    "            try:\n",
    "                # Get the selected frame\n",
    "                frame_idx = 10  # Use frame 10 as example\n",
    "                if frame_idx >= data_to_use.shape[0]:\n",
    "                    frame_idx = data_to_use.shape[0] // 2\n",
    "                \n",
    "                sample_frame = data_to_use[frame_idx].copy()\n",
    "                \n",
    "                # For tophat, create disk element\n",
    "                selem = None\n",
    "                if method.value == 'tophat':\n",
    "                    # Use skimage's disk function if available\n",
    "                    try:\n",
    "                        from skimage.morphology import disk\n",
    "                        selem = disk(window_size.value)\n",
    "                    except ImportError:\n",
    "                        print(\"skimage.morphology.disk not available. Using default structuring element.\")\n",
    "                \n",
    "                # Apply background removal\n",
    "                import time\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Import function from local module to avoid namespace issues\n",
    "                from modules.visualization_helpers import remove_background_perframe\n",
    "                \n",
    "                bg_removed_frame = remove_background_perframe(sample_frame, method.value, \n",
    "                                                             window_size.value, selem)\n",
    "                \n",
    "                process_time = time.time() - start_time\n",
    "                \n",
    "                # Calculate difference\n",
    "                diff = np.abs(sample_frame - bg_removed_frame)\n",
    "                \n",
    "                # Get a central row for profile\n",
    "                center_row = sample_frame.shape[0] // 2\n",
    "                original_profile = sample_frame[center_row, :]\n",
    "                bg_removed_profile = bg_removed_frame[center_row, :]\n",
    "                \n",
    "                # Plot the results\n",
    "                fig = plt.figure(figsize=(15, 10))\n",
    "                \n",
    "                # Original frame\n",
    "                ax1 = fig.add_subplot(231)\n",
    "                ax1.imshow(sample_frame, cmap='gray')\n",
    "                ax1.set_title('Original Frame')\n",
    "                ax1.axis('off')\n",
    "                \n",
    "                # Background removed\n",
    "                ax2 = fig.add_subplot(232)\n",
    "                ax2.imshow(bg_removed_frame, cmap='gray')\n",
    "                ax2.set_title(f'{method.value.title()} Background Removal\\nWindow: {window_size.value}, Time: {process_time:.3f}s')\n",
    "                ax2.axis('off')\n",
    "                \n",
    "                # Difference\n",
    "                ax3 = fig.add_subplot(233)\n",
    "                ax3.imshow(diff, cmap='gray') #previously 'hot'\n",
    "                ax3.set_title('Difference (Removed Background)')\n",
    "                ax3.axis('off')\n",
    "                \n",
    "                # Intensity profile\n",
    "                ax4 = fig.add_subplot(212)\n",
    "                ax4.plot(original_profile, 'b-', alpha=0.8, label='Original')\n",
    "                ax4.plot(bg_removed_profile, 'r-', alpha=0.8, label='Background Removed')\n",
    "                ax4.set_title('Intensity Profile (Center Row)')\n",
    "                ax4.set_xlabel('Pixel')\n",
    "                ax4.set_ylabel('Intensity')\n",
    "                ax4.grid(True, alpha=0.3)\n",
    "                ax4.legend()\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                # Update config with current values\n",
    "                if 'background_removal' not in config['preprocessing']:\n",
    "                    config['preprocessing']['background_removal'] = {}\n",
    "                \n",
    "                config['preprocessing']['background_removal']['enabled'] = True\n",
    "                config['preprocessing']['background_removal']['method'] = method.value\n",
    "                config['preprocessing']['background_removal']['window_size'] = window_size.value\n",
    "                \n",
    "                print(f\"Background removal complete. Parameters added to configuration.\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error applying {method.value} background removal: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "    \n",
    "    run_button.on_click(on_button_click)\n",
    "    \n",
    "    # Create method descriptions\n",
    "    method_descriptions = widgets.HTML(\n",
    "        \"\"\"\n",
    "        <h3>Background Removal Methods:</h3>\n",
    "        <ul>\n",
    "            <li><strong>Uniform</strong>: Removes background by subtracting a uniformly blurred version of the image. Good for removing slow variations in background intensity.</li>\n",
    "            <li><strong>Tophat</strong>: Uses morphological top-hat transformation to enhance small features while removing background. Excellent for extracting small bright features from varying backgrounds.</li>\n",
    "        </ul>\n",
    "        <p><em>Adjust the window size parameter to control how much background is removed. Larger values remove more broadly distributed background structures.</em></p>\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Display everything\n",
    "    display(method_descriptions)\n",
    "    display(widgets.VBox([method, window_size, run_button]))\n",
    "    display(output)\n",
    "\n",
    "# Run the function\n",
    "run_background_removal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358d74a0-180b-4f1c-83e5-1520b102e488",
   "metadata": {},
   "source": [
    "## Extract ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc119667-119a-452c-ac8a-b21cd4da8e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Extract ROIs {display-mode: \"form\"}\n",
    "\n",
    "def extract_rois():\n",
    "    \"\"\"Extract ROIs from a zip file\"\"\"\n",
    "    global corrected_data, image_data, config, roi_masks, roi_data, tif_path\n",
    "    \n",
    "    # Use corrected data if available, otherwise use original data\n",
    "    data_to_use = corrected_data if corrected_data is not None else image_data\n",
    "    \n",
    "    if data_to_use is None:\n",
    "        print(\"Please load or process image data first\")\n",
    "        return\n",
    "    \n",
    "    if 'config' not in globals() or config is None:\n",
    "        print(\"Please load configuration first\")\n",
    "        return\n",
    "    \n",
    "    # Get list of ZIP files in input directory\n",
    "    zip_files = sorted([f for f in os.listdir(args.input_dir) if f.endswith('.zip')])\n",
    "    \n",
    "    if not zip_files:\n",
    "        print(f\"No ZIP files found in {args.input_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Create file selection widget\n",
    "    zip_selector = widgets.Dropdown(\n",
    "        options=zip_files,\n",
    "        description='Select ROI file:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "    \n",
    "    run_button = widgets.Button(\n",
    "        description='Extract ROIs',\n",
    "        button_style='warning',\n",
    "        tooltip='Click to extract ROIs'\n",
    "    )\n",
    "    \n",
    "    info_output = widgets.Output()\n",
    "    \n",
    "    def on_run_click(b):\n",
    "        with info_output:\n",
    "            clear_output()\n",
    "            print(f\"Extracting ROIs from {zip_selector.value}...\")\n",
    "            \n",
    "            try:\n",
    "                # Set path to ROI zip file\n",
    "                roi_path = os.path.join(args.input_dir, zip_selector.value)\n",
    "                \n",
    "                # Create temporary output directory\n",
    "                temp_output_dir = os.path.join(args.output_dir, \"temp_output\")\n",
    "                os.makedirs(temp_output_dir, exist_ok=True)\n",
    "                \n",
    "                # Get image shape\n",
    "                image_shape = data_to_use.shape[1:]\n",
    "                \n",
    "                # Extract ROIs\n",
    "                global roi_masks, roi_data\n",
    "                roi_masks, roi_data = extract_roi_fluorescence(\n",
    "                    roi_path,\n",
    "                    data_to_use,\n",
    "                    image_shape,\n",
    "                    temp_output_dir,\n",
    "                    config[\"roi_processing\"],\n",
    "                    logger\n",
    "                )\n",
    "                \n",
    "                print(f\"Extracted {len(roi_masks)} ROIs\")\n",
    "                \n",
    "                # Display ROI visualization\n",
    "                # Create a composite mask with all ROIs\n",
    "                composite_mask = np.zeros(image_shape, dtype=np.uint8)\n",
    "                \n",
    "                # Assign different colors to each ROI\n",
    "                for i, mask in enumerate(roi_masks):\n",
    "                    # Add ROI to composite with unique intensity\n",
    "                    composite_mask[mask] = i + 1\n",
    "                \n",
    "                # Create a color-coded visualization\n",
    "                vis_image = np.zeros((*image_shape, 3), dtype=np.uint8)\n",
    "                \n",
    "                # Generate random colors for each ROI\n",
    "                np.random.seed(0)  # For reproducibility\n",
    "                colors = np.random.randint(50, 255, size=(len(roi_masks), 3))\n",
    "                \n",
    "                # Apply colors to ROIs\n",
    "                for i in range(len(roi_masks)):\n",
    "                    roi_indices = composite_mask == (i + 1)\n",
    "                    vis_image[roi_indices] = colors[i]\n",
    "                \n",
    "                # Display ROI image overlaid on the first frame\n",
    "                plt.figure(figsize=(10, 10))\n",
    "                \n",
    "                # First frame as background\n",
    "                plt.imshow(data_to_use[0], cmap='gray')\n",
    "                \n",
    "                # Overlay ROIs with transparency\n",
    "                plt.imshow(vis_image, alpha=0.5)\n",
    "                \n",
    "                plt.title(f\"Extracted ROIs ({len(roi_masks)} total)\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "                \n",
    "                # Plot some sample traces\n",
    "                n_samples = min(5, len(roi_masks))\n",
    "                plt.figure(figsize=(12, 2*n_samples))\n",
    "                \n",
    "                for i in range(n_samples):\n",
    "                    plt.subplot(n_samples, 1, i+1)\n",
    "                    plt.plot(roi_data[i])\n",
    "                    plt.title(f\"ROI {i+1} Trace\")\n",
    "                    plt.xlabel(\"Frame\")\n",
    "                    plt.ylabel(\"Fluorescence\")\n",
    "                    plt.grid(True, alpha=0.3)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                # Display next steps message\n",
    "                print(\"\\nROI extraction complete. You can now proceed to background subtraction and analysis.\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting ROIs: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "    \n",
    "    run_button.on_click(on_run_click)\n",
    "    \n",
    "    # Display widgets\n",
    "    display(widgets.VBox([\n",
    "        zip_selector,\n",
    "        run_button,\n",
    "        info_output\n",
    "    ]))\n",
    "\n",
    "# Initialize ROI variables\n",
    "roi_masks = None\n",
    "roi_data = None\n",
    "\n",
    "# Run the function\n",
    "extract_rois()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e6ace-a639-4cd7-8646-f7c669291db1",
   "metadata": {},
   "source": [
    "## Background Subtraction\n",
    "\n",
    "Background subtraction removes non-specific fluorescence signals that can mask the true neuronal activity. This improves signal-to-noise ratio and helps detect true calcium events.\n",
    "\n",
    "### Available Methods\n",
    "1. **Darkest Pixels**: Uses the darkest regions of the image (likely non-cellular regions) to estimate background\n",
    "2. **ROI Periphery**: Estimates background from the area surrounding each ROI\n",
    "3. **Global Background**: Uses a global approach to identify and subtract background signal\n",
    "\n",
    "### Key Parameters\n",
    "- **Percentile (%)**: For darkest pixels method, determines how much of the image is considered background\n",
    "- **Min Background Area**: Minimum size of the area to be considered a valid background region\n",
    "- **Median Filter Size**: Size of median filter for noise reduction in background mask\n",
    "- **Periphery Size**: For ROI periphery method, size of the expansion around ROIs\n",
    "\n",
    "### Finding Optimal Values\n",
    "- For darkest pixels, start with a low percentile (0.1-1%) and increase if needed\n",
    "- Larger median filter sizes produce smoother background but may miss spatial variations\n",
    "- For ROI periphery, larger values capture more surrounding tissue but risk including other cells\n",
    "\n",
    "The interactive tool below allows you to visualize how different background subtraction methods and parameters affect your fluorescence traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e675dfd9-26d8-462b-a679-3238a1c25276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Background Subtraction {display-mode: \"form\"}\n",
    "def run_background_subtraction():\n",
    "    \"\"\"Interactive background subtraction for ROI traces\"\"\"\n",
    "    global corrected_data, roi_masks, roi_data, config\n",
    "    \n",
    "    if 'corrected_data' not in globals() or corrected_data is None:\n",
    "        print(\"Please run photobleaching correction first\")\n",
    "        return\n",
    "    \n",
    "    if 'roi_masks' not in globals() or roi_masks is None or 'roi_data' not in globals() or roi_data is None:\n",
    "        print(\"Please extract ROIs first\")\n",
    "        return\n",
    "    \n",
    "    if 'config' not in globals() or config is None:\n",
    "        print(\"Please load configuration first\")\n",
    "        return\n",
    "    \n",
    "    # Get background subtraction parameters\n",
    "    method = widgets.Dropdown(\n",
    "        options=[\n",
    "            ('ROI Periphery', 'roi_periphery'),\n",
    "            ('Darkest Pixels', 'darkest_pixels'),\n",
    "            ('Global Background', 'global_background'),\n",
    "            ('Lowpass Filter', 'lowpass_filter')\n",
    "        ],\n",
    "        value=config['roi_processing'].get('background', {}).get('method', 'roi_periphery'),\n",
    "        description='Method:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Parameters for ROI periphery\n",
    "    periphery_size = widgets.IntSlider(\n",
    "        value=config['roi_processing'].get('background', {}).get('periphery_size', 2),\n",
    "        min=1,\n",
    "        max=10,\n",
    "        step=1,\n",
    "        description='Periphery Size:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Parameters for darkest pixels\n",
    "    percentile = widgets.FloatSlider(\n",
    "        value=config['roi_processing'].get('background', {}).get('percentile', 0.1),\n",
    "        min=0.01,\n",
    "        max=1.0,\n",
    "        step=0.01,\n",
    "        description='Percentile:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    median_filter_size = widgets.IntSlider(\n",
    "        value=config['roi_processing'].get('background', {}).get('median_filter_size', 3),\n",
    "        min=0,\n",
    "        max=19,\n",
    "        step=1,\n",
    "        description='Median Filter:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    dilation_size = widgets.IntSlider(\n",
    "        value=config['roi_processing'].get('background', {}).get('dilation_size', 2),\n",
    "        min=0,\n",
    "        max=10,\n",
    "        step=1,\n",
    "        description='Dilation Size:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Parameters for global background\n",
    "    min_background_area = widgets.IntSlider(\n",
    "        value=config['roi_processing'].get('background', {}).get('min_background_area', 200),\n",
    "        min=50,\n",
    "        max=1000,\n",
    "        step=50,\n",
    "        description='Min Area:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    background_dilation = widgets.IntSlider(\n",
    "        value=config['roi_processing'].get('background', {}).get('background_dilation', 2),\n",
    "        min=0,\n",
    "        max=10,\n",
    "        step=1,\n",
    "        description='BG Dilation:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Parameters for lowpass filter\n",
    "    cutoff_freq = widgets.FloatSlider(\n",
    "        value=config['roi_processing'].get('background', {}).get('cutoff_freq', 0.001),\n",
    "        min=0.0001,\n",
    "        max=0.01,\n",
    "        step=0.0001,\n",
    "        description='Cutoff Freq:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    filter_order = widgets.IntSlider(\n",
    "        value=config['roi_processing'].get('background', {}).get('filter_order', 2),\n",
    "        min=1,\n",
    "        max=6,\n",
    "        step=1,\n",
    "        description='Filter Order:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Add slope correction checkbox\n",
    "    apply_slope_correction = widgets.Checkbox(\n",
    "        value=True,\n",
    "        description='Apply Slope Correction After Background Subtraction',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Create parameter containers for each method\n",
    "    roi_periphery_params = widgets.VBox([periphery_size])\n",
    "    darkest_pixels_params = widgets.VBox([percentile, median_filter_size, dilation_size])\n",
    "    global_background_params = widgets.VBox([min_background_area, background_dilation])\n",
    "    lowpass_filter_params = widgets.VBox([cutoff_freq, filter_order])\n",
    "    \n",
    "    # Container for method-specific parameters\n",
    "    params_container = widgets.Output()\n",
    "    \n",
    "    # Show parameters based on selected method\n",
    "    def update_params(change):\n",
    "        with params_container:\n",
    "            clear_output()\n",
    "            if change.new == 'roi_periphery':\n",
    "                display(roi_periphery_params)\n",
    "            elif change.new == 'darkest_pixels':\n",
    "                display(darkest_pixels_params)\n",
    "            elif change.new == 'global_background':\n",
    "                display(global_background_params)\n",
    "            elif change.new == 'lowpass_filter':\n",
    "                display(lowpass_filter_params)\n",
    "    \n",
    "    method.observe(update_params, names='value')\n",
    "    \n",
    "    # Display initial parameters\n",
    "    with params_container:\n",
    "        if method.value == 'roi_periphery':\n",
    "            display(roi_periphery_params)\n",
    "        elif method.value == 'darkest_pixels':\n",
    "            display(darkest_pixels_params)\n",
    "        elif method.value == 'global_background':\n",
    "            display(global_background_params)\n",
    "        elif method.value == 'lowpass_filter':\n",
    "            display(lowpass_filter_params)\n",
    "    \n",
    "    # Create a temporary output directory for intermediate results\n",
    "    temp_output_dir = os.path.join(args.output_dir, 'temp_bg_subtraction')\n",
    "    os.makedirs(temp_output_dir, exist_ok=True)\n",
    "    \n",
    "    run_button = widgets.Button(\n",
    "        description='Run Background Subtraction',\n",
    "        button_style='success',\n",
    "        tooltip='Apply background subtraction to ROI traces'\n",
    "    )\n",
    "    \n",
    "    info_output = widgets.Output()\n",
    "    \n",
    "    def on_run_click(b):\n",
    "        with info_output:\n",
    "            clear_output()\n",
    "            print(f\"Running background subtraction with method: {method.value}\")\n",
    "            \n",
    "            # Update config with current values\n",
    "            if 'background' not in config['roi_processing']:\n",
    "                config['roi_processing']['background'] = {}\n",
    "            \n",
    "            config['roi_processing']['background']['method'] = method.value\n",
    "            \n",
    "            if method.value == 'roi_periphery':\n",
    "                config['roi_processing']['background']['periphery_size'] = periphery_size.value\n",
    "            elif method.value == 'darkest_pixels':\n",
    "                config['roi_processing']['background']['percentile'] = percentile.value\n",
    "                config['roi_processing']['background']['median_filter_size'] = median_filter_size.value\n",
    "                config['roi_processing']['background']['dilation_size'] = dilation_size.value\n",
    "            elif method.value == 'global_background':\n",
    "                config['roi_processing']['background']['min_background_area'] = min_background_area.value\n",
    "                config['roi_processing']['background']['background_dilation'] = background_dilation.value\n",
    "            elif method.value == 'lowpass_filter':\n",
    "                config['roi_processing']['background']['cutoff_freq'] = cutoff_freq.value\n",
    "                config['roi_processing']['background']['filter_order'] = filter_order.value\n",
    "            \n",
    "            try:\n",
    "                # Apply background subtraction first\n",
    "                global bg_corrected_data\n",
    "                \n",
    "                # Set save_intermediate_traces to true temporarily\n",
    "                original_save_setting = config['roi_processing'].get('save_intermediate_traces', False)\n",
    "                config['roi_processing']['save_intermediate_traces'] = True\n",
    "                \n",
    "                if method.value == 'global_background':\n",
    "                    bg_subtracted_data = subtract_global_background(\n",
    "                        corrected_data,\n",
    "                        roi_data,\n",
    "                        roi_masks,\n",
    "                        config['roi_processing']['background'],\n",
    "                        logger,\n",
    "                        output_dir=temp_output_dir\n",
    "                    )\n",
    "                else:\n",
    "                    bg_subtracted_data = subtract_background(\n",
    "                        corrected_data,\n",
    "                        roi_data,\n",
    "                        roi_masks,\n",
    "                        config['roi_processing']['background'],\n",
    "                        logger,\n",
    "                        output_dir=temp_output_dir\n",
    "                    )\n",
    "                \n",
    "                # Store a copy of the background-subtracted data before slope correction\n",
    "                bg_subtracted_only = bg_subtracted_data.copy()\n",
    "                \n",
    "                # Apply slope correction if enabled\n",
    "                if apply_slope_correction.value:\n",
    "                    print(\"\\nApplying slope correction to background-subtracted traces...\")\n",
    "                    \n",
    "                    # Import necessary functions\n",
    "                    import numpy as np\n",
    "                    from scipy.signal import find_peaks\n",
    "                    \n",
    "                    # Get the condition from metadata if available\n",
    "                    condition = metadata.get(\"condition\", \"unknown\") if 'metadata' in globals() else \"unknown\"\n",
    "                    print(f\"Using condition: {condition}\")\n",
    "                    \n",
    "                    # Get photobleaching correction settings from config\n",
    "                    pb_settings = config.get(\"analysis\", {}).get(\"photobleaching_correction\", {})\n",
    "                    \n",
    "                    # Default extended frames\n",
    "                    default_extended = pb_settings.get(\"default_extended_frames\", [0, 200])\n",
    "                    extended_frames = default_extended.copy()\n",
    "                    \n",
    "                    # Default prominence\n",
    "                    prominence = pb_settings.get(\"prominence\", 0.05)\n",
    "                    \n",
    "                    # Apply condition-specific settings if available\n",
    "                    if condition and \"condition_specific\" in pb_settings and condition in pb_settings[\"condition_specific\"]:\n",
    "                        condition_config = pb_settings[\"condition_specific\"][condition]\n",
    "                        \n",
    "                        if \"extended_frames\" in condition_config:\n",
    "                            extended_frames = condition_config[\"extended_frames\"]\n",
    "                            print(f\"Using condition-specific range {extended_frames} for {condition} photobleaching correction\")\n",
    "                        \n",
    "                        if \"prominence\" in condition_config:\n",
    "                            prominence = condition_config[\"prominence\"]\n",
    "                            print(f\"Using condition-specific prominence {prominence} for {condition} peak detection\")\n",
    "                    \n",
    "                    # Initialize array for slope-corrected data\n",
    "                    bg_corrected_data = np.zeros_like(bg_subtracted_data)\n",
    "                    \n",
    "                    # Process each ROI\n",
    "                    for i in range(len(bg_subtracted_data)):\n",
    "                        trace = bg_subtracted_data[i]\n",
    "                        \n",
    "                        # Extend baseline window to specified frames or use all available frames if less\n",
    "                        ex_frames = [extended_frames[0], min(extended_frames[1], len(trace)-1)]\n",
    "                        baseline_window = trace[ex_frames[0]:ex_frames[1]+1]\n",
    "                        baseline_x = np.arange(len(baseline_window))\n",
    "                        \n",
    "                        # Find peaks in the baseline window to exclude them\n",
    "                        peaks, _ = find_peaks(baseline_window, prominence=prominence)\n",
    "                        \n",
    "                        # Create mask to exclude peaks and their surrounding frames (±2 frames)\n",
    "                        mask = np.ones(len(baseline_window), dtype=bool)\n",
    "                        for peak in peaks:\n",
    "                            start = max(0, peak - 2)\n",
    "                            end = min(len(baseline_window), peak + 3)  # +3 because slicing is exclusive of end\n",
    "                            mask[start:end] = False\n",
    "                        \n",
    "                        # If all frames would be excluded, keep at least half of them\n",
    "                        if not np.any(mask) and len(baseline_window) > 0:\n",
    "                            print(f\"ROI {i+1}: All baseline frames would be excluded. Keeping 50% of frames.\")\n",
    "                            mask = np.ones(len(baseline_window), dtype=bool)\n",
    "                            for peak in peaks:\n",
    "                                mask[peak] = False  # Just exclude the exact peak\n",
    "                        \n",
    "                        # Fit a line to the non-peak frames to estimate photobleaching slope\n",
    "                        if np.sum(mask) > 1:  # Need at least 2 points for linear regression\n",
    "                            x_fit = baseline_x[mask]\n",
    "                            y_fit = baseline_window[mask]\n",
    "                            \n",
    "                            # Use polyfit for linear regression: y = mx + b\n",
    "                            m, b = np.polyfit(x_fit, y_fit, 1)\n",
    "                            \n",
    "                            # If slope is essentially flat, don't correct\n",
    "                            if abs(m) < 1e-5:\n",
    "                                print(f\"ROI {i+1}: No significant trend detected. Slope is nearly flat.\")\n",
    "                                bg_corrected_data[i] = trace.copy()\n",
    "                            else:\n",
    "                                # Calculate the trend using the estimated slope and intercept\n",
    "                                x_all = np.arange(len(trace))\n",
    "                                trend = m * x_all + b\n",
    "                                \n",
    "                                # Calculate the mean of the baseline points used for fitting\n",
    "                                baseline_mean = np.mean(baseline_window[mask])\n",
    "                                \n",
    "                                # Create a flat baseline at the mean level\n",
    "                                flat_baseline = np.ones(len(trace)) * baseline_mean\n",
    "                                \n",
    "                                # Replace the trended baseline with a flat baseline\n",
    "                                # Preserve the fluctuations around the trend line\n",
    "                                corrected_trace = trace - trend + flat_baseline\n",
    "                                \n",
    "                                if m < 0:\n",
    "                                    print(f\"ROI {i+1}: Negative slope detected ({m:.6f}). Applied correction to flatten baseline.\")\n",
    "                                else:\n",
    "                                    print(f\"ROI {i+1}: Positive slope detected ({m:.6f}). Applied correction to flatten baseline.\")\n",
    "                                    \n",
    "                                bg_corrected_data[i] = corrected_trace\n",
    "                        else:\n",
    "                            print(f\"ROI {i+1}: Not enough non-peak points to estimate trend. Using background-subtracted trace without slope correction.\")\n",
    "                            bg_corrected_data[i] = trace.copy()\n",
    "                    \n",
    "                    print(\"\\nBackground subtraction and slope correction completed successfully.\")\n",
    "                else:\n",
    "                    # If slope correction is disabled, use the background-subtracted data directly\n",
    "                    bg_corrected_data = bg_subtracted_data\n",
    "                    print(\"\\nBackground subtraction completed successfully (slope correction skipped).\")\n",
    "                \n",
    "                # Restore original setting\n",
    "                config['roi_processing']['save_intermediate_traces'] = original_save_setting\n",
    "                \n",
    "                # Plot comparison of traces with separate y-axes\n",
    "                plt.figure(figsize=(12, 10))\n",
    "                \n",
    "                # Choose a few ROIs to plot\n",
    "                sample_rois = min(5, len(roi_data))\n",
    "                for i in range(sample_rois):\n",
    "                    # Create a subplot with two y-axes\n",
    "                    fig, ax1 = plt.subplots(figsize=(10, 3))\n",
    "                    ax2 = ax1.twinx()\n",
    "                    \n",
    "                    # Plot before and after on different y-axes\n",
    "                    line1 = ax1.plot(roi_data[i], 'r-', alpha=0.7, label='Original')\n",
    "                    line2 = ax2.plot(bg_corrected_data[i], 'g-', alpha=0.7, label='Processed')\n",
    "                    \n",
    "                    # Set labels and title\n",
    "                    ax1.set_title(f'ROI {i+1} - Before and After Processing')\n",
    "                    ax1.set_xlabel('Frame')\n",
    "                    ax1.set_ylabel('Original', color='red')\n",
    "                    ax2.set_ylabel('Processed', color='green')\n",
    "                    \n",
    "                    # Color the y-axis tick labels\n",
    "                    ax1.tick_params(axis='y', labelcolor='red')\n",
    "                    ax2.tick_params(axis='y', labelcolor='green')\n",
    "                    \n",
    "                    # Add legend\n",
    "                    lines = line1 + line2\n",
    "                    labels = ['Original', 'Processed']\n",
    "                    plt.legend(lines, labels, loc='best')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                \n",
    "                # If slope correction was applied, show before and after slope correction\n",
    "                if apply_slope_correction.value:\n",
    "                    for i in range(sample_rois):\n",
    "                        fig, ax = plt\n",
    "                # If slope correction was applied, show before and after slope correction\n",
    "                if apply_slope_correction.value:\n",
    "                    for i in range(sample_rois):\n",
    "                        fig, ax = plt.subplots(figsize=(10, 3))\n",
    "                        \n",
    "                        # Plot background-subtracted before and after slope correction\n",
    "                        ax.plot(bg_subtracted_only[i], 'b-', alpha=0.7, label='After BG Subtraction')\n",
    "                        ax.plot(bg_corrected_data[i], 'g-', alpha=0.7, label='After Slope Correction')\n",
    "                        \n",
    "                        # Set labels and title\n",
    "                        ax.set_title(f'ROI {i+1} - Effect of Slope Correction')\n",
    "                        ax.set_xlabel('Frame')\n",
    "                        ax.set_ylabel('Fluorescence')\n",
    "                        ax.legend(loc='best')\n",
    "                        \n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "\n",
    "                # Create a side-by-side comparison of all traces\n",
    "                plt.figure(figsize=(16, 8))\n",
    "                \n",
    "                # Before\n",
    "                plt.subplot(1, 2, 1)\n",
    "                for i in range(min(10, len(roi_data))):\n",
    "                    plt.plot(roi_data[i], alpha=0.7)\n",
    "                plt.title('Original Traces')\n",
    "                plt.xlabel('Frame')\n",
    "                plt.ylabel('Fluorescence')\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                \n",
    "                # After\n",
    "                plt.subplot(1, 2, 2)\n",
    "                for i in range(min(10, len(bg_corrected_data))):\n",
    "                    plt.plot(bg_corrected_data[i], alpha=0.7)\n",
    "                plt.title('Processed Traces')\n",
    "                plt.xlabel('Frame')\n",
    "                plt.ylabel('Fluorescence')\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                print(\"Processing complete! The corrected traces are now available for further analysis.\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error during processing: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "    \n",
    "    run_button.on_click(on_run_click)\n",
    "    \n",
    "    # Create description of background subtraction methods\n",
    "    bg_info = widgets.HTML(\n",
    "        \"\"\"\n",
    "        <h3>Background Subtraction Methods:</h3>\n",
    "        <ul>\n",
    "            <li><strong>ROI Periphery</strong>: Uses the area surrounding each ROI as local background.</li>\n",
    "            <li><strong>Darkest Pixels</strong>: Uses the darkest pixels in the image as global background.</li>\n",
    "            <li><strong>Global Background</strong>: Identifies a region in the image with low intensity as background.</li>\n",
    "            <li><strong>Lowpass Filter</strong>: Uses a low-pass filter to separate fast signals from slow background changes.</li>\n",
    "        </ul>\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Display widgets\n",
    "    display(bg_info)\n",
    "    display(widgets.VBox([\n",
    "        method,\n",
    "        params_container,\n",
    "        apply_slope_correction,\n",
    "        run_button,\n",
    "        info_output\n",
    "    ]))\n",
    "\n",
    "# Initialize the background-corrected data variable\n",
    "bg_corrected_data = None\n",
    "\n",
    "# Run the function\n",
    "run_background_subtraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a81e33-ebde-4b5a-868e-36b16aa1a62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Background Subtraction {display-mode: \"form\"}\n",
    "def run_background_subtraction():\n",
    "    \"\"\"Interactive background subtraction for ROI traces\"\"\"\n",
    "    global corrected_data, roi_masks, roi_data, config\n",
    "    \n",
    "    if 'corrected_data' not in globals() or corrected_data is None:\n",
    "        print(\"Please run photobleaching correction first\")\n",
    "        return\n",
    "    \n",
    "    if 'roi_masks' not in globals() or roi_masks is None or 'roi_data' not in globals() or roi_data is None:\n",
    "        print(\"Please extract ROIs first\")\n",
    "        return\n",
    "    \n",
    "    if 'config' not in globals() or config is None:\n",
    "        print(\"Please load configuration first\")\n",
    "        return\n",
    "    \n",
    "    # Get background subtraction parameters\n",
    "    method = widgets.Dropdown(\n",
    "        options=[\n",
    "            ('ROI Periphery', 'roi_periphery'),\n",
    "            ('Darkest Pixels', 'darkest_pixels'),\n",
    "            ('Global Background', 'global_background'),\n",
    "            ('Lowpass Filter', 'lowpass_filter')\n",
    "        ],\n",
    "        value=config['roi_processing'].get('background', {}).get('method', 'roi_periphery'),\n",
    "        description='Method:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Parameters for ROI periphery\n",
    "    periphery_size = widgets.IntSlider(\n",
    "        value=config['roi_processing'].get('background', {}).get('periphery_size', 2),\n",
    "        min=1,\n",
    "        max=10,\n",
    "        step=1,\n",
    "        description='Periphery Size:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Parameters for darkest pixels\n",
    "    percentile = widgets.FloatSlider(\n",
    "        value=config['roi_processing'].get('background', {}).get('percentile', 0.1),\n",
    "        min=0.01,\n",
    "        max=5.0,\n",
    "        step=0.01,\n",
    "        description='Percentile:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    median_filter_size = widgets.IntSlider(\n",
    "        value=config['roi_processing'].get('background', {}).get('median_filter_size', 3),\n",
    "        min=1,\n",
    "        max=19,\n",
    "        step=2,\n",
    "        description='Median Filter:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    dilation_size = widgets.IntSlider(\n",
    "        value=config['roi_processing'].get('background', {}).get('dilation_size', 2),\n",
    "        min=0,\n",
    "        max=10,\n",
    "        step=1,\n",
    "        description='Dilation Size:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Parameters for global background\n",
    "    min_background_area = widgets.IntSlider(\n",
    "        value=config['roi_processing'].get('background', {}).get('min_background_area', 200),\n",
    "        min=50,\n",
    "        max=1000,\n",
    "        step=50,\n",
    "        description='Min Area:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    background_dilation = widgets.IntSlider(\n",
    "        value=config['roi_processing'].get('background', {}).get('background_dilation', 2),\n",
    "        min=0,\n",
    "        max=10,\n",
    "        step=1,\n",
    "        description='BG Dilation:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Parameters for lowpass filter\n",
    "    cutoff_freq = widgets.FloatSlider(\n",
    "        value=config['roi_processing'].get('background', {}).get('cutoff_freq', 0.001),\n",
    "        min=0.0001,\n",
    "        max=0.01,\n",
    "        step=0.0001,\n",
    "        description='Cutoff Freq:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    filter_order = widgets.IntSlider(\n",
    "        value=config['roi_processing'].get('background', {}).get('filter_order', 2),\n",
    "        min=1,\n",
    "        max=6,\n",
    "        step=1,\n",
    "        description='Filter Order:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Create parameter containers for each method\n",
    "    roi_periphery_params = widgets.VBox([periphery_size])\n",
    "    darkest_pixels_params = widgets.VBox([percentile, median_filter_size, dilation_size])\n",
    "    global_background_params = widgets.VBox([min_background_area, background_dilation])\n",
    "    lowpass_filter_params = widgets.VBox([cutoff_freq, filter_order])\n",
    "    \n",
    "    # Container for method-specific parameters\n",
    "    params_container = widgets.Output()\n",
    "    \n",
    "    # Show parameters based on selected method\n",
    "    def update_params(change):\n",
    "        with params_container:\n",
    "            clear_output()\n",
    "            if change.new == 'roi_periphery':\n",
    "                display(roi_periphery_params)\n",
    "            elif change.new == 'darkest_pixels':\n",
    "                display(darkest_pixels_params)\n",
    "            elif change.new == 'global_background':\n",
    "                display(global_background_params)\n",
    "            elif change.new == 'lowpass_filter':\n",
    "                display(lowpass_filter_params)\n",
    "    \n",
    "    method.observe(update_params, names='value')\n",
    "    \n",
    "    # Display initial parameters\n",
    "    with params_container:\n",
    "        if method.value == 'roi_periphery':\n",
    "            display(roi_periphery_params)\n",
    "        elif method.value == 'darkest_pixels':\n",
    "            display(darkest_pixels_params)\n",
    "        elif method.value == 'global_background':\n",
    "            display(global_background_params)\n",
    "        elif method.value == 'lowpass_filter':\n",
    "            display(lowpass_filter_params)\n",
    "    \n",
    "    # Create a temporary output directory for intermediate results\n",
    "    temp_output_dir = os.path.join(args.output_dir, 'temp_bg_subtraction')\n",
    "    os.makedirs(temp_output_dir, exist_ok=True)\n",
    "    \n",
    "    run_button = widgets.Button(\n",
    "        description='Run Background Subtraction',\n",
    "        button_style='success',\n",
    "        tooltip='Apply background subtraction to ROI traces'\n",
    "    )\n",
    "    \n",
    "    info_output = widgets.Output()\n",
    "    \n",
    "    def on_run_click(b):\n",
    "        with info_output:\n",
    "            clear_output()\n",
    "            print(f\"Running background subtraction with method: {method.value}\")\n",
    "            \n",
    "            # Update config with current values\n",
    "            if 'background' not in config['roi_processing']:\n",
    "                config['roi_processing']['background'] = {}\n",
    "            \n",
    "            config['roi_processing']['background']['method'] = method.value\n",
    "            \n",
    "            if method.value == 'roi_periphery':\n",
    "                config['roi_processing']['background']['periphery_size'] = periphery_size.value\n",
    "            elif method.value == 'darkest_pixels':\n",
    "                config['roi_processing']['background']['percentile'] = percentile.value\n",
    "                config['roi_processing']['background']['median_filter_size'] = median_filter_size.value\n",
    "                config['roi_processing']['background']['dilation_size'] = dilation_size.value\n",
    "            elif method.value == 'global_background':\n",
    "                config['roi_processing']['background']['min_background_area'] = min_background_area.value\n",
    "                config['roi_processing']['background']['background_dilation'] = background_dilation.value\n",
    "            elif method.value == 'lowpass_filter':\n",
    "                config['roi_processing']['background']['cutoff_freq'] = cutoff_freq.value\n",
    "                config['roi_processing']['background']['filter_order'] = filter_order.value\n",
    "            \n",
    "            try:\n",
    "                # Apply background subtraction\n",
    "                global bg_corrected_data\n",
    "                \n",
    "                # Set save_intermediate_traces to true temporarily\n",
    "                original_save_setting = config['roi_processing'].get('save_intermediate_traces', False)\n",
    "                config['roi_processing']['save_intermediate_traces'] = True\n",
    "                \n",
    "                if method.value == 'global_background':\n",
    "                    bg_corrected_data = subtract_global_background(\n",
    "                        corrected_data,\n",
    "                        roi_data,\n",
    "                        roi_masks,\n",
    "                        config['roi_processing']['background'],\n",
    "                        logger,\n",
    "                        output_dir=temp_output_dir\n",
    "                    )\n",
    "                else:\n",
    "                    bg_corrected_data = subtract_background(\n",
    "                        corrected_data,\n",
    "                        roi_data,\n",
    "                        roi_masks,\n",
    "                        config['roi_processing']['background'],\n",
    "                        logger,\n",
    "                        output_dir=temp_output_dir\n",
    "                    )\n",
    "                \n",
    "                # Restore original setting\n",
    "                config['roi_processing']['save_intermediate_traces'] = original_save_setting\n",
    "                \n",
    "                print(\"Background subtraction completed successfully.\")\n",
    "                \n",
    "                # Plot comparison of traces before and after background subtraction with separate y-axes\n",
    "                plt.figure(figsize=(12, 10))\n",
    "                \n",
    "                # Choose a few ROIs to plot\n",
    "                sample_rois = min(5, len(roi_data))\n",
    "                for i in range(sample_rois):\n",
    "                    # Create a subplot with two y-axes\n",
    "                    fig, ax1 = plt.subplots(figsize=(10, 3))\n",
    "                    ax2 = ax1.twinx()\n",
    "                    \n",
    "                    # Plot before and after on different y-axes\n",
    "                    line1 = ax1.plot(roi_data[i], 'r-', alpha=0.7, label='Before')\n",
    "                    line2 = ax2.plot(bg_corrected_data[i], 'g-', alpha=0.7, label='After')\n",
    "                    \n",
    "                    # Set labels and title\n",
    "                    ax1.set_title(f'ROI {i+1} - Before and After Background Subtraction')\n",
    "                    ax1.set_xlabel('Frame')\n",
    "                    ax1.set_ylabel('Before Correction', color='red')\n",
    "                    ax2.set_ylabel('After Correction', color='green')\n",
    "                    \n",
    "                    # Color the y-axis tick labels\n",
    "                    ax1.tick_params(axis='y', labelcolor='red')\n",
    "                    ax2.tick_params(axis='y', labelcolor='green')\n",
    "                    \n",
    "                    # Add legend\n",
    "                    lines = line1 + line2\n",
    "                    labels = ['Before', 'After']\n",
    "                    plt.legend(lines, labels, loc='best')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "\n",
    "                # Create a side-by-side comparison of all traces\n",
    "                plt.figure(figsize=(16, 8))\n",
    "                \n",
    "                # Before\n",
    "                plt.subplot(1, 2, 1)\n",
    "                for i in range(min(10, len(roi_data))):\n",
    "                    plt.plot(roi_data[i], alpha=0.7)\n",
    "                plt.title('Traces Before Background Subtraction')\n",
    "                plt.xlabel('Frame')\n",
    "                plt.ylabel('Fluorescence')\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                \n",
    "                # After\n",
    "                plt.subplot(1, 2, 2)\n",
    "                for i in range(min(10, len(bg_corrected_data))):\n",
    "                    plt.plot(bg_corrected_data[i], alpha=0.7)\n",
    "                plt.title('Traces After Background Subtraction')\n",
    "                plt.xlabel('Frame')\n",
    "                plt.ylabel('Fluorescence')\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                print(\"Background subtraction complete! The corrected traces are now available for further analysis.\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error during background subtraction: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "    \n",
    "    run_button.on_click(on_run_click)\n",
    "    \n",
    "    # Create description of background subtraction methods\n",
    "    bg_info = widgets.HTML(\n",
    "        \"\"\"\n",
    "        <h3>Background Subtraction Methods:</h3>\n",
    "        <ul>\n",
    "            <li><strong>ROI Periphery</strong>: Uses the area surrounding each ROI as local background.</li>\n",
    "            <li><strong>Darkest Pixels</strong>: Uses the darkest pixels in the image as global background.</li>\n",
    "            <li><strong>Global Background</strong>: Identifies a region in the image with low intensity as background.</li>\n",
    "            <li><strong>Lowpass Filter</strong>: Uses a low-pass filter to separate fast signals from slow background changes.</li>\n",
    "        </ul>\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Display widgets\n",
    "    display(bg_info)\n",
    "    display(widgets.VBox([\n",
    "        method,\n",
    "        params_container,\n",
    "        run_button,\n",
    "        info_output\n",
    "    ]))\n",
    "\n",
    "# Initialize the background-corrected data variable\n",
    "bg_corrected_data = None\n",
    "\n",
    "# Run the function\n",
    "run_background_subtraction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d2cd4f-623d-406a-9618-bf30b4353be1",
   "metadata": {},
   "source": [
    "## ROI Processing with PNR Refinement\n",
    "\n",
    "Peak-to-Noise Ratio (PNR) refinement helps identify and select ROIs with strong neuronal signals while filtering out ROIs with poor signal quality. This is essential for accurate calcium imaging analysis.\n",
    "\n",
    "### How PNR Refinement Works\n",
    "1. **Frequency Separation**: The fluorescence trace is split into signal (low-frequency) and noise (high-frequency) components\n",
    "2. **Signal Smoothing**: Optional smoothing can be applied to the signal component to reduce fluctuations\n",
    "3. **PNR Calculation**: The ratio between peak signal value and noise standard deviation is calculated\n",
    "4. **Thresholding**: ROIs with PNR values below the threshold are excluded from analysis\n",
    "\n",
    "### Key Parameters\n",
    "- **Noise Frequency Cutoff**: Determines the boundary between signal and noise components (0.01-0.2 Hz)\n",
    "- **Percentile Threshold**: Percentile used to determine peak signal value (90-99.9%)\n",
    "- **Trace Smoothing**: Window size for signal smoothing (0 = no smoothing)\n",
    "- **Min PNR**: Minimum PNR threshold for accepting an ROI (typically 5-10)\n",
    "\n",
    "### Finding Optimal Values\n",
    "- Higher PNR thresholds produce more reliable results but may exclude valid ROIs\n",
    "- The ideal noise frequency cutoff depends on the temporal characteristics of your signal\n",
    "- Smoothing can help stabilize PNR values but may mask transient events\n",
    "\n",
    "The tool below allows you to visualize and adjust these parameters to optimize ROI selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac008b2f-d5aa-4542-83e2-973d56bf1985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title PNR-Based ROI Refinement {display-mode: \"form\"}\n",
    "import random\n",
    "\n",
    "def run_pnr_refinement():\n",
    "    \"\"\"Interactive PNR-based refinement of ROIs\"\"\"\n",
    "    global roi_data, roi_masks, bg_corrected_data, config\n",
    "    \n",
    "    # Use background-corrected data if available, otherwise use original ROI data\n",
    "    data_to_use = bg_corrected_data if 'bg_corrected_data' in globals() and bg_corrected_data is not None else roi_data\n",
    "    \n",
    "    if 'roi_masks' not in globals() or roi_masks is None or data_to_use is None:\n",
    "        print(\"Please extract ROIs and perform background subtraction first\")\n",
    "        return\n",
    "    \n",
    "    if 'config' not in globals() or config is None:\n",
    "        print(\"Please load configuration first\")\n",
    "        return\n",
    "    \n",
    "    # Get PNR refinement parameters\n",
    "    noise_freq_cutoff = widgets.FloatSlider(\n",
    "        value=config['roi_processing'].get('pnr_refinement', {}).get('noise_freq_cutoff', 0.03),\n",
    "        min=0.01,\n",
    "        max=0.5,\n",
    "        step=0.01,\n",
    "        description='Noise Cutoff:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    min_pnr = widgets.FloatSlider(\n",
    "        value=config['roi_processing'].get('pnr_refinement', {}).get('min_pnr', 10),\n",
    "        min=1.0,\n",
    "        max=20.0,\n",
    "        step=0.5,\n",
    "        description='Min PNR:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    percentile_threshold = widgets.FloatSlider(\n",
    "        value=config['roi_processing'].get('pnr_refinement', {}).get('percentile_threshold', 99),\n",
    "        min=90.0,\n",
    "        max=99.9,\n",
    "        step=0.1,\n",
    "        description='Percentile:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    trace_smoothing = widgets.IntSlider(\n",
    "        value=config['roi_processing'].get('pnr_refinement', {}).get('trace_smoothing', 3),\n",
    "        min=0,\n",
    "        max=9,\n",
    "        step=1,\n",
    "        description='Smoothing:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    auto_determine = widgets.Checkbox(\n",
    "        value=config['roi_processing'].get('pnr_refinement', {}).get('auto_determine', False),\n",
    "        description='Auto-Determine Cutoff',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    run_button = widgets.Button(\n",
    "        description='Run PNR Refinement',\n",
    "        button_style='success',\n",
    "        tooltip='Apply PNR-based refinement to ROIs'\n",
    "    )\n",
    "    \n",
    "    info_output = widgets.Output()\n",
    "    \n",
    "    def on_run_click(b):\n",
    "        with info_output:\n",
    "            clear_output()\n",
    "            print(\"Running PNR-based ROI refinement...\")\n",
    "            \n",
    "            # Update config with current values\n",
    "            if 'pnr_refinement' not in config['roi_processing']:\n",
    "                config['roi_processing']['pnr_refinement'] = {}\n",
    "            \n",
    "            config['roi_processing']['pnr_refinement']['noise_freq_cutoff'] = noise_freq_cutoff.value\n",
    "            config['roi_processing']['pnr_refinement']['min_pnr'] = min_pnr.value\n",
    "            config['roi_processing']['pnr_refinement']['percentile_threshold'] = percentile_threshold.value\n",
    "            config['roi_processing']['pnr_refinement']['trace_smoothing'] = trace_smoothing.value\n",
    "            config['roi_processing']['pnr_refinement']['auto_determine'] = auto_determine.value\n",
    "            \n",
    "            try:\n",
    "                # Apply PNR refinement\n",
    "                global refined_masks, refined_traces, pnr_values, diagnostic_info\n",
    "                \n",
    "                refined_masks, refined_traces, pnr_values, diagnostic_info = refine_rois_with_pnr(\n",
    "                    data_to_use,\n",
    "                    roi_masks,\n",
    "                    config['roi_processing'],\n",
    "                    logger\n",
    "                )\n",
    "                \n",
    "                print(f\"PNR refinement complete! Kept {len(refined_masks)}/{len(roi_masks)} ROIs.\")\n",
    "                \n",
    "                # Create visualization\n",
    "                # Split signal and noise components\n",
    "                signal_traces, noise_traces = split_signal_noise(data_to_use, noise_freq_cutoff.value, logger)\n",
    "                \n",
    "                # Get some representative ROIs to visualize\n",
    "                n_vis = min(5, len(roi_masks))\n",
    "                vis_indices = []\n",
    "                \n",
    "                # Try to include both kept and discarded ROIs\n",
    "                kept_indices = diagnostic_info['kept_indices']\n",
    "                all_indices = list(range(len(roi_masks)))\n",
    "                discarded_indices = [i for i in all_indices if i not in kept_indices]\n",
    "                \n",
    "                # Add some kept ROIs if available\n",
    "                n_kept_vis = min(3, len(kept_indices))\n",
    "                if n_kept_vis > 0:\n",
    "                    vis_indices.extend(kept_indices[:n_kept_vis])\n",
    "                \n",
    "                # Add some discarded ROIs if available\n",
    "                n_discarded_vis = min(2, len(discarded_indices))\n",
    "                if n_discarded_vis > 0:\n",
    "                    vis_indices.extend(discarded_indices[:n_discarded_vis])\n",
    "                \n",
    "                # If we still need more, add random ones\n",
    "                if len(vis_indices) < n_vis:\n",
    "                    remaining = n_vis - len(vis_indices)\n",
    "                    remaining_indices = [i for i in all_indices if i not in vis_indices]\n",
    "                    if remaining_indices:\n",
    "                        vis_indices.extend(random.sample(remaining_indices, min(remaining, len(remaining_indices))))\n",
    "                \n",
    "                # Plot signal-noise decomposition for selected ROIs\n",
    "                plt.figure(figsize=(12, 3 * len(vis_indices)))\n",
    "                \n",
    "                for i, idx in enumerate(vis_indices):\n",
    "                    # Create original trace plot\n",
    "                    plt.subplot(len(vis_indices), 3, i*3 + 1)\n",
    "                    plt.plot(data_to_use[idx], 'k-', label=f'Original (ROI {idx+1})')\n",
    "                    plt.title(f'ROI {idx+1} - Original')\n",
    "                    plt.ylabel('Fluorescence')\n",
    "                    plt.grid(True, alpha=0.3)\n",
    "                    \n",
    "                    # Create signal plot\n",
    "                    plt.subplot(len(vis_indices), 3, i*3 + 2)\n",
    "                    plt.plot(signal_traces[idx], 'g-', label='Signal')\n",
    "                    is_kept = idx in kept_indices\n",
    "                    pnr_val = pnr_values[idx] if idx < len(pnr_values) else 0\n",
    "                    status = \"Kept\" if is_kept else \"Discarded\"\n",
    "                    plt.title(f'Signal Component (PNR: {pnr_val:.2f}) - {status}')\n",
    "                    plt.grid(True, alpha=0.3)\n",
    "                    \n",
    "                    # Create noise plot\n",
    "                    plt.subplot(len(vis_indices), 3, i*3 + 3)\n",
    "                    plt.plot(noise_traces[idx], 'r-', label='Noise')\n",
    "                    plt.title('Noise Component')\n",
    "                    plt.grid(True, alpha=0.3)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                # Generate a histogram of PNR values\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                \n",
    "                # Create bins for PNR values\n",
    "                bins = np.linspace(0, max(pnr_values) * 1.1, 30)\n",
    "                \n",
    "                # Plot histogram\n",
    "                n, bins, patches = plt.hist(pnr_values, bins=bins, alpha=0.7)\n",
    "                \n",
    "                # Add a vertical line at the threshold\n",
    "                plt.axvline(x=min_pnr.value, color='r', linestyle='--', \n",
    "                           label=f'Threshold: {min_pnr.value}')\n",
    "                \n",
    "                plt.title('Distribution of Peak-to-Noise Ratio (PNR) Values')\n",
    "                plt.xlabel('PNR')\n",
    "                plt.ylabel('Count')\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                plt.legend()\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                # Plot showing before/after refinement\n",
    "                if len(refined_masks) > 0:\n",
    "                    # Sample frame to display ROIs\n",
    "                    sample_frame = min(10, corrected_data.shape[0]-1)\n",
    "                    \n",
    "                    plt.figure(figsize=(12, 8))\n",
    "                    \n",
    "                    # Before refinement\n",
    "                    plt.subplot(1, 2, 1)\n",
    "                    plt.imshow(corrected_data[sample_frame], cmap='gray')\n",
    "                    plt.title(f\"All ROIs (Before Refinement: {len(roi_masks)})\")\n",
    "                    \n",
    "                    # Draw all ROI outlines\n",
    "                    for i, mask in enumerate(roi_masks):\n",
    "                        # Find contours\n",
    "                        contours = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "                        for contour in contours:\n",
    "                            contour = np.squeeze(contour)\n",
    "                            if len(contour.shape) == 1:\n",
    "                                # Single point contour\n",
    "                                continue\n",
    "                                \n",
    "                            # Create color based on whether it was kept\n",
    "                            color = 'g' if i in kept_indices else 'r'\n",
    "                            \n",
    "                            # Use fill method to draw closed polygons instead of plot\n",
    "                            polygon = plt.Polygon(contour, fill=False, edgecolor=color, linewidth=1.5, closed=True)\n",
    "                            plt.gca().add_patch(polygon)\n",
    "                    \n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    # After refinement\n",
    "                    plt.subplot(1, 2, 2)\n",
    "                    plt.imshow(corrected_data[sample_frame], cmap='gray')\n",
    "                    plt.title(f\"Kept ROIs (After Refinement: {len(refined_masks)})\")\n",
    "                    \n",
    "                    # Draw only kept ROI outlines\n",
    "                    for i, mask in enumerate(refined_masks):\n",
    "                        # Find contours\n",
    "                        contours = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "                        for contour in contours:\n",
    "                            contour = np.squeeze(contour)\n",
    "                            if len(contour.shape) == 1:\n",
    "                                # Single point contour\n",
    "                                continue\n",
    "                                \n",
    "                            # Use fill method to draw closed polygons\n",
    "                            polygon = plt.Polygon(contour, fill=False, edgecolor='g', linewidth=1.5, closed=True)\n",
    "                            plt.gca().add_patch(polygon)\n",
    "                        \n",
    "                        # Add ROI number\n",
    "                        y_indices, x_indices = np.where(mask)\n",
    "                        if len(y_indices) > 0 and len(x_indices) > 0:\n",
    "                            # Calculate centroid\n",
    "                            center_y = int(np.mean(y_indices))\n",
    "                            center_x = int(np.mean(x_indices))\n",
    "                            plt.text(center_x, center_y, str(i+1), color='white', \n",
    "                                    fontsize=8, ha='center', va='center',\n",
    "                                    bbox=dict(boxstyle=\"circle\", fc=\"black\", alpha=0.7))\n",
    "                    \n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                    \n",
    "                    # Add button to use refined ROIs\n",
    "                    use_refined_button = widgets.Button(\n",
    "                        description='Use Refined ROIs',\n",
    "                        button_style='success',\n",
    "                        tooltip='Replace original ROIs with refined ROIs'\n",
    "                    )\n",
    "                    \n",
    "                    def on_use_refined_click(b):\n",
    "                        global roi_masks, roi_data\n",
    "                        # Update global variables with refined data\n",
    "                        roi_masks = refined_masks\n",
    "                        roi_data = refined_traces\n",
    "                        print(f\"Updated to use {len(refined_masks)} refined ROIs for further analysis\")\n",
    "                    \n",
    "                    use_refined_button.on_click(on_use_refined_click)\n",
    "                    display(use_refined_button)\n",
    "                \n",
    "                print(\"\\nPNR refinement complete. Review the results above to decide if you want to use the refined ROIs.\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error during PNR refinement: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "    \n",
    "    run_button.on_click(on_run_click)\n",
    "    \n",
    "    # Create description of PNR refinement parameters\n",
    "    pnr_info = widgets.HTML(\n",
    "        \"\"\"\n",
    "        <h3>PNR-Based ROI Refinement:</h3>\n",
    "        <p>This method refines ROIs based on their peak-to-noise ratio (PNR). ROIs with PNR above the threshold are kept, others are discarded.</p>\n",
    "        <ul>\n",
    "            <li><strong>Noise Cutoff</strong>: Frequency cutoff for signal/noise separation. Higher values include more high-frequency components in the noise.</li>\n",
    "            <li><strong>Min PNR</strong>: Minimum peak-to-noise ratio required to keep an ROI.</li>\n",
    "            <li><strong>Percentile</strong>: Percentile of signal to use as peak value.</li>\n",
    "            <li><strong>Smoothing</strong>: Window size for smoothing signal traces (0 to disable).</li>\n",
    "            <li><strong>Auto-Determine</strong>: Automatically determine optimal frequency cutoff (overrides Noise Cutoff).</li>\n",
    "        </ul>\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Display widgets\n",
    "    display(pnr_info)\n",
    "    display(widgets.VBox([\n",
    "        noise_freq_cutoff,\n",
    "        min_pnr,\n",
    "        percentile_threshold,\n",
    "        trace_smoothing,\n",
    "        auto_determine,\n",
    "        run_button,\n",
    "        info_output\n",
    "    ]))\n",
    "\n",
    "# Initialize variables for refined data\n",
    "refined_masks = None\n",
    "refined_traces = None\n",
    "pnr_values = None\n",
    "diagnostic_info = None\n",
    "\n",
    "# Run the function\n",
    "run_pnr_refinement()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68007efe-07ae-4ab0-9848-892aaff5a8a8",
   "metadata": {},
   "source": [
    "## Event Detection and Analysis\n",
    "\n",
    "Accurate detection of calcium events is crucial for analyzing neuronal activity. This tool allows you to adjust event detection parameters to optimize sensitivity and specificity for your data.\n",
    "\n",
    "### Event Detection Methods\n",
    "The pipeline uses the SciPy `find_peaks` function with several parameters that control sensitivity:\n",
    "\n",
    "### Key Parameters\n",
    "- **Prominence**: Minimum height difference between a peak and surrounding baseline\n",
    "- **Width**: Minimum width (in frames) of a valid peak\n",
    "- **Distance**: Minimum separation (in frames) between valid peaks\n",
    "- **Height**: Minimum absolute height above baseline for a valid peak\n",
    "- **Activity Threshold**: Threshold for declaring an ROI as 'active'\n",
    "\n",
    "### Condition-Specific Analysis\n",
    "Different experimental conditions require different analysis approaches:\n",
    "- **Spontaneous (0µm)**: Analyzes spontaneous activity throughout the recording\n",
    "- **Evoked (10µm/25µm)**: Focuses on activity following stimulus application (frame 100)\n",
    "\n",
    "### Finding Optimal Values\n",
    "- Higher prominence values detect stronger events but may miss subtle ones\n",
    "- Width requirements help distinguish true events from noise\n",
    "- The activity threshold should be set based on your experimental design and expected effect size\n",
    "\n",
    "The interactive tool below allows you to visualize how parameter adjustments affect event detection sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1f19fa-69b6-4524-bdb7-a46d788a49a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Event Detection {display-mode: \"form\"}\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_event_detection():\n",
    "    \"\"\"Interactive event detection and visualization\"\"\"\n",
    "    global roi_data, roi_masks, corrected_data, bg_corrected_data, metadata, config\n",
    "    \n",
    "    # First check if we have the necessary data\n",
    "    if not all(var in globals() for var in ['roi_masks']):\n",
    "        print(\"Please extract ROIs first\")\n",
    "        return\n",
    "    \n",
    "    if 'config' not in globals() or config is None:\n",
    "        print(\"Please load configuration first\")\n",
    "        return\n",
    "    \n",
    "    # Create a copy of traces for visualization\n",
    "    # First determine which data to use (priority: bg_corrected > roi_data > extract from corrected_data)\n",
    "    if 'bg_corrected_data' in globals() and bg_corrected_data is not None:\n",
    "        traces_for_analysis = bg_corrected_data\n",
    "        print(\"Using background-corrected data for analysis\")\n",
    "    elif 'roi_data' in globals() and roi_data is not None:\n",
    "        traces_for_analysis = roi_data\n",
    "        print(\"Using ROI data for analysis\")\n",
    "    elif 'corrected_data' in globals() and corrected_data is not None and 'roi_masks' in globals() and roi_masks:\n",
    "        # Extract traces directly from corrected_data using ROI masks\n",
    "        print(\"Extracting traces from corrected data using ROI masks\")\n",
    "        n_rois = len(roi_masks)\n",
    "        n_frames = corrected_data.shape[0]\n",
    "        traces_for_analysis = np.zeros((n_rois, n_frames), dtype=np.float32)\n",
    "        for i, mask in enumerate(roi_masks):\n",
    "            for t in range(n_frames):\n",
    "                binary_mask = mask.astype(bool)\n",
    "                traces_for_analysis[i, t] = np.mean(corrected_data[t][binary_mask])\n",
    "    else:\n",
    "        print(\"No suitable data found for event detection\")\n",
    "        return\n",
    "    \n",
    "    # Convert to dF/F using a simple baseline calculation if needed\n",
    "    # This is just for visualization - the real pipeline will use more sophisticated methods\n",
    "    df_f_traces = np.zeros_like(traces_for_analysis)\n",
    "    for i in range(len(traces_for_analysis)):\n",
    "        # Use first 100 frames or fewer for baseline calculation\n",
    "        baseline_frames = min(100, traces_for_analysis.shape[1])\n",
    "        baseline = np.percentile(traces_for_analysis[i, :baseline_frames], 8)\n",
    "        df_f_traces[i] = (traces_for_analysis[i] - baseline) / baseline if baseline > 0 else traces_for_analysis[i]\n",
    "    \n",
    "    # Create widgets for event detection parameters\n",
    "    prominence = widgets.FloatSlider(\n",
    "        value=config['analysis'].get('peak_detection', {}).get('prominence', 0.03),\n",
    "        min=0.01,\n",
    "        max=0.2,\n",
    "        step=0.01,\n",
    "        description='Prominence:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    width = widgets.IntSlider(\n",
    "        value=config['analysis'].get('peak_detection', {}).get('width', 2),\n",
    "        min=1,\n",
    "        max=10,\n",
    "        step=1,\n",
    "        description='Width:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    distance = widgets.IntSlider(\n",
    "        value=config['analysis'].get('peak_detection', {}).get('distance', 10),\n",
    "        min=5,\n",
    "        max=30,\n",
    "        step=1,\n",
    "        description='Distance:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    height = widgets.FloatSlider(\n",
    "        value=config['analysis'].get('peak_detection', {}).get('height', 0.02),\n",
    "        min=0.01,\n",
    "        max=0.2,\n",
    "        step=0.01,\n",
    "        description='Height:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Activity threshold\n",
    "    active_threshold = widgets.FloatSlider(\n",
    "        value=config['analysis'].get('active_threshold', 0.02),\n",
    "        min=0.01,\n",
    "        max=0.1,\n",
    "        step=0.01,\n",
    "        description='Activity Threshold:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Widget for condition selection\n",
    "    condition_value = 'unknown'\n",
    "    if 'metadata' in globals() and metadata and 'condition' in metadata:\n",
    "        condition_value = metadata['condition']\n",
    "    \n",
    "    condition = widgets.Dropdown(\n",
    "        options=[\n",
    "            ('Spontaneous (0µm)', '0um'),\n",
    "            ('Evoked (10µm)', '10um'),\n",
    "            ('Evoked (25µm)', '25um')\n",
    "        ],\n",
    "        value=condition_value if condition_value in ['0um', '10um', '25um'] else '0um',\n",
    "        description='Condition:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Widget to select ROIs to display\n",
    "    roi_options = [(f\"ROI {i+1}\", i) for i in range(min(10, len(df_f_traces)))]\n",
    "    roi_indices = widgets.SelectMultiple(\n",
    "        options=roi_options,\n",
    "        value=[0, 1, 2] if len(roi_options) >= 3 else [0],  # Default: first 3 ROIs\n",
    "        description='ROIs to Display:',\n",
    "        disabled=False,\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Output widget for results\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def display_event_detection(b=None):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            \n",
    "            selected_indices = list(roi_indices.value)\n",
    "            if not selected_indices:\n",
    "                print(\"Please select at least one ROI to display\")\n",
    "                return\n",
    "            \n",
    "            # Create peak detection config\n",
    "            peak_config = {\n",
    "                \"prominence\": prominence.value,\n",
    "                \"width\": width.value,\n",
    "                \"distance\": distance.value,\n",
    "                \"height\": height.value,\n",
    "                \"rel_height\": 0.5\n",
    "            }\n",
    "            \n",
    "            # Create the peak detection and display\n",
    "            n_rois = len(selected_indices)\n",
    "            fig, axes = plt.subplots(n_rois, 1, figsize=(12, 3*n_rois))\n",
    "            \n",
    "            # Handle single ROI case\n",
    "            if n_rois == 1:\n",
    "                axes = np.array([axes])\n",
    "            \n",
    "            # Set analysis frames based on condition\n",
    "            if condition.value == '0um':\n",
    "                # For spontaneous, analyze all frames\n",
    "                analysis_frames = [0, df_f_traces.shape[1]-1]\n",
    "                active_metric = \"spont_peak_frequency\"\n",
    "                title_suffix = \"Spontaneous Activity\"\n",
    "            else:\n",
    "                # For evoked, focus on frames after stimulus\n",
    "                analysis_frames = [100, df_f_traces.shape[1]-1]\n",
    "                active_metric = \"peak_amplitude\"\n",
    "                title_suffix = f\"Evoked Activity ({condition.value})\"\n",
    "            \n",
    "            # Calculate baseline frames - just use first 100 frames or fewer\n",
    "            baseline_frames = [0, min(100, df_f_traces.shape[1]-1)]\n",
    "            \n",
    "            # Process and display each selected ROI\n",
    "            active_rois = 0\n",
    "            for i, roi_idx in enumerate(selected_indices):\n",
    "                trace = df_f_traces[roi_idx]\n",
    "                \n",
    "                # Extract analysis window\n",
    "                analysis_start, analysis_end = analysis_frames\n",
    "                analysis_window = trace[analysis_start:analysis_end+1]\n",
    "                \n",
    "                # For evoked conditions, calculate and display stimulus time\n",
    "                if condition.value != '0um':\n",
    "                    stim_frame = 100  # Frame where stimulus occurs\n",
    "                \n",
    "                # Extract peaks\n",
    "                if condition.value == '0um':\n",
    "                    # For spontaneous, look at peaks during baseline period\n",
    "                    baseline_trace = trace[baseline_frames[0]:baseline_frames[1]+1]\n",
    "                    peaks, properties = find_peaks(\n",
    "                        baseline_trace,\n",
    "                        prominence=prominence.value/2,  # Use lower threshold for spontaneous\n",
    "                        width=width.value,\n",
    "                        distance=distance.value,\n",
    "                        height=height.value\n",
    "                    )\n",
    "                    \n",
    "                    # Calculate peak frequency (peaks per 100 frames)\n",
    "                    peak_freq = len(peaks) / (len(baseline_trace) / 100) if len(baseline_trace) > 0 else 0\n",
    "                    \n",
    "                    # Check if ROI is active based on peak frequency\n",
    "                    is_active = peak_freq > active_threshold.value\n",
    "                    if is_active:\n",
    "                        active_rois += 1\n",
    "                    \n",
    "                    # Plot trace\n",
    "                    axes[i].plot(trace, 'k-')\n",
    "                    \n",
    "                    # Highlight baseline window\n",
    "                    axes[i].axvspan(baseline_frames[0], baseline_frames[1], color='lightgray', alpha=0.2)\n",
    "                    \n",
    "                    # Find and highlight peaks in full trace\n",
    "                    all_peaks, _ = find_peaks(\n",
    "                        trace,\n",
    "                        prominence=prominence.value/2,\n",
    "                        width=width.value,\n",
    "                        distance=distance.value,\n",
    "                        height=height.value\n",
    "                    )\n",
    "                    \n",
    "                    if len(all_peaks) > 0:\n",
    "                        axes[i].plot(all_peaks, trace[all_peaks], 'ro')\n",
    "                    \n",
    "                    # Add title with metrics\n",
    "                    axes[i].set_title(f\"ROI {roi_idx+1} - {'Active' if is_active else 'Inactive'} - Peak Freq: {peak_freq:.2f}/100 frames\")\n",
    "                    \n",
    "                else:\n",
    "                    # For evoked, look at peaks after stimulus\n",
    "                    peaks, properties = find_peaks(\n",
    "                        analysis_window,\n",
    "                        prominence=prominence.value,\n",
    "                        width=width.value,\n",
    "                        distance=distance.value,\n",
    "                        height=height.value\n",
    "                    )\n",
    "                    \n",
    "                    # Calculate peak amplitude (max value)\n",
    "                    peak_amplitude = np.max(analysis_window) if len(analysis_window) > 0 else 0\n",
    "                    \n",
    "                    # Check if ROI is active based on peak amplitude\n",
    "                    is_active = peak_amplitude > active_threshold.value\n",
    "                    if is_active:\n",
    "                        active_rois += 1\n",
    "                    \n",
    "                    # Plot trace\n",
    "                    axes[i].plot(trace, 'k-')\n",
    "                    \n",
    "                    # Add a vertical line at stimulus time\n",
    "                    axes[i].axvline(x=stim_frame, color='r', linestyle='--', alpha=0.7)\n",
    "                    \n",
    "                    # Highlight analysis window\n",
    "                    axes[i].axvspan(analysis_start, analysis_end, color='lightgray', alpha=0.2)\n",
    "                    \n",
    "                    # Find and highlight peaks\n",
    "                    if len(peaks) > 0:\n",
    "                        # Adjust peak indices to match original trace\n",
    "                        adjusted_peaks = peaks + analysis_start\n",
    "                        axes[i].plot(adjusted_peaks, trace[adjusted_peaks], 'ro')\n",
    "                    \n",
    "                    # Add title with metrics\n",
    "                    axes[i].set_title(f\"ROI {roi_idx+1} - {'Active' if is_active else 'Inactive'} - Peak Amplitude: {peak_amplitude:.4f}\")\n",
    "                \n",
    "                # Add zero line for reference\n",
    "                axes[i].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "                \n",
    "                # Add a threshold line\n",
    "                axes[i].axhline(y=active_threshold.value, color='g', linestyle=':', alpha=0.5)\n",
    "                \n",
    "                axes[i].set_xlabel('Frame')\n",
    "                axes[i].set_ylabel('dF/F')\n",
    "                axes[i].grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.suptitle(f\"Event Detection - {title_suffix} ({active_rois}/{n_rois} ROIs Active)\", fontsize=16, y=1.02)\n",
    "            plt.show()\n",
    "            \n",
    "            # Update config with current values\n",
    "            # Peak detection parameters\n",
    "            if 'peak_detection' not in config['analysis']:\n",
    "                config['analysis']['peak_detection'] = {}\n",
    "            \n",
    "            config['analysis']['peak_detection']['prominence'] = prominence.value\n",
    "            config['analysis']['peak_detection']['width'] = width.value\n",
    "            config['analysis']['peak_detection']['distance'] = distance.value\n",
    "            config['analysis']['peak_detection']['height'] = height.value\n",
    "            \n",
    "            # Activity threshold\n",
    "            config['analysis']['active_threshold'] = active_threshold.value\n",
    "            \n",
    "            # Condition-specific parameters\n",
    "            if 'condition_specific' not in config['analysis']:\n",
    "                config['analysis']['condition_specific'] = {}\n",
    "            \n",
    "            if condition.value not in config['analysis']['condition_specific']:\n",
    "                config['analysis']['condition_specific'][condition.value] = {}\n",
    "            \n",
    "            config['analysis']['condition_specific'][condition.value]['active_threshold'] = active_threshold.value\n",
    "            config['analysis']['condition_specific'][condition.value]['active_metric'] = active_metric\n",
    "            \n",
    "            print(f\"Updated config with: prominence={prominence.value}, width={width.value}, distance={distance.value}, height={height.value}\")\n",
    "            print(f\"active_threshold={active_threshold.value}, condition={condition.value}, active_metric={active_metric}\")\n",
    "            print(\"To apply these settings to your pipeline, update your config.yaml file.\")\n",
    "    \n",
    "    # Create display button\n",
    "    display_button = widgets.Button(\n",
    "        description='Display Event Detection',\n",
    "        button_style='success',\n",
    "        tooltip='Display event detection for selected ROIs'\n",
    "    )\n",
    "    display_button.on_click(display_event_detection)\n",
    "    \n",
    "    # Create description of event detection parameters\n",
    "    event_info = widgets.HTML(\n",
    "        \"\"\"\n",
    "        <h3>Event Detection Parameters:</h3>\n",
    "        <ul>\n",
    "            <li><strong>Prominence</strong>: Minimum vertical distance between a peak and its neighboring valleys. Higher values detect only more significant peaks.</li>\n",
    "            <li><strong>Width</strong>: Minimum width of peaks in frames. Increase to detect broader peaks.</li>\n",
    "            <li><strong>Distance</strong>: Minimum distance between peaks in frames. Increase to avoid detecting multiple peaks in one event.</li>\n",
    "            <li><strong>Height</strong>: Minimum height threshold for peaks. Peaks below this value are ignored.</li>\n",
    "            <li><strong>Activity Threshold</strong>: Threshold to determine if an ROI is considered active.</li>\n",
    "        </ul>\n",
    "        <p><strong>Condition:</strong> Select the appropriate condition to adjust analysis parameters. For spontaneous activity (0µm), all frames are analyzed. For evoked activity (10µm, 25µm), only frames after stimulus are analyzed.</p>\n",
    "        <p>Select ROIs to visualize, then click \"Display Event Detection\".</p>\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Create widget layout\n",
    "    parameter_widgets = widgets.VBox([\n",
    "        prominence,\n",
    "        width, \n",
    "        distance, \n",
    "        height,\n",
    "        active_threshold,\n",
    "        condition\n",
    "    ])\n",
    "    \n",
    "    control_widgets = widgets.VBox([\n",
    "        roi_indices,\n",
    "        display_button\n",
    "    ])\n",
    "    \n",
    "    # Display all widgets\n",
    "    display(event_info)\n",
    "    display(widgets.HBox([parameter_widgets, control_widgets]))\n",
    "    display(output)\n",
    "\n",
    "# Run the function directly\n",
    "run_event_detection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2d4dc2-ef51-4b0e-9c8d-e9dd6ba695de",
   "metadata": {},
   "source": [
    "## Save Optimized Configuration\n",
    "\n",
    "After exploring different parameter settings in the interactive visualizations, you can save your optimized configuration for future use. This will create a new YAML configuration file with all the parameter adjustments you've made.\n",
    "\n",
    "### Options\n",
    "- **Save Configuration**: Write the current parameters to a YAML file\n",
    "- **Print Current Configuration**: Display the current configuration in the notebook\n",
    "- **Reset Configuration**: Revert to the original configuration that was loaded\n",
    "\n",
    "The saved configuration can be used with the command-line version of the pipeline by specifying the `--config` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2547e3b2-98e7-4aef-9cdb-91d96c97d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Configuration Management {display-mode: \"form\"}\n",
    "def save_config_to_file():\n",
    "    \"\"\"Save the updated configuration to a YAML file\"\"\"\n",
    "    # Create a file selector\n",
    "    output_path = widgets.Text(\n",
    "        value='optimized_config.yaml',\n",
    "        placeholder='Enter file path to save config',\n",
    "        description='Output File:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "    \n",
    "    display(output_path)\n",
    "    \n",
    "    # Create a save button\n",
    "    save_button = widgets.Button(\n",
    "        description='Save Configuration',\n",
    "        button_style='success',\n",
    "        tooltip='Click to save the current configuration to a file'\n",
    "    )\n",
    "    \n",
    "    def on_save_click(b):\n",
    "        try:\n",
    "            path = output_path.value\n",
    "            if not path:\n",
    "                print(\"Please enter a valid file path\")\n",
    "                return\n",
    "            \n",
    "            # Save the configuration to the specified file\n",
    "            with open(path, 'w') as f:\n",
    "                yaml.dump(config, f, default_flow_style=False)\n",
    "            \n",
    "            print(f\"Configuration saved to {path}\")\n",
    "            print(\"To use this configuration in your pipeline, specify it with the --config parameter\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving configuration: {str(e)}\")\n",
    "    \n",
    "    save_button.on_click(on_save_click)\n",
    "    display(save_button)\n",
    "    \n",
    "    # Create a button to print the current configuration\n",
    "    print_button = widgets.Button(\n",
    "        description='Print Current Configuration',\n",
    "        button_style='info',\n",
    "        tooltip='Click to print the current configuration to the notebook'\n",
    "    )\n",
    "    \n",
    "    def on_print_click(b):\n",
    "        # Print the configuration in a readable format\n",
    "        print(\"Current Configuration:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Print as formatted YAML\n",
    "        print(yaml.dump(config, default_flow_style=False))\n",
    "    \n",
    "    print_button.on_click(on_print_click)\n",
    "    display(print_button)\n",
    "    \n",
    "    # Create a button to reset configuration to original\n",
    "    reset_button = widgets.Button(\n",
    "        description='Reset Configuration',\n",
    "        button_style='danger',\n",
    "        tooltip='Click to reset the configuration to the original values'\n",
    "    )\n",
    "    \n",
    "    def on_reset_click(b):\n",
    "        # Reset the configuration to the original values\n",
    "        global config\n",
    "        config = copy.deepcopy(config_original)\n",
    "        print(\"Configuration reset to original values\")\n",
    "    \n",
    "    reset_button.on_click(on_reset_click)\n",
    "    display(reset_button)\n",
    "\n",
    "# Call the save configuration function\n",
    "save_config_to_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d137d-6c09-4a29-8556-b4c8b2dfffc0",
   "metadata": {},
   "source": [
    "## Run Full Pipeline\n",
    "\n",
    "Once you've optimized the parameters using the interactive visualizations, you can run the complete analysis pipeline on all your data. The pipeline will:\n",
    "\n",
    "1. Process all matched TIF/ROI file pairs in the input directory\n",
    "2. Apply preprocessing with your optimized parameters\n",
    "3. Extract and refine ROIs\n",
    "4. Perform background subtraction\n",
    "5. Detect and analyze events\n",
    "6. Generate visualizations and metrics\n",
    "\n",
    "The results will be saved in the output directory specified in the parameters section. Each file pair will have its own subdirectory containing:\n",
    "- Corrected data (HDF5 format)\n",
    "- ROI masks and traces\n",
    "- Analysis metrics (Excel and CSV)\n",
    "- Visualizations (PNG format)\n",
    "\n",
    "### Performance Considerations\n",
    "- Processing multiple large files can be memory-intensive\n",
    "- The pipeline supports parallel processing using multiple CPU cores\n",
    "- Adjust the \"Max Workers\" parameter based on your computer's capabilities\n",
    "\n",
    "Click \"Run Full Pipeline\" to start processing all file pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b143ed1-fd8e-4cd0-91c9-d708d3d033f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc33c25414649c3a6070ca316b39856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n        <div style=\"background-color: #ffe6e6; padding: 10px; border-radius: 5px; margin-bottom:…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0870ec6da822430f97e8e232f1d6bf93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Config Source:', layout=Layout(width='50%'), options=(('Use current configuration in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ccdf1175a54c0ea64bdfec127aaa90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af2b8a04eaa46c49a977796a8edb38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Run Full Pipeline', style=ButtonStyle(), tooltip='Click to run the …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eca81ea059c45409508a1d87fe93b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Run Full Pipeline {display-mode: \"form\"}\n",
    "def run_full_pipeline():\n",
    "    \"\"\"Run the full analysis pipeline with the option to choose configuration\"\"\"\n",
    "    global config\n",
    "    \n",
    "    if 'config' not in globals() or config is None:\n",
    "        print(\"Please load configuration first\")\n",
    "        return\n",
    "    \n",
    "    # Create a dropdown to select configuration source\n",
    "    config_source = widgets.RadioButtons(\n",
    "        options=[\n",
    "            ('Use current configuration in memory', 'current'),\n",
    "            ('Load configuration from file', 'file')\n",
    "        ],\n",
    "        value='current',\n",
    "        description='Config Source:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='50%')\n",
    "    )\n",
    "    \n",
    "    # File selector widget (hidden initially)\n",
    "    file_selector_container = widgets.VBox([])\n",
    "    \n",
    "    def update_file_selector():\n",
    "        # Clear existing widgets\n",
    "        file_selector_container.children = ()\n",
    "        \n",
    "        if config_source.value == 'file':\n",
    "            # Create file path input\n",
    "            file_path = widgets.Text(\n",
    "                value='',\n",
    "                placeholder='Enter path to config YAML file',\n",
    "                description='Config file:',\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='70%')\n",
    "            )\n",
    "            \n",
    "            # Create a button to browse files\n",
    "            browse_button = widgets.Button(\n",
    "                description='Browse...',\n",
    "                button_style='info',\n",
    "                tooltip='Browse for configuration files',\n",
    "                layout=widgets.Layout(width='120px')\n",
    "            )\n",
    "            \n",
    "            # Function to handle file browsing\n",
    "            def on_browse_click(b):\n",
    "                # Create file browser UI - this is just an example\n",
    "                # In a real implementation, you'd use a file picker appropriate for your environment\n",
    "                config_dir = args.output_dir if hasattr(args, 'output_dir') else '.'\n",
    "                \n",
    "                # List YAML files in the directory\n",
    "                import glob\n",
    "                yaml_files = glob.glob(os.path.join(config_dir, '*.yaml')) + glob.glob(os.path.join(config_dir, '*.yml'))\n",
    "                \n",
    "                if not yaml_files:\n",
    "                    print(\"No YAML files found in\", config_dir)\n",
    "                    return\n",
    "                \n",
    "                # Create a dropdown for selecting a file\n",
    "                file_dropdown = widgets.Dropdown(\n",
    "                    options=yaml_files,\n",
    "                    description='Select file:',\n",
    "                    style={'description_width': 'initial'},\n",
    "                    layout=widgets.Layout(width='70%')\n",
    "                )\n",
    "                \n",
    "                # Function to update file path when selection changes\n",
    "                def on_selection_change(change):\n",
    "                    file_path.value = change['new']\n",
    "                \n",
    "                file_dropdown.observe(on_selection_change, names='value')\n",
    "                \n",
    "                # Display the dropdown in a new output\n",
    "                browse_output.clear_output()\n",
    "                with browse_output:\n",
    "                    display(file_dropdown)\n",
    "            \n",
    "            browse_button.on_click(on_browse_click)\n",
    "            \n",
    "            # Container for file browser output\n",
    "            browse_output = widgets.Output()\n",
    "            \n",
    "            # Add widgets to container\n",
    "            file_selector_container.children = (\n",
    "                widgets.HBox([file_path, browse_button]),\n",
    "                browse_output\n",
    "            )\n",
    "    \n",
    "    # Update file selector when config source changes\n",
    "    config_source.observe(lambda change: update_file_selector(), names='value')\n",
    "    \n",
    "    # Create a button to run the pipeline\n",
    "    run_button = widgets.Button(\n",
    "        description='Run Full Pipeline',\n",
    "        button_style='danger',\n",
    "        tooltip='Click to run the full pipeline with selected configuration'\n",
    "    )\n",
    "    \n",
    "    # Output for pipeline progress\n",
    "    pipeline_output = widgets.Output()\n",
    "    \n",
    "    # Function to run the pipeline\n",
    "    def on_run_click(b):\n",
    "        with pipeline_output:\n",
    "            clear_output()\n",
    "            print(\"Starting pipeline execution...\")\n",
    "            \n",
    "            try:\n",
    "                # Determine which config to use\n",
    "                if config_source.value == 'current':\n",
    "                    # Use current config in memory\n",
    "                    config_to_use = config\n",
    "                    print(\"Using current configuration in memory\")\n",
    "                else:\n",
    "                    # Load config from file\n",
    "                    if len(file_selector_container.children) > 0:\n",
    "                        file_path_widget = file_selector_container.children[0].children[0]\n",
    "                        config_file_path = file_path_widget.value\n",
    "                        \n",
    "                        if not config_file_path:\n",
    "                            print(\"Error: No configuration file specified\")\n",
    "                            return\n",
    "                        \n",
    "                        if not os.path.exists(config_file_path):\n",
    "                            print(f\"Error: Configuration file not found: {config_file_path}\")\n",
    "                            return\n",
    "                        \n",
    "                        # Load the specified config file\n",
    "                        try:\n",
    "                            with open(config_file_path, 'r') as f:\n",
    "                                config_to_use = yaml.safe_load(f)\n",
    "                            print(f\"Loaded configuration from: {config_file_path}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error loading configuration file: {str(e)}\")\n",
    "                            return\n",
    "                    else:\n",
    "                        print(\"Error: File selection UI not properly initialized\")\n",
    "                        return\n",
    "                \n",
    "                print(f\"Input directory: {args.input_dir}\")\n",
    "                print(f\"Output directory: {args.output_dir}\")\n",
    "                print(f\"Pipeline mode: {args.mode}\")\n",
    "                print(f\"Max workers: {args.max_workers}\")\n",
    "                print(\"=\" * 50)\n",
    "                \n",
    "                # Save the selected configuration to a temporary file\n",
    "                temp_config_path = os.path.join(args.output_dir, 'temp_config.yaml')\n",
    "                with open(temp_config_path, 'w') as f:\n",
    "                    yaml.dump(config_to_use, f, default_flow_style=False)\n",
    "                \n",
    "                print(f\"Saved configuration to {temp_config_path}\")\n",
    "                \n",
    "                # Import the main pipeline function\n",
    "                from pipeline import main\n",
    "                \n",
    "                # Update args with the temp config path\n",
    "                args.config = temp_config_path\n",
    "                \n",
    "                # Run the pipeline\n",
    "                print(\"\\nExecuting pipeline. This may take a while...\\n\")\n",
    "                \n",
    "                # In a Jupyter notebook, we need to use a different approach than in the script\n",
    "                # since we can't directly use sys.argv\n",
    "                import sys\n",
    "                original_argv = sys.argv\n",
    "                \n",
    "                # Create mock argv\n",
    "                sys.argv = ['pipeline.py', \n",
    "                           f'--input_dir={args.input_dir}', \n",
    "                           f'--output_dir={args.output_dir}',\n",
    "                           f'--config={temp_config_path}',\n",
    "                           f'--mode={args.mode}',\n",
    "                           f'--max_workers={args.max_workers}']\n",
    "                \n",
    "                if args.disable_advanced:\n",
    "                    sys.argv.append('--disable_advanced')\n",
    "                \n",
    "                # Execute the pipeline\n",
    "                try:\n",
    "                    main()\n",
    "                    print(\"\\nPipeline completed successfully!\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error executing pipeline: {str(e)}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc()\n",
    "                \n",
    "                # Restore original argv\n",
    "                sys.argv = original_argv\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error setting up pipeline: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "    \n",
    "    run_button.on_click(on_run_click)\n",
    "    \n",
    "    # Create warning about running the full pipeline\n",
    "    warning_text = widgets.HTML(\n",
    "        \"\"\"\n",
    "        <div style=\"background-color: #ffe6e6; padding: 10px; border-radius: 5px; margin-bottom: 10px;\">\n",
    "            <h3 style=\"color: #cc0000;\">⚠️ Warning</h3>\n",
    "            <p>This will run the full pipeline on all files in the input directory using the selected configuration.</p>\n",
    "            <p>Depending on the number of files and your settings, this could take a long time to complete.</p>\n",
    "            <p>Make sure your configuration parameters are optimized before running the full pipeline.</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Display all components\n",
    "    display(warning_text)\n",
    "    display(config_source)\n",
    "    display(file_selector_container)\n",
    "    display(run_button)\n",
    "    display(pipeline_output)\n",
    "    \n",
    "    # Initialize the file selector based on the default value\n",
    "    update_file_selector()\n",
    "\n",
    "# Run the function\n",
    "run_full_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34d9106-bb03-4189-a7d1-4d3e118e4149",
   "metadata": {},
   "source": [
    "## Notebook Summary\n",
    "\n",
    "This interactive notebook provides a user-friendly interface to the fluorescence analysis pipeline, allowing you to:\n",
    "\n",
    "1. **Load and Configure**: Set up pipeline parameters and load configuration from YAML file\n",
    "2. **Select and Preprocess Data**: Load TIF/ROI file pairs and prepare them for analysis\n",
    "3. **Explore Parameter Effects**: Use interactive visualizations to understand how different parameters affect:\n",
    "   - Gaussian denoising image quality\n",
    "   - ROI selection with PNR refinement\n",
    "   - Background subtraction effectiveness \n",
    "   - Event detection sensitivity and specificity\n",
    "4. **Optimize Settings**: Adjust parameters to find optimal values for your specific dataset\n",
    "5. **Save Configuration**: Save your optimized configuration for future use\n",
    "6. **Run Full Pipeline**: Process all file pairs with your optimized settings\n",
    "\n",
    "### Output Data\n",
    "The analysis results saved in the output directory include:\n",
    "- Corrected fluorescence data (HDF5 format)\n",
    "- ROI masks and fluorescence traces\n",
    "- Analysis metrics for each ROI (Excel and CSV format)\n",
    "- Visualizations of ROIs, traces, and detected events\n",
    "\n",
    "### Advanced Analysis\n",
    "For more sophisticated analysis of the pipeline outputs, you can:\n",
    "- Use the generated CSVs and Excel files for statistical analysis\n",
    "- Load the HDF5 files for custom visualization and processing\n",
    "- Examine the visualization PNGs for quality control\n",
    "- Compare results across different experimental conditions\n",
    "\n",
    "For questions or issues with the pipeline, please refer to the documentation or contact the developers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0699c8f7-c0ac-44c8-9997-7828f92c549d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
