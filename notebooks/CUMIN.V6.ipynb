{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a9911b3-d435-465d-9d70-aec08af5418c",
   "metadata": {},
   "source": [
    "# CUMIN (CUrated MINion): A Fluorescence Analysis Pipeline for Curated ROIs\n",
    "\n",
    "This notebook provides an interactive interface to the fluorescence analysis pipeline, allowing you to explore parameter effects on ROI detection, trace extraction, and event analysis.\n",
    "\n",
    "## Overview\n",
    "- Load and select fluorescence imaging data\n",
    "- Explore parameter effects with interactive visualizations:\n",
    "  - Gaussian denoising for image preprocessing\n",
    "  - ROI processing with PNR refinement\n",
    "  - Background subtraction for improved signal\n",
    "  - Event detection and analysis\n",
    "- Save optimized configurations\n",
    "- Run the full pipeline with optimized parameters\n",
    "\n",
    "Each section includes in-depth explanations of the algorithms and parameters, helping you understand how different settings affect your analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eec9f9-a621-4531-b84e-e6a0784a703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datashader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ec1e1d-73c5-45c0-9898-e3976ddebdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Import Libraries and Setup {display-mode: \"form\"}\n",
    "# Import standard libraries\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import tifffile\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import copy\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "from scipy.ndimage import binary_dilation, median_filter\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from holoviews.operation.datashader import datashade, regrid\n",
    "from holoviews.util import Dynamic\n",
    "from IPython.core.display import display\n",
    "\n",
    "# Import interactive libraries\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, fixed, interact_manual, interactive\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Add parent directory to path if notebook is in notebooks/\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "\n",
    "# Add current directory to path to import local modules\n",
    "if '.' not in sys.path:\n",
    "    sys.path.append('.')\n",
    "\n",
    "# Import pipeline modules\n",
    "try:\n",
    "    from modules.file_matcher import match_tif_and_roi_files\n",
    "    from modules.preprocessing import (\n",
    "        correct_photobleaching,\n",
    "        remove_background,\n",
    "        denoise,\n",
    "        stripe_correction\n",
    "    )\n",
    "    from modules.roi_processing import (\n",
    "        extract_roi_fluorescence, \n",
    "        subtract_background,\n",
    "        subtract_global_background,\n",
    "        extract_rois_from_zip, \n",
    "        save_masks_for_cnmf, \n",
    "        extract_roi_fluorescence_with_cnmf,\n",
    "        refine_rois_with_cnmfe,\n",
    "        refine_rois_with_pnr,\n",
    "        split_signal_noise,\n",
    "        visualize_pnr_results,\n",
    "        save_trace_data\n",
    "    )\n",
    "    from modules.analysis import (\n",
    "        analyze_fluorescence, \n",
    "        perform_qc_checks,\n",
    "        extract_peak_parameters,\n",
    "        extract_spontaneous_activity,\n",
    "        calculate_baseline_excluding_peaks\n",
    "    )\n",
    "    from modules.visualization import generate_visualizations\n",
    "    from modules.utils import setup_logging, save_slice_data, save_mouse_summary\n",
    "    from modules.visualization_helpers import (\n",
    "        create_denoising_visualization,\n",
    "        create_pnr_refinement_visualization,\n",
    "        create_background_subtraction_visualization,\n",
    "        create_event_detection_visualization\n",
    "    )\n",
    "    \n",
    "    # Try importing advanced analysis module if available\n",
    "    try:\n",
    "        from modules.advanced_analysis import run_advanced_analysis\n",
    "        ADVANCED_ANALYSIS_AVAILABLE = True\n",
    "    except ImportError:\n",
    "        ADVANCED_ANALYSIS_AVAILABLE = False\n",
    "        print(\"Advanced analysis module not available. Some features will be disabled.\")\n",
    "    \n",
    "    print(\"Successfully imported all modules\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing modules: {e}\")\n",
    "    print(\"Make sure the required modules are in the 'modules' directory or adjust the import path.\")\n",
    "    \n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e373ae-e3e6-4f63-8f67-32eab7f50521",
   "metadata": {},
   "source": [
    "## Setting Up Pipeline Parameters\n",
    "\n",
    "Before starting the analysis, we need to configure the pipeline parameters including:\n",
    "\n",
    "- **Input Directory**: Location of your .tif (image) and .zip (ROI) files\n",
    "- **Output Directory**: Where analysis results will be saved\n",
    "- **Configuration File**: YAML file with pipeline parameters\n",
    "- **Pipeline Mode**: \"all\" runs the complete pipeline; other options are \"preprocess\", \"extract\", and \"analyze\"\n",
    "- **Max Workers**: Number of parallel processes for multi-core processing\n",
    "\n",
    "You can adjust these parameters below. Click \"Update Parameters\" after making changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e737f7-f403-49c7-85a8-cf9a17e3222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Pipeline Parameters {display-mode: \"form\"}\n",
    "class Args:\n",
    "    \"\"\"Class to simulate command line arguments\"\"\"\n",
    "    def __init__(self):\n",
    "        self.input_dir = r\"F:\\Recovered\\Research\\BoninLab\\PainModelingProject\\calcium_imaging_data\\CAAR Testing\\CAAR part2 data\\paclitaxel\"  # CHANGE THIS\n",
    "        self.output_dir = r\"F:\\Recovered\\Research\\BoninLab\\PainModelingProject\\calcium_imaging_data\\CAAR Testing\\CUMIN output\\CUMIN_51_optimized_15\"   # CHANGE THIS\n",
    "        self.config = \"../config.yaml\"  # Path to your config file\n",
    "        self.mode = \"all\"  # Options: \"all\", \"preprocess\", \"extract\", \"analyze\"\n",
    "        self.max_workers = 4  # Adjust based on your CPU cores\n",
    "        self.disable_advanced = False\n",
    "\n",
    "# Create args object\n",
    "args = Args()\n",
    "\n",
    "# Create interactive widgets for adjusting parameters\n",
    "input_dir_widget = widgets.Text(\n",
    "    value=args.input_dir,\n",
    "    description='Input Directory:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "output_dir_widget = widgets.Text(\n",
    "    value=args.output_dir,\n",
    "    description='Output Directory:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "config_widget = widgets.Text(\n",
    "    value=args.config,\n",
    "    description='Config File:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "mode_widget = widgets.Dropdown(\n",
    "    options=['all', 'preprocess', 'extract', 'analyze'],\n",
    "    value=args.mode,\n",
    "    description='Pipeline Mode:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "workers_widget = widgets.IntSlider(\n",
    "    value=args.max_workers,\n",
    "    min=1,\n",
    "    max=12,\n",
    "    step=1,\n",
    "    description='Max Workers:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "disable_advanced_widget = widgets.Checkbox(\n",
    "    value=args.disable_advanced,\n",
    "    description='Disable Advanced Analysis',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Function to update args object based on widget values\n",
    "def update_args():\n",
    "    args.input_dir = input_dir_widget.value\n",
    "    args.output_dir = output_dir_widget.value\n",
    "    args.config = config_widget.value\n",
    "    args.mode = mode_widget.value\n",
    "    args.max_workers = workers_widget.value\n",
    "    args.disable_advanced = disable_advanced_widget.value\n",
    "    print(\"Parameters updated:\")\n",
    "    print(f\"Input Directory: {args.input_dir}\")\n",
    "    print(f\"Output Directory: {args.output_dir}\")\n",
    "    print(f\"Config File: {args.config}\")\n",
    "    print(f\"Pipeline Mode: {args.mode}\")\n",
    "    print(f\"Max Workers: {args.max_workers}\")\n",
    "    print(f\"Disable Advanced Analysis: {args.disable_advanced}\")\n",
    "\n",
    "# Create update button\n",
    "update_button = widgets.Button(\n",
    "    description='Update Parameters',\n",
    "    button_style='info',\n",
    "    tooltip='Click to update parameters'\n",
    ")\n",
    "\n",
    "update_button.on_click(lambda b: update_args())\n",
    "\n",
    "# Display widgets\n",
    "display(input_dir_widget)\n",
    "display(output_dir_widget)\n",
    "display(config_widget)\n",
    "display(mode_widget)\n",
    "display(workers_widget)\n",
    "display(disable_advanced_widget)\n",
    "display(update_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd871866-26b2-49d1-a609-a62af63e0200",
   "metadata": {},
   "source": [
    "## Loading Configuration\n",
    "\n",
    "The pipeline configuration is stored in a YAML file that defines parameters for each processing step. \n",
    "The configuration includes settings for:\n",
    "\n",
    "- **Preprocessing**: Methods and parameters for photo-bleaching correction, denoising, etc.\n",
    "- **ROI Processing**: ROI extraction, refinement, and background subtraction\n",
    "- **Analysis**: Event detection parameters, condition-specific settings, etc.\n",
    "- **Visualization**: Plot types, colormaps, and other visualization settings\n",
    "\n",
    "Click \"Load Configuration\" to load the configuration file specified in the parameters section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5adf4d-fcab-444b-a769-62f0574acdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Load Configuration {display-mode: \"form\"}\n",
    "def load_config(config_path, args=None):\n",
    "    \"\"\"Load configuration from YAML file and apply command line overrides.\"\"\"\n",
    "    try:\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        print(f\"Loaded configuration from {config_path}\")\n",
    "        \n",
    "        # Apply command line overrides if provided\n",
    "        if args and args.disable_advanced:\n",
    "            # Disable advanced analysis if requested via command line\n",
    "            if \"advanced_analysis\" in config:\n",
    "                config[\"advanced_analysis\"][\"enabled\"] = False\n",
    "                print(\"Advanced analysis disabled via command line argument\")\n",
    "        \n",
    "        return config\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load configuration: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Setup logging\n",
    "logger = setup_logging()\n",
    "\n",
    "# Create a load button\n",
    "load_config_button = widgets.Button(\n",
    "    description='Load Configuration',\n",
    "    button_style='success',\n",
    "    tooltip='Click to load the configuration file'\n",
    ")\n",
    "\n",
    "def on_load_config_click(b):\n",
    "    global config, config_original\n",
    "    # Load configuration\n",
    "    config = load_config(args.config, args)\n",
    "\n",
    "    if config:\n",
    "        print(\"Configuration loaded successfully.\")\n",
    "        \n",
    "        # Create a backup of original config for reference\n",
    "        config_original = copy.deepcopy(config)\n",
    "        \n",
    "        # Print some key configuration settings\n",
    "        print(\"\\nKey Configuration Settings:\")\n",
    "        print(f\"Photobleaching correction method: {config['preprocessing'].get('correction_method', 'Not specified')}\")\n",
    "        if 'denoise' in config['preprocessing']:\n",
    "            print(f\"Denoising enabled: {config['preprocessing']['denoise'].get('enabled', False)}\")\n",
    "        print(f\"Background subtraction method: {config['roi_processing'].get('background', {}).get('method', 'Not specified')}\")\n",
    "    else:\n",
    "        print(\"Failed to load configuration. Please check the config file path.\")\n",
    "\n",
    "load_config_button.on_click(on_load_config_click)\n",
    "display(load_config_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7234c599-2e19-4c29-8da5-ff0752f5d4fb",
   "metadata": {},
   "source": [
    "## Data Selection and Loading\n",
    "\n",
    "This section allows you to select a file pair (TIF image stack and ZIP ROI file) for analysis. The pipeline searches for matching file pairs in the input directory.\n",
    "\n",
    "### File Pairs\n",
    "A file pair consists of:\n",
    "- A **.tif file** containing the fluorescence imaging data (time series of frames)\n",
    "- A **.zip file** containing ImageJ/FIJI ROI definitions\n",
    "\n",
    "### Loading Process\n",
    "When you load a file pair, the following happens:\n",
    "1. The TIF stack is loaded and preprocessed\n",
    "2. ROI masks are extracted from the ZIP file\n",
    "3. Intermediate data is prepared for interactive visualization\n",
    "4. Visualization data is saved for future use\n",
    "\n",
    "Select a file pair from the dropdown menu and click \"Load Selected File Pair\" to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d80dd3-55de-4a1b-84c7-43a964f95c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title File Selection and Loading {display-mode: \"form\"}\n",
    "# Find matching TIF and ROI file pairs\n",
    "# Define extract_metadata_from_filename function\n",
    "def extract_metadata_from_filename(filename):\n",
    "    \"\"\"Extract metadata from custom filename pattern 'CFA1_7.23.20_ipsi1_0um'.\"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Initialize metadata dictionary\n",
    "    metadata = {\n",
    "        \"mouse_id\": \"unknown\",\n",
    "        \"date\": \"unknown\",\n",
    "        \"pain_model\": \"unknown\",\n",
    "        \"slice_type\": \"unknown\",\n",
    "        \"slice_number\": \"1\",\n",
    "        \"condition\": \"unknown\"\n",
    "    }\n",
    "    \n",
    "    # Split filename by underscore\n",
    "    parts = filename.split('_')\n",
    "    \n",
    "    if len(parts) < 3:\n",
    "        return metadata\n",
    "    \n",
    "    # First part typically contains pain model + mouse number (e.g., \"CFA1\")\n",
    "    if parts[0]:\n",
    "        # Extract pain model (letters) and mouse number (digits)\n",
    "        model_match = re.match(r'([A-Za-z]+)([0-9]*)', parts[0])\n",
    "        if model_match:\n",
    "            metadata[\"pain_model\"] = model_match.group(1)\n",
    "            mouse_number = model_match.group(2) or \"1\"\n",
    "            metadata[\"mouse_id\"] = f\"{metadata['pain_model']}{mouse_number}\"\n",
    "        else:\n",
    "            metadata[\"mouse_id\"] = parts[0]\n",
    "    \n",
    "    # Second part is usually the date\n",
    "    if len(parts) > 1:\n",
    "        metadata[\"date\"] = parts[1]\n",
    "    \n",
    "    # Third part usually contains slice type and number\n",
    "    if len(parts) > 2:\n",
    "        # Look for ipsi/contra with optional number\n",
    "        slice_match = re.match(r'(ipsi|contra)([0-9]*)', parts[2].lower())\n",
    "        if slice_match:\n",
    "            metadata[\"slice_type\"] = slice_match.group(1).capitalize()  # Capitalize first letter\n",
    "            metadata[\"slice_number\"] = slice_match.group(2) or \"1\"\n",
    "    \n",
    "    # Last part usually has the condition\n",
    "    for part in parts:\n",
    "        if any(cond in part.lower() for cond in [\"0um\", \"10um\", \"25um\"]):\n",
    "            metadata[\"condition\"] = part\n",
    "            break\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def find_file_pairs():\n",
    "    print(f\"Finding file pairs in {args.input_dir}...\")\n",
    "    file_pairs = match_tif_and_roi_files(args.input_dir, logger)\n",
    "    print(f\"Found {len(file_pairs)} matched file pairs\")\n",
    "    return file_pairs\n",
    "\n",
    "# Find file pairs button\n",
    "find_pairs_button = widgets.Button(\n",
    "    description='Find File Pairs',\n",
    "    button_style='info',\n",
    "    tooltip='Click to find matching TIF and ROI files'\n",
    ")\n",
    "\n",
    "def on_find_pairs_click(b):\n",
    "    print(\"Find button clicked!\")\n",
    "    global file_pairs\n",
    "    \n",
    "    # Find file pairs\n",
    "    file_pairs = find_file_pairs()\n",
    "    \n",
    "    if len(file_pairs) > 0:\n",
    "        print(\"Found file pairs:\")\n",
    "        for i, (tif_path, roi_path) in enumerate(file_pairs):\n",
    "            print(f\"{i+1}: {Path(tif_path).stem}\")\n",
    "        \n",
    "        # Always create dropdown, even for one pair\n",
    "        create_file_selection_dropdown()\n",
    "    else:\n",
    "        print(\"No file pairs found. Please check the input directory.\")\n",
    "\n",
    "def create_file_selection_dropdown():\n",
    "    \"\"\"Create the dropdown for selecting file pairs when multiple are found\"\"\"\n",
    "    global file_pair_dropdown\n",
    "    \n",
    "    # Create dropdown for file pair selection\n",
    "    pair_names = [f\"{i+1}: {Path(tif).stem}\" for i, (tif, roi) in enumerate(file_pairs)]\n",
    "    file_pair_dropdown = widgets.Dropdown(\n",
    "        options=list(zip(pair_names, range(len(file_pairs)))),\n",
    "        description='Select File Pair:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "    \n",
    "    def on_select_change(change):\n",
    "        index = change['new']\n",
    "        tif_path, roi_path = file_pairs[index]\n",
    "        print(f\"Selected file pair {index+1}:\")\n",
    "        print(f\"TIF: {tif_path}\")\n",
    "        print(f\"ROI: {roi_path}\")\n",
    "\n",
    "    file_pair_dropdown.observe(on_select_change, names='value')\n",
    "    \n",
    "    # Display the dropdown\n",
    "    display(file_pair_dropdown)\n",
    "    \n",
    "    # Create a button to load the selected file pair\n",
    "    load_button = widgets.Button(\n",
    "        description='Load Selected File Pair',\n",
    "        button_style='success',\n",
    "        tooltip='Click to load the selected file pair for analysis'\n",
    "    )\n",
    "    \n",
    "    load_button.on_click(lambda b: load_selected_pair(file_pair_dropdown.value))\n",
    "    display(load_button)\n",
    "\n",
    "def load_selected_pair(index):\n",
    "    \"\"\"Load the selected file pair\"\"\"\n",
    "    global selected_tif_path, selected_roi_path, image_data, image_shape\n",
    "    global roi_masks, roi_centers, slice_output_dir, corrected_data, roi_data, metadata\n",
    "    \n",
    "    selected_tif_path, selected_roi_path = file_pairs[index]\n",
    "    \n",
    "    print(f\"Loading file pair {index+1}:\")\n",
    "    print(f\"TIF: {selected_tif_path}\")\n",
    "    print(f\"ROI: {selected_roi_path}\")\n",
    "    \n",
    "    # Load image data\n",
    "    try:\n",
    "        print(\"Loading image data...\")\n",
    "        with tifffile.TiffFile(selected_tif_path) as tif:\n",
    "            image_data = tif.asarray()\n",
    "            \n",
    "            # Ensure data is in (frames, height, width) format\n",
    "            if len(image_data.shape) == 3:\n",
    "                if image_data.shape[0] < image_data.shape[1] and image_data.shape[0] < image_data.shape[2]:\n",
    "                    # Already in (frames, height, width) format\n",
    "                    pass\n",
    "                else:\n",
    "                    # Try to rearrange to (frames, height, width)\n",
    "                    if image_data.shape[2] < image_data.shape[0] and image_data.shape[2] < image_data.shape[1]:\n",
    "                        image_data = np.moveaxis(image_data, 2, 0)\n",
    "                    elif image_data.shape[1] < image_data.shape[0] and image_data.shape[1] < image_data.shape[2]:\n",
    "                        image_data = np.moveaxis(image_data, 1, 0)\n",
    "        \n",
    "        n_frames, height, width = image_data.shape\n",
    "        image_shape = (height, width)\n",
    "        \n",
    "        print(f\"Image loaded successfully with shape: {image_data.shape}\")\n",
    "        print(f\"Number of frames: {n_frames}\")\n",
    "        print(f\"Frame dimensions: {height}x{width}\")\n",
    "        \n",
    "        # Convert to float32 if needed\n",
    "        if image_data.dtype != np.float32:\n",
    "            image_data = image_data.astype(np.float32)\n",
    "            print(\"Converted data to float32\")\n",
    "        \n",
    "        # Extract metadata from filename\n",
    "        slice_name = Path(selected_tif_path).stem\n",
    "        metadata = extract_metadata_from_filename(slice_name)\n",
    "        print(f\"Extracted metadata: {metadata}\")\n",
    "        \n",
    "        # Extract ROI masks for visualization\n",
    "        roi_masks, roi_centers = extract_rois_from_zip(selected_roi_path, image_shape, logger)\n",
    "        print(f\"Extracted {len(roi_masks)} ROI masks\")\n",
    "        \n",
    "        # Create output directory for this slice\n",
    "        slice_output_dir = os.path.join(args.output_dir, slice_name)\n",
    "        os.makedirs(slice_output_dir, exist_ok=True)\n",
    "        print(f\"Created output directory: {slice_output_dir}\")\n",
    "        \n",
    "        # Run initial preprocessing to set up visualization data\n",
    "        print(\"Performing initial preprocessing for visualization...\")\n",
    "        corrected_data, _ = correct_photobleaching(\n",
    "            image_data,\n",
    "            None,  # No output file needed for visualization\n",
    "            config[\"preprocessing\"],\n",
    "            logger,\n",
    "            save_output=False\n",
    "        )\n",
    "        print(\"Initial preprocessing complete\")\n",
    "        \n",
    "        # Extract ROI fluorescence for visualization\n",
    "        _, roi_data = extract_roi_fluorescence(\n",
    "            selected_roi_path,\n",
    "            corrected_data,\n",
    "            image_shape,\n",
    "            slice_output_dir,\n",
    "            config[\"roi_processing\"],\n",
    "            logger\n",
    "        )\n",
    "        print(f\"Extracted fluorescence traces for {len(roi_masks)} ROIs\")\n",
    "        \n",
    "        # Save visualization data for later use\n",
    "        vis_data = {\n",
    "            'image_data': image_data,\n",
    "            'corrected_data': corrected_data,\n",
    "            'roi_masks': roi_masks,\n",
    "            'roi_centers': roi_centers,\n",
    "            'roi_data': roi_data,\n",
    "            'metadata': metadata,\n",
    "            'selected_tif_path': selected_tif_path,\n",
    "            'selected_roi_path': selected_roi_path,\n",
    "            'image_shape': image_shape\n",
    "        }\n",
    "        \n",
    "        # Save visualization data\n",
    "        vis_data_file = os.path.join(slice_output_dir, \"visualization_data.pkl\")\n",
    "        with open(vis_data_file, 'wb') as f:\n",
    "            pickle.dump(vis_data, f)\n",
    "            \n",
    "        print(f\"Saved visualization data to {vis_data_file}\")\n",
    "        print(\"Data loaded successfully and ready for visualization!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading files: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Set up button click handler\n",
    "find_pairs_button.on_click(on_find_pairs_click)\n",
    "print(\"Button ready. Click to find file pairs.\")\n",
    "display(find_pairs_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5365fe25-0ca3-4868-9a11-3725fbdb20a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a new cell\n",
    "create_file_selection_dropdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb7132b-9a80-4224-9a46-a70af5e0979d",
   "metadata": {},
   "source": [
    "## Load Previously Saved Visualization Data\n",
    "\n",
    "If you've previously run this notebook and saved visualization data, you can load it here instead of reprocessing the data. This saves time when you want to continue exploring the same dataset.\n",
    "\n",
    "The visualization data includes:\n",
    "- Original image data\n",
    "- Preprocessed (corrected) data\n",
    "- ROI masks and centers\n",
    "- ROI fluorescence traces\n",
    "- Metadata extracted from the filename\n",
    "\n",
    "Enter the path to the saved visualization data file (`visualization_data.pkl`) and click \"Load Saved Visualization Data\" to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f916e-5182-403c-b8ea-b5ccc739352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Load Saved Visualization Data {display-mode: \"form\"}\n",
    "def load_visualization_data(data_file):\n",
    "    \"\"\"Load saved visualization data from pickle file\"\"\"\n",
    "    try:\n",
    "        with open(data_file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Assign to global variables for use in visualizations\n",
    "        global image_data, corrected_data, roi_masks, roi_centers, roi_data, metadata, selected_tif_path, selected_roi_path, image_shape\n",
    "        image_data = data['image_data']\n",
    "        corrected_data = data['corrected_data']\n",
    "        roi_masks = data['roi_masks']\n",
    "        roi_centers = data['roi_centers']\n",
    "        roi_data = data['roi_data']\n",
    "        metadata = data['metadata']\n",
    "        selected_tif_path = data['selected_tif_path']\n",
    "        selected_roi_path = data['selected_roi_path']\n",
    "        image_shape = data['image_shape']\n",
    "        \n",
    "        print(\"Visualization data loaded successfully!\")\n",
    "        print(f\"File: {Path(selected_tif_path).stem}\")\n",
    "        print(f\"Image shape: {image_data.shape}\")\n",
    "        print(f\"Number of ROIs: {len(roi_masks)}\")\n",
    "        print(f\"Condition: {metadata.get('condition', 'unknown')}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading visualization data: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Widget to select a visualization data file\n",
    "vis_data_path_widget = widgets.Text(\n",
    "    placeholder='Enter path to visualization_data.pkl file',\n",
    "    description='Data File:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "load_vis_data_button = widgets.Button(\n",
    "    description='Load Saved Visualization Data',\n",
    "    button_style='info',\n",
    "    tooltip='Load previously saved visualization data'\n",
    ")\n",
    "\n",
    "def on_load_vis_data_click(b):\n",
    "    path = vis_data_path_widget.value\n",
    "    if path:\n",
    "        success = load_visualization_data(path)\n",
    "        if success:\n",
    "            print(\"Ready for visualization!\")\n",
    "    else:\n",
    "        print(\"Please enter a valid path to the visualization_data.pkl file\")\n",
    "\n",
    "load_vis_data_button.on_click(on_load_vis_data_click)\n",
    "\n",
    "display(vis_data_path_widget)\n",
    "display(load_vis_data_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a395f40-f042-46b8-a2d4-3fe69811c5b5",
   "metadata": {},
   "source": [
    "## Gaussian Denoising\n",
    "\n",
    "Gaussian denoising helps reduce noise in fluorescence images while preserving important features. This is particularly important for accurately identifying ROIs and detecting events in your calcium imaging data.\n",
    "\n",
    "### How It Works\n",
    "The Gaussian blur operation applies a weighted average to each pixel, where nearby pixels have more influence than distant ones. The weighting follows a Gaussian distribution centered at the pixel being processed.\n",
    "\n",
    "### Key Parameters\n",
    "- **Kernel Size**: Controls the size of the filter window (must be odd). Larger values remove more noise but may blur important details.\n",
    "- **Sigma**: Controls the width of the Gaussian distribution. Higher values produce more blurring and stronger noise reduction.\n",
    "\n",
    "### Finding Optimal Values\n",
    "The best parameters balance noise reduction and feature preservation:\n",
    "- For noisy recordings, try larger kernel sizes (7-11) and higher sigma values (2-4)\n",
    "- For cleaner recordings, use smaller kernels (3-5) and lower sigma values (0.5-1.5)\n",
    "\n",
    "Use the interactive tool below to experiment with different settings and observe their effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080bbf3f-d20e-484d-ba7e-402791a504a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary visualization libraries\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "import numpy as np\n",
    "from IPython.core.display import display\n",
    "\n",
    "# Initialize holoviews with bokeh backend\n",
    "hv.extension('bokeh')\n",
    "\n",
    "# @title Gaussian Denoising Visualization\n",
    "\n",
    "def run_gaussian_denoising():\n",
    "    # Check that image data is loaded\n",
    "    if 'image_data' not in globals() or image_data is None:\n",
    "        print(\"Please load image data first\")\n",
    "        return\n",
    "    \n",
    "    # Create panel widgets for parameters\n",
    "    frame_slider = pn.widgets.IntSlider(name='Frame', start=0, \n",
    "                                     end=min(image_data.shape[0]-1, 100), step=1, value=10)\n",
    "    ksize_slider = pn.widgets.IntSlider(name='Kernel Size', start=1, end=21, step=2, value=5)\n",
    "    sigma_slider = pn.widgets.FloatSlider(name='Sigma X', start=0.1, end=10.0, step=0.1, value=1.5)\n",
    "    \n",
    "    @pn.depends(frame_slider, ksize_slider, sigma_slider)\n",
    "    def apply_gaussian_blur(frame_idx, ksize, sigma):\n",
    "        # Ensure ksize is odd\n",
    "        if ksize % 2 == 0:\n",
    "            ksize += 1\n",
    "            \n",
    "        # Get the selected frame\n",
    "        sample_frame = image_data[frame_idx].copy()\n",
    "        \n",
    "        # Apply Gaussian denoising\n",
    "        denoised_frame = cv2.GaussianBlur(sample_frame, (ksize, ksize), sigma)\n",
    "        \n",
    "        # Calculate difference\n",
    "        diff = np.abs(sample_frame - denoised_frame)\n",
    "        \n",
    "        # Normalize for display\n",
    "        norm_orig = (sample_frame - sample_frame.min()) / (sample_frame.max() - sample_frame.min() + 1e-10)\n",
    "        norm_denoised = (denoised_frame - denoised_frame.min()) / (denoised_frame.max() - denoised_frame.min() + 1e-10)\n",
    "        norm_diff = diff / (diff.max() + 1e-10)\n",
    "        \n",
    "        # Convert to HoloViews Image objects\n",
    "        orig_img = hv.Image(norm_orig).opts(\n",
    "            title='Original Frame',\n",
    "            cmap='gray', \n",
    "            width=300, \n",
    "            height=300\n",
    "        )\n",
    "        \n",
    "        denoised_img = hv.Image(norm_denoised).opts(\n",
    "            title=f'Gaussian Denoised (k={ksize}, Ïƒ={sigma:.1f})',\n",
    "            cmap='gray', \n",
    "            width=300, \n",
    "            height=300\n",
    "        )\n",
    "        \n",
    "        diff_img = hv.Image(norm_diff).opts(\n",
    "            title='Difference (Red=More Change)',\n",
    "            cmap='hot', \n",
    "            width=300, \n",
    "            height=300\n",
    "        )\n",
    "        \n",
    "        # Update config with current values\n",
    "        if 'denoise' not in config['preprocessing']:\n",
    "            config['preprocessing']['denoise'] = {}\n",
    "        \n",
    "        config['preprocessing']['denoise']['enabled'] = True\n",
    "        config['preprocessing']['denoise']['method'] = 'gaussian'\n",
    "        config['preprocessing']['denoise']['params'] = {\n",
    "            'ksize': [ksize, ksize],\n",
    "            'sigmaX': sigma\n",
    "        }\n",
    "        \n",
    "        # Return layout with all three images\n",
    "        return (orig_img + denoised_img + diff_img).cols(3)\n",
    "    \n",
    "    # Create a Panel app with the widgets and visualization\n",
    "    app = pn.Column(\n",
    "        \"## Gaussian Denoising Tool\",\n",
    "        pn.Row(\n",
    "            pn.Column(frame_slider, ksize_slider, sigma_slider, width=250),\n",
    "            apply_gaussian_blur\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return app\n",
    "\n",
    "# Allow user to run the visualization\n",
    "try:\n",
    "    import panel as pn\n",
    "    print(\"Panel is installed. Run the following to start the visualization:\")\n",
    "    print(\"app = run_gaussian_denoising()\")\n",
    "    print(\"display(app)\")\n",
    "except ImportError:\n",
    "    print(\"You need to install panel first:\")\n",
    "    print(\"!pip install panel\")\n",
    "    print(\"Then restart the kernel and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ed8d4b-6fe1-499f-b0ae-ffd425729cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = run_gaussian_denoising()\n",
    "display(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d2cd4f-623d-406a-9618-bf30b4353be1",
   "metadata": {},
   "source": [
    "## ROI Processing with PNR Refinement\n",
    "\n",
    "Peak-to-Noise Ratio (PNR) refinement helps identify and select ROIs with strong neuronal signals while filtering out ROIs with poor signal quality. This is essential for accurate calcium imaging analysis.\n",
    "\n",
    "### How PNR Refinement Works\n",
    "1. **Frequency Separation**: The fluorescence trace is split into signal (low-frequency) and noise (high-frequency) components\n",
    "2. **Signal Smoothing**: Optional smoothing can be applied to the signal component to reduce fluctuations\n",
    "3. **PNR Calculation**: The ratio between peak signal value and noise standard deviation is calculated\n",
    "4. **Thresholding**: ROIs with PNR values below the threshold are excluded from analysis\n",
    "\n",
    "### Key Parameters\n",
    "- **Noise Frequency Cutoff**: Determines the boundary between signal and noise components (0.01-0.2 Hz)\n",
    "- **Percentile Threshold**: Percentile used to determine peak signal value (90-99.9%)\n",
    "- **Trace Smoothing**: Window size for signal smoothing (0 = no smoothing)\n",
    "- **Min PNR**: Minimum PNR threshold for accepting an ROI (typically 5-10)\n",
    "\n",
    "### Finding Optimal Values\n",
    "- Higher PNR thresholds produce more reliable results but may exclude valid ROIs\n",
    "- The ideal noise frequency cutoff depends on the temporal characteristics of your signal\n",
    "- Smoothing can help stabilize PNR values but may mask transient events\n",
    "\n",
    "The tool below allows you to visualize and adjust these parameters to optimize ROI selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c65f1db-5255-4630-ba6b-17d503167795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title PNR Refinement Interactive Visualization {display-mode: \"form\"}\n",
    "\n",
    "def split_signal_noise(traces, cutoff_freq, logger=None):\n",
    "    \"\"\"Split traces into signal and noise components using frequency filtering.\"\"\"\n",
    "    from scipy import signal\n",
    "    import numpy as np\n",
    "    \n",
    "    n_rois, n_frames = traces.shape\n",
    "    \n",
    "    # Verify cutoff frequency is in valid range\n",
    "    if cutoff_freq <= 0 or cutoff_freq >= 0.5:\n",
    "        cutoff_freq = 0.03\n",
    "    \n",
    "    # Design Butterworth low-pass filter\n",
    "    b_low, a_low = signal.butter(2, cutoff_freq, 'low')\n",
    "    \n",
    "    # Design Butterworth high-pass filter (same cutoff)\n",
    "    b_high, a_high = signal.butter(2, cutoff_freq, 'high')\n",
    "    \n",
    "    # Initialize output arrays\n",
    "    signal_traces = np.zeros_like(traces)\n",
    "    noise_traces = np.zeros_like(traces)\n",
    "    \n",
    "    # Apply filters to each ROI\n",
    "    for i in range(n_rois):\n",
    "        # Apply low-pass filter for signal\n",
    "        signal_traces[i] = signal.filtfilt(b_low, a_low, traces[i])\n",
    "        \n",
    "        # Apply high-pass filter for noise\n",
    "        noise_traces[i] = signal.filtfilt(b_high, a_high, traces[i])\n",
    "    \n",
    "    return signal_traces, noise_traces\n",
    "\n",
    "def smooth_trace(trace, window_size):\n",
    "    \"\"\"Apply moving average smoothing to a trace.\"\"\"\n",
    "    from scipy import signal\n",
    "    import numpy as np\n",
    "    \n",
    "    if window_size <= 0:\n",
    "        return trace\n",
    "        \n",
    "    # Create window coefficients (simple moving average)\n",
    "    window = np.ones(window_size) / window_size\n",
    "    \n",
    "    # Apply convolution for smoothing\n",
    "    smoothed = signal.convolve(trace, window, mode='same')\n",
    "    \n",
    "    # Handle edge effects by copying original values at edges\n",
    "    half_window = window_size // 2\n",
    "    if half_window > 0:\n",
    "        smoothed[:half_window] = trace[:half_window]\n",
    "        smoothed[-half_window:] = trace[-half_window:]\n",
    "    \n",
    "    return smoothed\n",
    "\n",
    "def run_pnr_refinement_visualization():\n",
    "    \"\"\"Create interactive visualization for PNR refinement\"\"\"\n",
    "    # Check that required data is loaded\n",
    "    if 'roi_data' not in globals() or roi_data is None:\n",
    "        print(\"Please load image data first\")\n",
    "        return None\n",
    "    \n",
    "    # Create widgets for parameters\n",
    "    noise_freq_cutoff = widgets.FloatSlider(\n",
    "        value=0.03,\n",
    "        min=0.01,\n",
    "        max=0.2,\n",
    "        step=0.01,\n",
    "        description='Noise Freq Cutoff:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    percentile_threshold = widgets.FloatSlider(\n",
    "        value=99,\n",
    "        min=90,\n",
    "        max=99.9,\n",
    "        step=0.1,\n",
    "        description='Percentile Threshold:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    trace_smoothing = widgets.IntSlider(\n",
    "        value=3,\n",
    "        min=0,\n",
    "        max=15,\n",
    "        step=1,\n",
    "        description='Trace Smoothing:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    min_pnr = widgets.FloatSlider(\n",
    "        value=8.0,\n",
    "        min=3.0,\n",
    "        max=20.0,\n",
    "        step=0.5,\n",
    "        description='Min PNR:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Widget to select ROIs to display\n",
    "    roi_options = [(f\"ROI {i+1}\", i) for i in range(min(10, len(roi_data)))]\n",
    "    roi_indices = widgets.SelectMultiple(\n",
    "        options=roi_options,\n",
    "        value=[0, 1, 2],  # Default: first 3 ROIs\n",
    "        description='ROIs to Display:',\n",
    "        disabled=False,\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    def display_pnr_refinement(noise_freq_cutoff, percentile_threshold, trace_smoothing, min_pnr, roi_indices):\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "        \n",
    "        if not roi_indices or len(roi_indices) == 0:\n",
    "            print(\"Please select at least one ROI to display\")\n",
    "            return\n",
    "            \n",
    "        # Split traces into signal and noise components\n",
    "        sample_traces = roi_data[list(roi_indices)]\n",
    "        signal_traces, noise_traces = split_signal_noise(sample_traces, noise_freq_cutoff)\n",
    "        \n",
    "        # Apply smoothing if enabled\n",
    "        if trace_smoothing > 0:\n",
    "            smoothed_signal = np.zeros_like(signal_traces)\n",
    "            for i in range(len(signal_traces)):\n",
    "                smoothed_signal[i] = smooth_trace(signal_traces[i], trace_smoothing)\n",
    "        else:\n",
    "            smoothed_signal = signal_traces.copy()\n",
    "        \n",
    "        # Compute PNR values\n",
    "        pnr_values = np.zeros(len(roi_indices))\n",
    "        for i in range(len(roi_indices)):\n",
    "            # Get peak value (using percentile)\n",
    "            peak_value = np.percentile(smoothed_signal[i], percentile_threshold)\n",
    "            \n",
    "            # Calculate noise standard deviation\n",
    "            noise_std = np.std(noise_traces[i])\n",
    "            \n",
    "            # Avoid division by zero\n",
    "            if noise_std > 0:\n",
    "                pnr_values[i] = peak_value / noise_std\n",
    "            else:\n",
    "                pnr_values[i] = 0\n",
    "        \n",
    "        # Display traces and PNR values\n",
    "        n_rois = len(roi_indices)\n",
    "        fig, axes = plt.subplots(n_rois, 3, figsize=(15, 4*n_rois))\n",
    "        \n",
    "        # Handle single ROI case\n",
    "        if n_rois == 1:\n",
    "            axes = np.array([axes])\n",
    "        \n",
    "        for i, roi_idx in enumerate(roi_indices):\n",
    "            # Original trace\n",
    "            axes[i, 0].plot(roi_data[roi_idx], 'k-', label=f'Original')\n",
    "            axes[i, 0].set_title(f'ROI {roi_idx+1} - Original Trace')\n",
    "            axes[i, 0].set_xlabel('Frame')\n",
    "            axes[i, 0].set_ylabel('Fluorescence')\n",
    "            axes[i, 0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Signal component\n",
    "            axes[i, 1].plot(signal_traces[i], 'g-', label='Signal')\n",
    "            if trace_smoothing > 0:\n",
    "                axes[i, 1].plot(smoothed_signal[i], 'r-', label='Smoothed Signal')\n",
    "            axes[i, 1].set_title(f'Signal Component (cutoff={noise_freq_cutoff})')\n",
    "            axes[i, 1].set_xlabel('Frame')\n",
    "            axes[i, 1].set_ylabel('Fluorescence')\n",
    "            axes[i, 1].grid(True, alpha=0.3)\n",
    "            axes[i, 1].legend()\n",
    "            \n",
    "            # Noise component\n",
    "            axes[i, 2].plot(noise_traces[i], 'b-', label='Noise')\n",
    "            axes[i, 2].set_title(f'Noise Component (PNR={pnr_values[i]:.2f})')\n",
    "            axes[i, 2].set_xlabel('Frame')\n",
    "            axes[i, 2].set_ylabel('Fluorescence')\n",
    "            axes[i, 2].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add PNR threshold line and indication if the ROI passes the threshold\n",
    "            axes[i, 2].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "            if pnr_values[i] >= min_pnr:\n",
    "                status = \"PASS\"\n",
    "                color = 'green'\n",
    "            else:\n",
    "                status = \"FAIL\"\n",
    "                color = 'red'\n",
    "            \n",
    "            axes[i, 2].text(0.05, 0.95, f\"PNR: {pnr_values[i]:.2f} ({status})\", \n",
    "                            transform=axes[i, 2].transAxes, \n",
    "                            fontsize=10, va='top', ha='left',\n",
    "                            bbox=dict(facecolor=color, alpha=0.3))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Display summary\n",
    "        n_pass = sum(pnr >= min_pnr for pnr in pnr_values)\n",
    "        print(f\"PNR Summary: {n_pass}/{len(roi_indices)} selected ROIs pass the threshold (>= {min_pnr})\")\n",
    "        \n",
    "        # Update config with current values\n",
    "        if 'pnr_refinement' not in config['roi_processing']:\n",
    "            config['roi_processing']['pnr_refinement'] = {}\n",
    "        \n",
    "        config['roi_processing']['pnr_refinement']['noise_freq_cutoff'] = noise_freq_cutoff\n",
    "        config['roi_processing']['pnr_refinement']['min_pnr'] = min_pnr\n",
    "        config['roi_processing']['pnr_refinement']['percentile_threshold'] = percentile_threshold\n",
    "        config['roi_processing']['pnr_refinement']['trace_smoothing'] = trace_smoothing\n",
    "        \n",
    "        # Set these parameters to be enabled in the config\n",
    "        if 'steps' not in config['roi_processing']:\n",
    "            config['roi_processing']['steps'] = {}\n",
    "        config['roi_processing']['steps']['refine_with_pnr'] = True\n",
    "        \n",
    "        print(f\"Updated config with: noise_freq_cutoff={noise_freq_cutoff}, min_pnr={min_pnr}\")\n",
    "        print(f\"percentile_threshold={percentile_threshold}, trace_smoothing={trace_smoothing}\")\n",
    "        print(\"To apply these settings to your pipeline, update your config.yaml file.\")\n",
    "    \n",
    "    # Create and return interactive widget\n",
    "    interactive_plot = interactive(\n",
    "        display_pnr_refinement,\n",
    "        noise_freq_cutoff=noise_freq_cutoff,\n",
    "        percentile_threshold=percentile_threshold,\n",
    "        trace_smoothing=trace_smoothing,\n",
    "        min_pnr=min_pnr,\n",
    "        roi_indices=roi_indices\n",
    "    )\n",
    "    \n",
    "    return interactive_plot\n",
    "\n",
    "print(\"\\n## Interactive ROI Processing with PNR Refinement ##\")\n",
    "print(\"Run the following commands to start the PNR refinement visualization:\")\n",
    "print(\"app = run_pnr_refinement_visualization()\")\n",
    "print(\"display(app)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f64215b-441c-4fd5-9e77-2bf75a9656c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = run_pnr_refinement_visualization()\n",
    "display(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e6ace-a639-4cd7-8646-f7c669291db1",
   "metadata": {},
   "source": [
    "## Background Subtraction\n",
    "\n",
    "Background subtraction removes non-specific fluorescence signals that can mask the true neuronal activity. This improves signal-to-noise ratio and helps detect true calcium events.\n",
    "\n",
    "### Available Methods\n",
    "1. **Darkest Pixels**: Uses the darkest regions of the image (likely non-cellular regions) to estimate background\n",
    "2. **ROI Periphery**: Estimates background from the area surrounding each ROI\n",
    "3. **Global Background**: Uses a global approach to identify and subtract background signal\n",
    "\n",
    "### Key Parameters\n",
    "- **Percentile (%)**: For darkest pixels method, determines how much of the image is considered background\n",
    "- **Min Background Area**: Minimum size of the area to be considered a valid background region\n",
    "- **Median Filter Size**: Size of median filter for noise reduction in background mask\n",
    "- **Periphery Size**: For ROI periphery method, size of the expansion around ROIs\n",
    "\n",
    "### Finding Optimal Values\n",
    "- For darkest pixels, start with a low percentile (0.1-1%) and increase if needed\n",
    "- Larger median filter sizes produce smoother background but may miss spatial variations\n",
    "- For ROI periphery, larger values capture more surrounding tissue but risk including other cells\n",
    "\n",
    "The interactive tool below allows you to visualize how different background subtraction methods and parameters affect your fluorescence traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7098d696-72cc-413a-ac84-48c1d6129b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Background Subtraction Tool {display-mode: \"form\"}\n",
    "\n",
    "def normalize_for_display(img):\n",
    "    \"\"\"Normalize image for display\"\"\"\n",
    "    img_min = img.min()\n",
    "    img_max = img.max()\n",
    "    if img_max > img_min:\n",
    "        return (img - img_min) / (img_max - img_min)\n",
    "    return img\n",
    "\n",
    "def run_background_subtraction_visualization():\n",
    "    \"\"\"Create interactive visualization for background subtraction\"\"\"\n",
    "    # Check if required data is loaded\n",
    "    if 'roi_data' not in globals() or roi_data is None or 'image_data' not in globals() or image_data is None:\n",
    "        print(\"Please load ROI data and image data first\")\n",
    "        return None\n",
    "    \n",
    "    # Create widgets for background subtraction parameters\n",
    "    bg_method = widgets.Dropdown(\n",
    "        options=[\n",
    "            ('Darkest Pixels', 'darkest_pixels'), \n",
    "            ('ROI Periphery', 'roi_periphery'),\n",
    "            ('Global Background', 'global_background')\n",
    "        ],\n",
    "        value='darkest_pixels',\n",
    "        description='Method:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    percentile = widgets.FloatSlider(\n",
    "        value=0.2,\n",
    "        min=0.1,\n",
    "        max=10.0,\n",
    "        step=0.1,\n",
    "        description='Percentile (%):',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    min_bg_area = widgets.IntSlider(\n",
    "        value=200,\n",
    "        min=50,\n",
    "        max=1000,\n",
    "        step=50,\n",
    "        description='Min Background Area:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    median_filter_size = widgets.IntSlider(\n",
    "        value=5,\n",
    "        min=0,\n",
    "        max=15,\n",
    "        step=2,\n",
    "        description='Median Filter Size:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    periphery_size = widgets.IntSlider(\n",
    "        value=2,\n",
    "        min=1,\n",
    "        max=10,\n",
    "        step=1,\n",
    "        description='Periphery Size:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Widget to select ROIs to display\n",
    "    roi_options = [(f\"ROI {i+1}\", i) for i in range(min(10, len(roi_data)))]\n",
    "    roi_indices = widgets.SelectMultiple(\n",
    "        options=roi_options,\n",
    "        value=[0, 1, 2],  # Default: first 3 ROIs\n",
    "        description='ROIs to Display:',\n",
    "        disabled=False,\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    def display_background_subtraction(bg_method, percentile, min_bg_area, median_filter_size, periphery_size, roi_indices):\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "        from scipy.ndimage import binary_dilation, median_filter\n",
    "        \n",
    "        if not roi_indices or len(roi_indices) == 0:\n",
    "            print(\"Please select at least one ROI to display\")\n",
    "            return\n",
    "        \n",
    "        # Create configuration for background subtraction\n",
    "        bg_config = {\n",
    "            \"method\": bg_method,\n",
    "            \"percentile\": percentile,\n",
    "            \"min_background_area\": min_bg_area,\n",
    "            \"median_filter_size\": median_filter_size,\n",
    "            \"periphery_size\": periphery_size\n",
    "        }\n",
    "        \n",
    "        # Get ROI data for selected ROIs\n",
    "        selected_roi_data = roi_data[list(roi_indices)]\n",
    "        selected_roi_masks = [roi_masks[i] for i in roi_indices]\n",
    "        \n",
    "        # Apply background subtraction - first create a shallow copy of functions we need\n",
    "        if bg_method == 'global_background':\n",
    "            # For global background, we need to use the correct function\n",
    "            from modules.roi_processing import subtract_global_background\n",
    "            bg_corrected_data = subtract_global_background(\n",
    "                image_data, \n",
    "                selected_roi_data,\n",
    "                selected_roi_masks,\n",
    "                bg_config,\n",
    "                logger\n",
    "            )\n",
    "        else:\n",
    "            # For other methods, use standard background subtraction\n",
    "            from modules.roi_processing import subtract_background\n",
    "            bg_corrected_data = subtract_background(\n",
    "                image_data, \n",
    "                selected_roi_data,\n",
    "                selected_roi_masks,\n",
    "                bg_config,\n",
    "                logger\n",
    "            )\n",
    "        \n",
    "        # Display original vs background-corrected traces\n",
    "        n_rois = len(roi_indices)\n",
    "        fig, axes = plt.subplots(n_rois, 2, figsize=(15, 4*n_rois))\n",
    "        \n",
    "        # Handle single ROI case\n",
    "        if n_rois == 1:\n",
    "            axes = np.array([axes])\n",
    "        \n",
    "        for i, roi_idx in enumerate(roi_indices):\n",
    "            # Original trace\n",
    "            axes[i, 0].plot(selected_roi_data[i], 'k-', label=f'Original')\n",
    "            axes[i, 0].set_title(f'ROI {roi_idx+1} - Original Trace')\n",
    "            axes[i, 0].set_xlabel('Frame')\n",
    "            axes[i, 0].set_ylabel('Fluorescence')\n",
    "            axes[i, 0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Background-corrected trace\n",
    "            axes[i, 1].plot(bg_corrected_data[i], 'g-', label='Background Corrected')\n",
    "            axes[i, 1].set_title(f'Background Corrected ({bg_method})')\n",
    "            axes[i, 1].set_xlabel('Frame')\n",
    "            axes[i, 1].set_ylabel('Fluorescence')\n",
    "            axes[i, 1].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add zero line for reference\n",
    "            axes[i, 1].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Create visualizations based on method\n",
    "        if bg_method == 'darkest_pixels':\n",
    "            # Create darkest pixels mask\n",
    "            avg_intensity = np.mean(image_data, axis=0)\n",
    "            threshold = np.percentile(avg_intensity, percentile)\n",
    "            darkest_pixels_mask = avg_intensity <= threshold\n",
    "            \n",
    "            # Apply median filter to remove noise\n",
    "            if median_filter_size > 0:\n",
    "                darkest_pixels_mask = median_filter(darkest_pixels_mask.astype(float), \n",
    "                                                   size=median_filter_size) > 0.5\n",
    "            \n",
    "            # Create a visualization of the background mask\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "            \n",
    "            # Display average intensity image\n",
    "            axes[0].imshow(normalize_for_display(avg_intensity), cmap='gray')\n",
    "            axes[0].set_title('Average Intensity')\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            # Display background mask\n",
    "            axes[1].imshow(darkest_pixels_mask, cmap='hot')\n",
    "            axes[1].set_title(f'Background Mask (percentile={percentile}%)')\n",
    "            axes[1].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        elif bg_method == 'roi_periphery' and n_rois > 0:\n",
    "            # Create periphery mask for the first selected ROI\n",
    "            first_roi_idx = roi_indices[0]\n",
    "            mask = roi_masks[first_roi_idx]\n",
    "            expanded_mask = binary_dilation(mask, iterations=periphery_size)\n",
    "            periphery_mask = expanded_mask & ~mask\n",
    "            \n",
    "            # Create a visualization of the ROI periphery\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "            \n",
    "            # Get first frame for background display\n",
    "            first_frame = image_data[0]\n",
    "            \n",
    "            # Display original ROI\n",
    "            axes[0].imshow(normalize_for_display(first_frame), cmap='gray')\n",
    "            axes[0].imshow(mask, cmap='hot', alpha=0.5)\n",
    "            axes[0].set_title(f'ROI {first_roi_idx+1} Mask')\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            # Display expanded ROI\n",
    "            axes[1].imshow(normalize_for_display(first_frame), cmap='gray')\n",
    "            axes[1].imshow(expanded_mask, cmap='hot', alpha=0.5)\n",
    "            axes[1].set_title(f'Expanded Mask (periphery={periphery_size})')\n",
    "            axes[1].axis('off')\n",
    "            \n",
    "            # Display periphery only\n",
    "            axes[2].imshow(normalize_for_display(first_frame), cmap='gray')\n",
    "            axes[2].imshow(periphery_mask, cmap='hot', alpha=0.5)\n",
    "            axes[2].set_title('Periphery Mask (for background)')\n",
    "            axes[2].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        # Update config with current values\n",
    "        if 'background' not in config['roi_processing']:\n",
    "            config['roi_processing']['background'] = {}\n",
    "        \n",
    "        config['roi_processing']['background']['method'] = bg_method\n",
    "        config['roi_processing']['background']['percentile'] = percentile\n",
    "        config['roi_processing']['background']['min_background_area'] = min_bg_area\n",
    "        config['roi_processing']['background']['median_filter_size'] = median_filter_size\n",
    "        config['roi_processing']['background']['periphery_size'] = periphery_size\n",
    "        \n",
    "        print(f\"Updated config with: method={bg_method}, percentile={percentile}\")\n",
    "        print(f\"min_background_area={min_bg_area}, median_filter_size={median_filter_size}\")\n",
    "        print(f\"periphery_size={periphery_size}\")\n",
    "        print(\"To apply these settings to your pipeline, update your config.yaml file.\")\n",
    "    \n",
    "    # Create and return interactive widget\n",
    "    interactive_plot = interactive(\n",
    "        display_background_subtraction,\n",
    "        bg_method=bg_method,\n",
    "        percentile=percentile,\n",
    "        min_bg_area=min_bg_area,\n",
    "        median_filter_size=median_filter_size,\n",
    "        periphery_size=periphery_size,\n",
    "        roi_indices=roi_indices\n",
    "    )\n",
    "    \n",
    "    return interactive_plot\n",
    "\n",
    "print(\"\\n## Interactive Background Subtraction Tool ##\")\n",
    "print(\"Run the following commands to start the background subtraction visualization:\")\n",
    "print(\"app = run_background_subtraction_visualization()\")\n",
    "print(\"display(app)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad421f55-aeab-434f-9acc-022dcabeedac",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = run_background_subtraction_visualization()\n",
    "display(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68007efe-07ae-4ab0-9848-892aaff5a8a8",
   "metadata": {},
   "source": [
    "## Event Detection and Analysis\n",
    "\n",
    "Accurate detection of calcium events is crucial for analyzing neuronal activity. This tool allows you to adjust event detection parameters to optimize sensitivity and specificity for your data.\n",
    "\n",
    "### Event Detection Methods\n",
    "The pipeline uses the SciPy `find_peaks` function with several parameters that control sensitivity:\n",
    "\n",
    "### Key Parameters\n",
    "- **Prominence**: Minimum height difference between a peak and surrounding baseline\n",
    "- **Width**: Minimum width (in frames) of a valid peak\n",
    "- **Distance**: Minimum separation (in frames) between valid peaks\n",
    "- **Height**: Minimum absolute height above baseline for a valid peak\n",
    "- **Activity Threshold**: Threshold for declaring an ROI as 'active'\n",
    "\n",
    "### Condition-Specific Analysis\n",
    "Different experimental conditions require different analysis approaches:\n",
    "- **Spontaneous (0Âµm)**: Analyzes spontaneous activity throughout the recording\n",
    "- **Evoked (10Âµm/25Âµm)**: Focuses on activity following stimulus application (frame 100)\n",
    "\n",
    "### Finding Optimal Values\n",
    "- Higher prominence values detect stronger events but may miss subtle ones\n",
    "- Width requirements help distinguish true events from noise\n",
    "- The activity threshold should be set based on your experimental design and expected effect size\n",
    "\n",
    "The interactive tool below allows you to visualize how parameter adjustments affect event detection sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51987f90-1730-44d7-8be4-d5b0f687d94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Event Detection Tool {display-mode: \"form\"}\n",
    "\n",
    "def run_event_detection_visualization():\n",
    "    \"\"\"Create interactive visualization for event detection and analysis\"\"\"\n",
    "    # Check if required data is loaded\n",
    "    if 'roi_data' not in globals() or roi_data is None:\n",
    "        print(\"Please load ROI data first\")\n",
    "        return None\n",
    "    \n",
    "    # Create a copy of traces for visualization\n",
    "    # We'll convert ROI data to dF/F for the event detection\n",
    "    if 'corrected_data' in globals() and corrected_data is not None:\n",
    "        # Extract traces directly from corrected_data using ROI masks\n",
    "        n_rois = len(roi_masks)\n",
    "        n_frames = corrected_data.shape[0]\n",
    "        traces_for_analysis = np.zeros((n_rois, n_frames), dtype=np.float32)\n",
    "        for i, mask in enumerate(roi_masks):\n",
    "            for t in range(n_frames):\n",
    "                binary_mask = mask.astype(bool)\n",
    "                traces_for_analysis[i, t] = np.mean(corrected_data[t][binary_mask])\n",
    "    else:\n",
    "        # If corrected_data isn't available, use roi_data directly\n",
    "        traces_for_analysis = roi_data.copy()\n",
    "    \n",
    "    # Convert to dF/F using a simple baseline calculation\n",
    "    # This is just for visualization - the real pipeline will use more sophisticated methods\n",
    "    df_f_traces = np.zeros_like(traces_for_analysis)\n",
    "    for i in range(len(traces_for_analysis)):\n",
    "        # Use first 100 frames or fewer for baseline calculation\n",
    "        baseline_frames = min(100, traces_for_analysis.shape[1])\n",
    "        baseline = np.percentile(traces_for_analysis[i, :baseline_frames], 8)\n",
    "        df_f_traces[i] = (traces_for_analysis[i] - baseline) / baseline if baseline > 0 else traces_for_analysis[i]\n",
    "    \n",
    "    # Create widgets for event detection parameters\n",
    "    prominence = widgets.FloatSlider(\n",
    "        value=0.03,\n",
    "        min=0.01,\n",
    "        max=0.2,\n",
    "        step=0.01,\n",
    "        description='Prominence:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    width = widgets.IntSlider(\n",
    "        value=2,\n",
    "        min=1,\n",
    "        max=10,\n",
    "        step=1,\n",
    "        description='Width:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    distance = widgets.IntSlider(\n",
    "        value=10,\n",
    "        min=5,\n",
    "        max=30,\n",
    "        step=1,\n",
    "        description='Distance:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    height = widgets.FloatSlider(\n",
    "        value=0.02,\n",
    "        min=0.01,\n",
    "        max=0.2,\n",
    "        step=0.01,\n",
    "        description='Height:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Activity threshold\n",
    "    active_threshold = widgets.FloatSlider(\n",
    "        value=0.02,\n",
    "        min=0.01,\n",
    "        max=0.1,\n",
    "        step=0.01,\n",
    "        description='Activity Threshold:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Widget for condition selection\n",
    "    condition = widgets.Dropdown(\n",
    "        options=[\n",
    "            ('Spontaneous (0Âµm)', '0um'),\n",
    "            ('Evoked (10Âµm)', '10um'),\n",
    "            ('Evoked (25Âµm)', '25um')\n",
    "        ],\n",
    "        value='0um',\n",
    "        description='Condition:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Widget to select ROIs to display\n",
    "    roi_options = [(f\"ROI {i+1}\", i) for i in range(min(10, len(df_f_traces)))]\n",
    "    roi_indices = widgets.SelectMultiple(\n",
    "        options=roi_options,\n",
    "        value=[0, 1, 2],  # Default: first 3 ROIs\n",
    "        description='ROIs to Display:',\n",
    "        disabled=False,\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    def display_event_detection(prominence, width, distance, height, active_threshold, condition, roi_indices):\n",
    "        import matplotlib.pyplot as plt\n",
    "        from scipy.signal import find_peaks\n",
    "        import numpy as np\n",
    "        \n",
    "        if not roi_indices or len(roi_indices) == 0:\n",
    "            print(\"Please select at least one ROI to display\")\n",
    "            return\n",
    "        \n",
    "        # Create peak detection config\n",
    "        peak_config = {\n",
    "            \"prominence\": prominence,\n",
    "            \"width\": width,\n",
    "            \"distance\": distance,\n",
    "            \"height\": height,\n",
    "            \"rel_height\": 0.5\n",
    "        }\n",
    "        \n",
    "        # Create the peak detection and display\n",
    "        n_rois = len(roi_indices)\n",
    "        fig, axes = plt.subplots(n_rois, 1, figsize=(15, 4*n_rois))\n",
    "        \n",
    "        # Handle single ROI case\n",
    "        if n_rois == 1:\n",
    "            axes = np.array([axes])\n",
    "        \n",
    "        # Set analysis frames based on condition\n",
    "        if condition == '0um':\n",
    "            # For spontaneous, analyze all frames\n",
    "            analysis_frames = [0, df_f_traces.shape[1]-1]\n",
    "            active_metric = \"spont_peak_frequency\"\n",
    "            title_suffix = \"Spontaneous Activity\"\n",
    "        else:\n",
    "            # For evoked, focus on frames after stimulus\n",
    "            analysis_frames = [100, df_f_traces.shape[1]-1]\n",
    "            active_metric = \"peak_amplitude\"\n",
    "            title_suffix = f\"Evoked Activity ({condition})\"\n",
    "        \n",
    "        # Calculate baseline frames - just use first 100 frames or fewer\n",
    "        baseline_frames = [0, min(100, df_f_traces.shape[1]-1)]\n",
    "        \n",
    "        # Process and display each selected ROI\n",
    "        active_rois = 0\n",
    "        for i, roi_idx in enumerate(roi_indices):\n",
    "            trace = df_f_traces[roi_idx]\n",
    "            \n",
    "            # Extract analysis window\n",
    "            analysis_start, analysis_end = analysis_frames\n",
    "            analysis_window = trace[analysis_start:analysis_end+1]\n",
    "            \n",
    "            # For evoked conditions, calculate and display stimulus time\n",
    "            if condition != '0um':\n",
    "                stim_frame = 100  # Frame where stimulus occurs\n",
    "            \n",
    "            # Extract peaks\n",
    "            if condition == '0um':\n",
    "                # For spontaneous, look at peaks during baseline period\n",
    "                baseline_trace = trace[baseline_frames[0]:baseline_frames[1]+1]\n",
    "                peaks, properties = find_peaks(\n",
    "                    baseline_trace,\n",
    "                    prominence=prominence/2,  # Use lower threshold for spontaneous\n",
    "                    width=width,\n",
    "                    distance=distance,\n",
    "                    height=active_threshold\n",
    "                )\n",
    "                \n",
    "                # Calculate peak frequency (peaks per 100 frames)\n",
    "                peak_freq = len(peaks) / (len(baseline_trace) / 100) if len(baseline_trace) > 0 else 0\n",
    "                \n",
    "                # Check if ROI is active based on peak frequency\n",
    "                is_active = peak_freq > active_threshold\n",
    "                if is_active:\n",
    "                    active_rois += 1\n",
    "                \n",
    "                # Plot trace\n",
    "                axes[i].plot(trace, 'k-', label='dF/F')\n",
    "                \n",
    "                # Highlight baseline window\n",
    "                axes[i].axvspan(baseline_frames[0], baseline_frames[1], color='lightgray', alpha=0.2, label='Baseline Window')\n",
    "                \n",
    "                # Find and highlight peaks in full trace\n",
    "                all_peaks, _ = find_peaks(\n",
    "                    trace,\n",
    "                    prominence=prominence/2,\n",
    "                    width=width,\n",
    "                    distance=distance,\n",
    "                    height=active_threshold\n",
    "                )\n",
    "                \n",
    "                if len(all_peaks) > 0:\n",
    "                    axes[i].plot(all_peaks, trace[all_peaks], 'ro', label='Peaks')\n",
    "                \n",
    "                # Add title with metrics\n",
    "                axes[i].set_title(f\"ROI {roi_idx+1} - {'Active' if is_active else 'Inactive'} - Peak Freq: {peak_freq:.2f}/100 frames\")\n",
    "                \n",
    "            else:\n",
    "                # For evoked, look at peaks after stimulus\n",
    "                peaks, properties = find_peaks(\n",
    "                    analysis_window,\n",
    "                    prominence=prominence,\n",
    "                    width=width,\n",
    "                    distance=distance,\n",
    "                    height=height\n",
    "                )\n",
    "                \n",
    "                # Calculate peak amplitude (max value)\n",
    "                peak_amplitude = np.max(analysis_window) if len(analysis_window) > 0 else 0\n",
    "                \n",
    "                # Check if ROI is active based on peak amplitude\n",
    "                is_active = peak_amplitude > active_threshold\n",
    "                if is_active:\n",
    "                    active_rois += 1\n",
    "                \n",
    "                # Plot trace\n",
    "                axes[i].plot(trace, 'k-', label='dF/F')\n",
    "                \n",
    "                # Add a vertical line at stimulus time\n",
    "                axes[i].axvline(x=stim_frame, color='r', linestyle='--', label='Stimulus', alpha=0.7)\n",
    "                \n",
    "                # Highlight analysis window\n",
    "                axes[i].axvspan(analysis_start, analysis_end, color='lightgray', alpha=0.2, label='Analysis Window')\n",
    "                \n",
    "                # Find and highlight peaks\n",
    "                if len(peaks) > 0:\n",
    "                    # Adjust peak indices to match original trace\n",
    "                    adjusted_peaks = peaks + analysis_start\n",
    "                    axes[i].plot(adjusted_peaks, trace[adjusted_peaks], 'ro', label='Peaks')\n",
    "                \n",
    "                # Add title with metrics\n",
    "                axes[i].set_title(f\"ROI {roi_idx+1} - {'Active' if is_active else 'Inactive'} - Peak Amplitude: {peak_amplitude:.4f}\")\n",
    "            \n",
    "            # Add zero line for reference\n",
    "            axes[i].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "            \n",
    "            # Add a threshold line\n",
    "            axes[i].axhline(y=active_threshold, color='g', linestyle=':', \n",
    "                           label=f'Threshold ({active_threshold:.2f})', alpha=0.5)\n",
    "            \n",
    "            axes[i].set_xlabel('Frame')\n",
    "            axes[i].set_ylabel('dF/F')\n",
    "            axes[i].legend()\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f\"Event Detection - {title_suffix} ({active_rois}/{n_rois} ROIs Active)\", fontsize=16, y=1.02)\n",
    "        plt.show()\n",
    "        \n",
    "        # Update config with current values\n",
    "        # Peak detection parameters\n",
    "        if 'peak_detection' not in config['analysis']:\n",
    "            config['analysis']['peak_detection'] = {}\n",
    "        \n",
    "        config['analysis']['peak_detection']['prominence'] = prominence\n",
    "        config['analysis']['peak_detection']['width'] = width\n",
    "        config['analysis']['peak_detection']['distance'] = distance\n",
    "        config['analysis']['peak_detection']['height'] = height\n",
    "        \n",
    "        # Activity threshold\n",
    "        config['analysis']['active_threshold'] = active_threshold\n",
    "        \n",
    "        # Condition-specific parameters\n",
    "        if 'condition_specific' not in config['analysis']:\n",
    "            config['analysis']['condition_specific'] = {}\n",
    "        \n",
    "        if condition not in config['analysis']['condition_specific']:\n",
    "            config['analysis']['condition_specific'][condition] = {}\n",
    "        \n",
    "        config['analysis']['condition_specific'][condition]['active_threshold'] = active_threshold\n",
    "        config['analysis']['condition_specific'][condition]['active_metric'] = active_metric\n",
    "        \n",
    "        print(f\"Updated config with: prominence={prominence}, width={width}, distance={distance}, height={height}\")\n",
    "        print(f\"active_threshold={active_threshold}, condition={condition}, active_metric={active_metric}\")\n",
    "        print(\"To apply these settings to your pipeline, update your config.yaml file.\")\n",
    "    \n",
    "    # Create and return interactive widget\n",
    "    interactive_plot = interactive(\n",
    "        display_event_detection,\n",
    "        prominence=prominence,\n",
    "        width=width,\n",
    "        distance=distance,\n",
    "        height=height,\n",
    "        active_threshold=active_threshold,\n",
    "        condition=condition,\n",
    "        roi_indices=roi_indices\n",
    "    )\n",
    "    \n",
    "    return interactive_plot\n",
    "\n",
    "print(\"\\n## Interactive Event Detection Tool ##\")\n",
    "print(\"Run the following commands to start the event detection visualization:\")\n",
    "print(\"app = run_event_detection_visualization()\")\n",
    "print(\"display(app)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5ac087-8593-48f3-862a-d23f288ef39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = run_event_detection_visualization()\n",
    "display(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2d4dc2-ef51-4b0e-9c8d-e9dd6ba695de",
   "metadata": {},
   "source": [
    "## Save Optimized Configuration\n",
    "\n",
    "After exploring different parameter settings in the interactive visualizations, you can save your optimized configuration for future use. This will create a new YAML configuration file with all the parameter adjustments you've made.\n",
    "\n",
    "### Options\n",
    "- **Save Configuration**: Write the current parameters to a YAML file\n",
    "- **Print Current Configuration**: Display the current configuration in the notebook\n",
    "- **Reset Configuration**: Revert to the original configuration that was loaded\n",
    "\n",
    "The saved configuration can be used with the command-line version of the pipeline by specifying the `--config` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2547e3b2-98e7-4aef-9cdb-91d96c97d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Configuration Management {display-mode: \"form\"}\n",
    "def save_config_to_file():\n",
    "    \"\"\"Save the updated configuration to a YAML file\"\"\"\n",
    "    # Create a file selector\n",
    "    output_path = widgets.Text(\n",
    "        value='optimized_config.yaml',\n",
    "        placeholder='Enter file path to save config',\n",
    "        description='Output File:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "    \n",
    "    display(output_path)\n",
    "    \n",
    "    # Create a save button\n",
    "    save_button = widgets.Button(\n",
    "        description='Save Configuration',\n",
    "        button_style='success',\n",
    "        tooltip='Click to save the current configuration to a file'\n",
    "    )\n",
    "    \n",
    "    def on_save_click(b):\n",
    "        try:\n",
    "            path = output_path.value\n",
    "            if not path:\n",
    "                print(\"Please enter a valid file path\")\n",
    "                return\n",
    "            \n",
    "            # Save the configuration to the specified file\n",
    "            with open(path, 'w') as f:\n",
    "                yaml.dump(config, f, default_flow_style=False)\n",
    "            \n",
    "            print(f\"Configuration saved to {path}\")\n",
    "            print(\"To use this configuration in your pipeline, specify it with the --config parameter\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving configuration: {str(e)}\")\n",
    "    \n",
    "    save_button.on_click(on_save_click)\n",
    "    display(save_button)\n",
    "    \n",
    "    # Create a button to print the current configuration\n",
    "    print_button = widgets.Button(\n",
    "        description='Print Current Configuration',\n",
    "        button_style='info',\n",
    "        tooltip='Click to print the current configuration to the notebook'\n",
    "    )\n",
    "    \n",
    "    def on_print_click(b):\n",
    "        # Print the configuration in a readable format\n",
    "        print(\"Current Configuration:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Print as formatted YAML\n",
    "        print(yaml.dump(config, default_flow_style=False))\n",
    "    \n",
    "    print_button.on_click(on_print_click)\n",
    "    display(print_button)\n",
    "    \n",
    "    # Create a button to reset configuration to original\n",
    "    reset_button = widgets.Button(\n",
    "        description='Reset Configuration',\n",
    "        button_style='danger',\n",
    "        tooltip='Click to reset the configuration to the original values'\n",
    "    )\n",
    "    \n",
    "    def on_reset_click(b):\n",
    "        # Reset the configuration to the original values\n",
    "        global config\n",
    "        config = copy.deepcopy(config_original)\n",
    "        print(\"Configuration reset to original values\")\n",
    "    \n",
    "    reset_button.on_click(on_reset_click)\n",
    "    display(reset_button)\n",
    "\n",
    "# Call the save configuration function\n",
    "save_config_to_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d137d-6c09-4a29-8556-b4c8b2dfffc0",
   "metadata": {},
   "source": [
    "## Run Full Pipeline\n",
    "\n",
    "Once you've optimized the parameters using the interactive visualizations, you can run the complete analysis pipeline on all your data. The pipeline will:\n",
    "\n",
    "1. Process all matched TIF/ROI file pairs in the input directory\n",
    "2. Apply preprocessing with your optimized parameters\n",
    "3. Extract and refine ROIs\n",
    "4. Perform background subtraction\n",
    "5. Detect and analyze events\n",
    "6. Generate visualizations and metrics\n",
    "\n",
    "The results will be saved in the output directory specified in the parameters section. Each file pair will have its own subdirectory containing:\n",
    "- Corrected data (HDF5 format)\n",
    "- ROI masks and traces\n",
    "- Analysis metrics (Excel and CSV)\n",
    "- Visualizations (PNG format)\n",
    "\n",
    "### Performance Considerations\n",
    "- Processing multiple large files can be memory-intensive\n",
    "- The pipeline supports parallel processing using multiple CPU cores\n",
    "- Adjust the \"Max Workers\" parameter based on your computer's capabilities\n",
    "\n",
    "Click \"Run Full Pipeline\" to start processing all file pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b143ed1-fd8e-4cd0-91c9-d708d3d033f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Run Full Pipeline {display-mode: \"form\"}\n",
    "# Define the process_file_pair function at the module level (outside of any other function)\n",
    "def process_file_pair(pair_info):\n",
    "    \"\"\"Process a single file pair.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pair_info : tuple\n",
    "        Tuple containing (pair_idx, tif_path, roi_path, config, args)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Processing results\n",
    "    \"\"\"\n",
    "    pair_idx, tif_path, roi_path, config, args = pair_info\n",
    "    slice_name = Path(tif_path).stem\n",
    "    print(f\"Processing {slice_name}...\")\n",
    "    \n",
    "    # Create output directory for this slice\n",
    "    slice_output_dir = os.path.join(args.output_dir, slice_name)\n",
    "    os.makedirs(slice_output_dir, exist_ok=True)\n",
    "    \n",
    "    # Extract metadata from filename\n",
    "    metadata = extract_metadata_from_filename(slice_name)\n",
    "    \n",
    "    # Load and preprocess the image data\n",
    "    with tifffile.TiffFile(tif_path) as tif:\n",
    "        image_data = tif.asarray()\n",
    "        \n",
    "        # Ensure data is in (frames, height, width) format\n",
    "        if len(image_data.shape) == 3:\n",
    "            if image_data.shape[0] < image_data.shape[1] and image_data.shape[0] < image_data.shape[2]:\n",
    "                # Already in (frames, height, width) format\n",
    "                pass\n",
    "            else:\n",
    "                # Try to rearrange to (frames, height, width)\n",
    "                if image_data.shape[2] < image_data.shape[0] and image_data.shape[2] < image_data.shape[1]:\n",
    "                    image_data = np.moveaxis(image_data, 2, 0)\n",
    "                elif image_data.shape[1] < image_data.shape[0] and image_data.shape[1] < image_data.shape[2]:\n",
    "                    image_data = np.moveaxis(image_data, 1, 0)\n",
    "    \n",
    "    n_frames, height, width = image_data.shape\n",
    "    image_shape = (height, width)\n",
    "    \n",
    "    # Setup logging\n",
    "    log_file = os.path.join(slice_output_dir, f\"{slice_name}_processing.log\")\n",
    "    slice_logger = setup_logging(log_file, process_id=pair_idx)\n",
    "    \n",
    "    # Apply photobleaching correction\n",
    "    output_h5 = os.path.join(slice_output_dir, f\"{slice_name}_corrected.h5\")\n",
    "    corrected_data, _ = correct_photobleaching(\n",
    "        image_data,\n",
    "        output_h5,\n",
    "        config[\"preprocessing\"],\n",
    "        slice_logger,\n",
    "        save_output=config[\"preprocessing\"].get(\"save_corrected_data\", True)\n",
    "    )\n",
    "    \n",
    "    # Extract ROIs\n",
    "    roi_masks, roi_data = extract_roi_fluorescence(\n",
    "        roi_path,\n",
    "        corrected_data,\n",
    "        image_shape,\n",
    "        slice_output_dir,\n",
    "        config[\"roi_processing\"],\n",
    "        slice_logger\n",
    "    )\n",
    "    \n",
    "    # Background subtraction\n",
    "    if config[\"roi_processing\"].get(\"steps\", {}).get(\"subtract_background\", True):\n",
    "        bg_method = config[\"roi_processing\"][\"background\"].get(\"method\", \"darkest_pixels\")\n",
    "        \n",
    "        if bg_method == \"global_background\":\n",
    "            bg_corrected_data = subtract_global_background(\n",
    "                corrected_data,\n",
    "                roi_data,\n",
    "                roi_masks,\n",
    "                config[\"roi_processing\"][\"background\"],\n",
    "                slice_logger,\n",
    "                output_dir=slice_output_dir\n",
    "            )\n",
    "        else:\n",
    "            bg_corrected_data = subtract_background(\n",
    "                corrected_data,\n",
    "                roi_data,\n",
    "                roi_masks,\n",
    "                config[\"roi_processing\"][\"background\"],\n",
    "                slice_logger,\n",
    "                output_dir=slice_output_dir\n",
    "            )\n",
    "    else:\n",
    "        bg_corrected_data = roi_data\n",
    "    \n",
    "    # Analyze fluorescence\n",
    "    metrics_df, df_f_traces = analyze_fluorescence(\n",
    "        bg_corrected_data,\n",
    "        roi_masks,\n",
    "        tif_path,\n",
    "        config[\"analysis\"],\n",
    "        slice_logger,\n",
    "        output_dir=slice_output_dir,\n",
    "        metadata=metadata\n",
    "    )\n",
    "    \n",
    "    # Save metrics to Excel\n",
    "    metrics_file = os.path.join(slice_output_dir, f\"{slice_name}_metrics.xlsx\")\n",
    "    metrics_df.to_excel(metrics_file, index=False)\n",
    "    \n",
    "    # Also save as CSV for easier processing\n",
    "    csv_file = os.path.join(slice_output_dir, f\"{slice_name}_metrics.csv\")\n",
    "    metrics_df.to_csv(csv_file, index=False)\n",
    "    \n",
    "    # Generate visualizations\n",
    "    flagged_rois = perform_qc_checks(\n",
    "        bg_corrected_data,\n",
    "        metrics_df,\n",
    "        config[\"analysis\"].get(\"qc_thresholds\", {}),\n",
    "        slice_logger\n",
    "    )\n",
    "    \n",
    "    generate_visualizations(\n",
    "        df_f_traces,\n",
    "        roi_masks,\n",
    "        metrics_df,\n",
    "        flagged_rois,\n",
    "        tif_path,\n",
    "        slice_output_dir,\n",
    "        config[\"visualization\"],\n",
    "        slice_logger,\n",
    "        metadata=metadata\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"slice_name\": slice_name,\n",
    "        \"metrics_file\": metrics_file,\n",
    "        \"metadata\": metadata\n",
    "    }\n",
    "\n",
    "def run_full_pipeline():\n",
    "    \"\"\"Run the full pipeline with the current configuration\"\"\"\n",
    "    # Create a run button\n",
    "    run_button = widgets.Button(\n",
    "        description='Run Full Pipeline',\n",
    "        button_style='success',\n",
    "        tooltip='Click to run the full pipeline with the current configuration'\n",
    "    )\n",
    "    \n",
    "    def on_run_click(b):\n",
    "        # Run the pipeline with the current configuration\n",
    "        print(\"Running pipeline...\")\n",
    "        print(f\"Input Directory: {args.input_dir}\")\n",
    "        print(f\"Output Directory: {args.output_dir}\")\n",
    "        print(f\"Pipeline Mode: {args.mode}\")\n",
    "        print(f\"Max Workers: {args.max_workers}\")\n",
    "        \n",
    "        try:\n",
    "            # Update args with current widget values\n",
    "            update_args()\n",
    "            \n",
    "            # Match tif and roi files\n",
    "            file_pairs = match_tif_and_roi_files(args.input_dir, logger)\n",
    "            print(f\"Found {len(file_pairs)} matched file pairs\")\n",
    "            \n",
    "            if len(file_pairs) == 0:\n",
    "                print(\"No file pairs found. Please check the input directory.\")\n",
    "                return\n",
    "            \n",
    "            # Process each file pair\n",
    "            import concurrent.futures\n",
    "            from tqdm.notebook import tqdm\n",
    "            \n",
    "            # Create a progress widget\n",
    "            progress = widgets.IntProgress(\n",
    "                value=0,\n",
    "                min=0,\n",
    "                max=len(file_pairs),\n",
    "                description='Processing:',\n",
    "                bar_style='info',\n",
    "                orientation='horizontal'\n",
    "            )\n",
    "            display(progress)\n",
    "            \n",
    "            # Process file pairs sequentially or in parallel based on max_workers\n",
    "            results = []\n",
    "            \n",
    "            # Create tuples of arguments for the process_file_pair function\n",
    "            # This allows us to pass the config to each process\n",
    "            pair_infos = [\n",
    "                (i, tif_path, roi_path, config, args) \n",
    "                for i, (tif_path, roi_path) in enumerate(file_pairs)\n",
    "            ]\n",
    "            \n",
    "            if args.max_workers > 1:\n",
    "                print(f\"Using {args.max_workers} parallel workers\")\n",
    "                with concurrent.futures.ProcessPoolExecutor(max_workers=args.max_workers) as executor:\n",
    "                    futures = [executor.submit(process_file_pair, pair_info) \n",
    "                              for pair_info in pair_infos]\n",
    "                    \n",
    "                    for i, future in enumerate(concurrent.futures.as_completed(futures)):\n",
    "                        try:\n",
    "                            result = future.result()\n",
    "                            results.append(result)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error in worker process: {str(e)}\")\n",
    "                        finally:\n",
    "                            progress.value += 1\n",
    "            else:\n",
    "                print(\"Processing files sequentially\")\n",
    "                for pair_info in pair_infos:\n",
    "                    try:\n",
    "                        result = process_file_pair(pair_info)\n",
    "                        results.append(result)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing file: {str(e)}\")\n",
    "                    finally:\n",
    "                        progress.value += 1\n",
    "            \n",
    "            progress.bar_style = 'success'\n",
    "            print(f\"Processing completed for {len(results)} file pairs\")\n",
    "            \n",
    "            # Generate summary if we have successful results\n",
    "            if results:\n",
    "                print(\"Generating summary...\")\n",
    "                # Group results by mouse ID\n",
    "                mouse_data = {}\n",
    "                for result in results:\n",
    "                    if \"metadata\" in result:\n",
    "                        mouse_id = result[\"metadata\"].get(\"mouse_id\", \"unknown\")\n",
    "                        if mouse_id not in mouse_data:\n",
    "                            mouse_data[mouse_id] = []\n",
    "                        mouse_data[mouse_id].append(result)\n",
    "                \n",
    "                # Create summary for each mouse\n",
    "                for mouse_id, slices in mouse_data.items():\n",
    "                    summary_path = save_mouse_summary(mouse_id, slices, args.output_dir, logger)\n",
    "                    print(f\"Saved summary for mouse {mouse_id} to {summary_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error running pipeline: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    run_button.on_click(on_run_click)\n",
    "    display(run_button)\n",
    "\n",
    "# Call the run pipeline function\n",
    "run_full_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8f2d01-3d26-4306-9bdd-5c32aae27814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Run Full Pipeline {display-mode: \"form\"}\n",
    "def run_full_pipeline():\n",
    "    \"\"\"Run the full pipeline with the current configuration\"\"\"\n",
    "    # Create a run button\n",
    "    run_button = widgets.Button(\n",
    "        description='Run Full Pipeline',\n",
    "        button_style='success',\n",
    "        tooltip='Click to run the full pipeline with the current configuration'\n",
    "    )\n",
    "    \n",
    "    def on_run_click(b):\n",
    "        # Run the pipeline with the current configuration\n",
    "        print(\"Running pipeline...\")\n",
    "        print(f\"Input Directory: {args.input_dir}\")\n",
    "        print(f\"Output Directory: {args.output_dir}\")\n",
    "        print(f\"Pipeline Mode: {args.mode}\")\n",
    "        print(f\"Max Workers: {args.max_workers}\")\n",
    "        \n",
    "        try:\n",
    "            # Update args with current widget values\n",
    "            update_args()\n",
    "            \n",
    "            # Match tif and roi files\n",
    "            file_pairs = match_tif_and_roi_files(args.input_dir, logger)\n",
    "            print(f\"Found {len(file_pairs)} matched file pairs\")\n",
    "            \n",
    "            if len(file_pairs) == 0:\n",
    "                print(\"No file pairs found. Please check the input directory.\")\n",
    "                return\n",
    "            \n",
    "            # Process each file pair\n",
    "            import concurrent.futures\n",
    "            from tqdm.notebook import tqdm\n",
    "            \n",
    "            # Process a single file pair\n",
    "            def process_file_pair(pair_idx):\n",
    "                tif_path, roi_path = file_pairs[pair_idx]\n",
    "                slice_name = Path(tif_path).stem\n",
    "                print(f\"Processing {slice_name}...\")\n",
    "                \n",
    "                # Create output directory for this slice\n",
    "                slice_output_dir = os.path.join(args.output_dir, slice_name)\n",
    "                os.makedirs(slice_output_dir, exist_ok=True)\n",
    "                \n",
    "                # Extract metadata from filename\n",
    "                metadata = extract_metadata_from_filename(slice_name)\n",
    "                \n",
    "                # Load and preprocess the image data\n",
    "                with tifffile.TiffFile(tif_path) as tif:\n",
    "                    image_data = tif.asarray()\n",
    "                    \n",
    "                    # Ensure data is in (frames, height, width) format\n",
    "                    if len(image_data.shape) == 3:\n",
    "                        if image_data.shape[0] < image_data.shape[1] and image_data.shape[0] < image_data.shape[2]:\n",
    "                            # Already in (frames, height, width) format\n",
    "                            pass\n",
    "                        else:\n",
    "                            # Try to rearrange to (frames, height, width)\n",
    "                            if image_data.shape[2] < image_data.shape[0] and image_data.shape[2] < image_data.shape[1]:\n",
    "                                image_data = np.moveaxis(image_data, 2, 0)\n",
    "                            elif image_data.shape[1] < image_data.shape[0] and image_data.shape[1] < image_data.shape[2]:\n",
    "                                image_data = np.moveaxis(image_data, 1, 0)\n",
    "                \n",
    "                n_frames, height, width = image_data.shape\n",
    "                image_shape = (height, width)\n",
    "                \n",
    "                # Apply photobleaching correction\n",
    "                output_h5 = os.path.join(slice_output_dir, f\"{slice_name}_corrected.h5\")\n",
    "                corrected_data, _ = correct_photobleaching(\n",
    "                    image_data,\n",
    "                    output_h5,\n",
    "                    config[\"preprocessing\"],\n",
    "                    logger,\n",
    "                    save_output=config[\"preprocessing\"].get(\"save_corrected_data\", True)\n",
    "                )\n",
    "                \n",
    "                # Extract ROIs\n",
    "                roi_masks, roi_data = extract_roi_fluorescence(\n",
    "                    roi_path,\n",
    "                    corrected_data,\n",
    "                    image_shape,\n",
    "                    slice_output_dir,\n",
    "                    config[\"roi_processing\"],\n",
    "                    logger\n",
    "                )\n",
    "                \n",
    "                # Background subtraction\n",
    "                if config[\"roi_processing\"].get(\"steps\", {}).get(\"subtract_background\", True):\n",
    "                    bg_method = config[\"roi_processing\"][\"background\"].get(\"method\", \"darkest_pixels\")\n",
    "                    \n",
    "                    if bg_method == \"global_background\":\n",
    "                        bg_corrected_data = subtract_global_background(\n",
    "                            corrected_data,\n",
    "                            roi_data,\n",
    "                            roi_masks,\n",
    "                            config[\"roi_processing\"][\"background\"],\n",
    "                            logger,\n",
    "                            output_dir=slice_output_dir\n",
    "                        )\n",
    "                    else:\n",
    "                        bg_corrected_data = subtract_background(\n",
    "                            corrected_data,\n",
    "                            roi_data,\n",
    "                            roi_masks,\n",
    "                            config[\"roi_processing\"][\"background\"],\n",
    "                            logger,\n",
    "                            output_dir=slice_output_dir\n",
    "                        )\n",
    "                else:\n",
    "                    bg_corrected_data = roi_data\n",
    "                \n",
    "                # Analyze fluorescence\n",
    "                metrics_df, df_f_traces = analyze_fluorescence(\n",
    "                    bg_corrected_data,\n",
    "                    roi_masks,\n",
    "                    tif_path,\n",
    "                    config[\"analysis\"],\n",
    "                    logger,\n",
    "                    output_dir=slice_output_dir,\n",
    "                    metadata=metadata\n",
    "                )\n",
    "                \n",
    "                # Save metrics to Excel\n",
    "                metrics_file = os.path.join(slice_output_dir, f\"{slice_name}_metrics.xlsx\")\n",
    "                metrics_df.to_excel(metrics_file, index=False)\n",
    "                \n",
    "                # Also save as CSV for easier processing\n",
    "                csv_file = os.path.join(slice_output_dir, f\"{slice_name}_metrics.csv\")\n",
    "                metrics_df.to_csv(csv_file, index=False)\n",
    "                \n",
    "                # Generate visualizations\n",
    "                flagged_rois = perform_qc_checks(\n",
    "                    bg_corrected_data,\n",
    "                    metrics_df,\n",
    "                    config[\"analysis\"].get(\"qc_thresholds\", {}),\n",
    "                    logger\n",
    "                )\n",
    "                \n",
    "                generate_visualizations(\n",
    "                    df_f_traces,\n",
    "                    roi_masks,\n",
    "                    metrics_df,\n",
    "                    flagged_rois,\n",
    "                    tif_path,\n",
    "                    slice_output_dir,\n",
    "                    config[\"visualization\"],\n",
    "                    logger,\n",
    "                    metadata=metadata\n",
    "                )\n",
    "                \n",
    "                return {\n",
    "                    \"slice_name\": slice_name,\n",
    "                    \"metrics_file\": metrics_file,\n",
    "                    \"metadata\": metadata\n",
    "                }\n",
    "            \n",
    "            # Create a progress widget\n",
    "            progress = widgets.IntProgress(\n",
    "                value=0,\n",
    "                min=0,\n",
    "                max=len(file_pairs),\n",
    "                description='Processing:',\n",
    "                bar_style='info',\n",
    "                orientation='horizontal'\n",
    "            )\n",
    "            display(progress)\n",
    "            \n",
    "            # Process file pairs sequentially or in parallel based on max_workers\n",
    "            results = []\n",
    "            if args.max_workers > 1:\n",
    "                print(f\"Using {args.max_workers} parallel workers\")\n",
    "                with concurrent.futures.ProcessPoolExecutor(max_workers=args.max_workers) as executor:\n",
    "                    futures = [executor.submit(process_file_pair, i) for i in range(len(file_pairs))]\n",
    "                    for i, future in enumerate(concurrent.futures.as_completed(futures)):\n",
    "                        result = future.result()\n",
    "                        results.append(result)\n",
    "                        progress.value += 1\n",
    "            else:\n",
    "                print(\"Processing files sequentially\")\n",
    "                for i in range(len(file_pairs)):\n",
    "                    result = process_file_pair(i)\n",
    "                    results.append(result)\n",
    "                    progress.value += 1\n",
    "            \n",
    "            progress.bar_style = 'success'\n",
    "            print(f\"Processing completed for {len(results)} file pairs\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error running pipeline: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    run_button.on_click(on_run_click)\n",
    "    display(run_button)\n",
    "\n",
    "# Call the run pipeline function\n",
    "run_full_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34d9106-bb03-4189-a7d1-4d3e118e4149",
   "metadata": {},
   "source": [
    "## Notebook Summary\n",
    "\n",
    "This interactive notebook provides a user-friendly interface to the fluorescence analysis pipeline, allowing you to:\n",
    "\n",
    "1. **Load and Configure**: Set up pipeline parameters and load configuration from YAML file\n",
    "2. **Select and Preprocess Data**: Load TIF/ROI file pairs and prepare them for analysis\n",
    "3. **Explore Parameter Effects**: Use interactive visualizations to understand how different parameters affect:\n",
    "   - Gaussian denoising image quality\n",
    "   - ROI selection with PNR refinement\n",
    "   - Background subtraction effectiveness \n",
    "   - Event detection sensitivity and specificity\n",
    "4. **Optimize Settings**: Adjust parameters to find optimal values for your specific dataset\n",
    "5. **Save Configuration**: Save your optimized configuration for future use\n",
    "6. **Run Full Pipeline**: Process all file pairs with your optimized settings\n",
    "\n",
    "### Output Data\n",
    "The analysis results saved in the output directory include:\n",
    "- Corrected fluorescence data (HDF5 format)\n",
    "- ROI masks and fluorescence traces\n",
    "- Analysis metrics for each ROI (Excel and CSV format)\n",
    "- Visualizations of ROIs, traces, and detected events\n",
    "\n",
    "### Advanced Analysis\n",
    "For more sophisticated analysis of the pipeline outputs, you can:\n",
    "- Use the generated CSVs and Excel files for statistical analysis\n",
    "- Load the HDF5 files for custom visualization and processing\n",
    "- Examine the visualization PNGs for quality control\n",
    "- Compare results across different experimental conditions\n",
    "\n",
    "For questions or issues with the pipeline, please refer to the documentation or contact the developers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0699c8f7-c0ac-44c8-9997-7828f92c549d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
